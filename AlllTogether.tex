\documentclass[12pt]{book}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[compact]{titlesec}
\usepackage{color}
\usepackage{setspace}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{subfig}
%\usepackage[sorting=none]{biblatex}
%\bibliography{thesisbib}
\doublespacing

\begin{document}

\chapter{Abstract}
One of the most basic open questions in physics today concerns the nature of dark matter. There exists strong observational evidence for the existence of dark matter, yet we still know little about its composition, despite the fact that it composes $26.8\%$ of our universe. One leading candidate for dark matter are new light pseudoscalars called axion-like particles (ALPs). Searches for ALPs have been experimentally challenging, as they couple very feebly to ordinary matter.  Experimental techniques to detect dark matter ALPs  rely on a multiphoton radiative transition; in the presence of a strong magnetic field ALPs can convert to photons. If a microwave cavity is placed in the interaction region, when the produced photon's frequency is resonant with a mode of the cavity, the signal power is enhanced further. This method has been applied successfully to constrain the ALP coupling to photons for masses near 1 $\mu$eV, with plans to search up to 10 $\mu$eV. However, prior to this work, the microwave cavity method had not been applied to look for ALPs of higher mass, in the 0.1 to 1 meV range. It is important to search for axions in this mass range in order to cover all possible parameter space, as the axion mass is constrained to lie roughly between 1 $\mu$eV to 1 meV. We present here the first microwave cavity search for dark matter ALPs with mass $\sim 140 \mu$eV. In our experiment we cryogenically cooled a cavity and measured the power in the cavity $\text{ª}_{020}$ mode in a 7 Tesla background magnetic field. Cryogenic HEMT amplifiers and a low noise receiver chain allowed us to run with a system noise temperature of approximately 20 Kelvin. We ran for four months and swept the microwave cavity resonant frequency from 33.9 to 34.5 GHz, corresponding to an axion mass range of 140.2  to 142.7 $\mu$eV. Non-observation of statistically significant signals led to an upper bound on the ALP to two photon coupling of $g_{a\gamma\gamma} < 8.6 \times10^{-11}$ 1/GeV, marginally improving on the previous best limit obtained from the CAST experiment. With the same data set we were also able to set new limits on ``hidden photon" couplings if these hidden photons are responsible for dark matter, where hidden photons refers to massive vector bosons that couple only with Standard Model photons. As with the first generation of microwave cavity experiments that searched for ALPs in the lower mass region, there are several technical challenges that must be overcome in order to reach the sensitivity to observe or exclude canonical axion models. However, as we do not know the ALP mass a priori, it is valuable to develop experiments and techniques to search for them in their entire possible mass range. If observed, axion (and ALP) dark matter would not only be an important advance in our knowledge of dark matter but also give us clues about processes at high energy scales inaccessible by collider experiments.

\tableofcontents
\chapter{Acknowledgments}

\chapter{Introduction}
%At this point, it is firmly established that a large portion of the matter in the universe is non-luminous. Through astrophysical observations, we can estimate that the mass to light ratio in spiral galaxies is much higher than we would expect from the amount of luminous matter alone [NEEDSREF]. The existence of this gravitationally interacting matter influences the rate of structure formation in the early universe, and measurements of the cosmic microwave background can state that the observations are consistent with a $\Lambda$CDM model; that is, a model of the universe as composed of non-baryonic, non-relativistic matter [NEEDSREF]. We know very little more about this dark matter other than the conclusions stated above.
One of the most basic open questions in physics today concerns the nature of dark matter. Strong observational evidence was first presented for the existence of non-luminous, gravitationally interacting matter by Zwicky in 1937 \cite{zwicky37}, who showed that the mass to light ratiosince then the existence of matter that does not interact electromagnetically has been confirmed in other astrophysical observations, with evidence of a diffuse dark matter halo from observations of the rotation curves of spiral galaxies \cite{rubin80}, and precision measurements of the Cosmic Microwave Background that measure the dark matter density in our universe to be 26.8$\%$ \cite{planck13}. However, to date we know little more than the fact that this dark matter is most likely a stable, neutral particle that is non-relativistic (or cold) and non-baryonic

At the same time, the nature of physics at high energy (> TeV) scales is unknown. The equations that make up the Standard Model do not extend into this energy range, and current experiments that can produce physics at high energies (the LHC, other colliders) will be limited by the size of the experiments to explore energies of at most 10 TeV. Ther are many theories of physics at high energy scales; all of these predict new particles at higher energies, or additional symmetries. The high-energy particles or new effects at high energies can enter as small corrections in loop diagrams, leading to small corrections in low-energy observables. The electric dipole moment is one such observable that can be measured in laboratories but whose value is sensitive to high energy physics. The most recent measurement of the electric dipole moment of the electron \cite{acme14} done by the ACME experiment has seen a result consistent with zero, ruling out parameters of 100 TeV theories such as Supersymmetric models. These Supersymmetric (SUSY) theories are high energy theories that solve problems in high energy particle physics, and also predict a stable particle that is a very good candidate for the particle of cold dark matter.

Another probe of this high energy physics is to look for extremely light, feebly interacting particles. These particles arise as the low-mass boson accompanying the breaking of new symmetries at high energies (usually >$10^{14}$ eV). These particles, known generally as Weakly Interacting Sub-eV Particles (WISPs), are good cold dark matter candidates as well, granted that their abundance can be accounted to match the present abundance of dark matter. A particular family of particles belonging to the WISP category, are axion-like particles (ALPs). This denotes pseudoscalar spin 0 bosons with a non-zero coupling to two photons. ALPs take their name from the axion, a particle with the properties described above which arises from a new symmetry which was postulated by Peccei and Quinn \cite{peccei77} to solve the problem of charge and parity conservation in the theory of strong interactions when a priori there is no physical reason this CP conservation should hold.

As direct detection searches for  the SUSY dark matter candidate with no results, there is an intrinsic neutrino background that will soon limit the experiments' sensitivity within another few orders of magnitude from where they can presently search. In addition, no particles have been seen at the LHC, which expected to find new particles that would be SUSY particles. The EDM experiments have constrained different SUSY models with no observation of the electric dipole moment. At this time, it seems necessary to build small tabletop experiments that can look for other dark matter candidates, such as axion-like particles. There is a wide space in which to search for these WISPs, and having measurements allows us to constrain models. A discovery would give us clues as to the nature of physics at high energy scales, and tell us about the composition of dark matter.

\section{Dark Matter}

%There exists compelling evidence that we exist in a universe with non-luminous, non-baryonic matter that forms close to $27\%$ of the matter density in the universe. Cosmologically, the existence of primarily non-relativistic dark matter is crucial in the process of structure formation; without dark matter to form local over-density perturbations, galaxies would have formed much later and the universe we see today would have a much different structure. Astrophysically, the rotation curves of hundreds of spiral galaxies imply a mass to light ratio consistent with a diffuse halo of non-luminous, gravitationally interacting matter. 

%One of the most basic open questions in physics today concerns the nature of dark matter. Strong observational evidence was first presented for the existence of non-luminous, gravitationally interacting matter by Zwicky in 1937 \cite{zwicky37}, who showed that the mass to light ratiosince then the existence of matter that does not interact electromagnetically has been confirmed in other astrophysical observations, with evidence of a diffuse dark matter halo from observations of the rotation curves of spiral galaxies \cite{rubin80}, and precision measurements of the Cosmic Microwave Background that measure the dark matter density in our universe to be 26.8$\%$ \cite{planck13}. However, to date we know little more than the fact that this dark matter is most likely a stable, neutral particle that is non-relativistic (or cold) and non-baryonic \footnote{although dark matter could be caused by modifications to gravity}.
 There are several strongly motivated candidates for dark matter; the three most promising today are sterile neutrinos \cite{kusenko09}, Weakly Interacting Massive Particles (WIMPs), and axion-like particles (ALPs). 

%The argument for the existence of "dark matter", namely mass density that is not luminous and cannot be seen in telescopes, is actually very old. Zwicky back in 1933 already reported "missing mass" in Coma cluster of galaxies. By studying the motion of galaxies in the cluster and using the virial theorem (assuming of course that the galactic motion is virtualized) he determined the mass distribution in the cluster and reported that a substantial fraction of mass is not seen. Since the, the case for dark matter has gotten stronger and stronger and most of us regard its existence as established by now.
%
%Arguably the most important one is the determination of cosmological parameters by the power spectrum of CMB anisotropy. In the fit to the power load flat $\Lambda CDM$ model gives $\Omega_m h^2 = 0.127$ and $\Omega_B h^2 = 0.0223$. This data alone says most of the matter component in the universe is not atoms.
%
%Another important way to determine the baryon density of the universe is based on Big Bang Nucleosynthesis. The baryon density is consistent with what is obtained from the CMB power spectrum $\Omega_B h^2 = 0.0216$. This agrees very well with the CMB result even though they refer to very different epochs.
%
%I'd like also to mention a classic strong evidence for dark matter in galaxies. It comes from the study of rotation cubes in spiral galaxies. Stars and gas rotate about the center of the galaxy. Using Kepler's law, the total mass $M¨$ within radius $r$ and the rotation speed at this radius $v¨$ are related by 
%
%$v¨^{2} = G_N \frac{M¨}{r}$
%
%Once the galaxy runs out of stars beyond a certain radius, the rotation speed is hence expected to decrease as $r^{-12}$. By studying spiral galaxies which happen to be "edge-on" one can measure the rotation speed of cold neutral hydrogen gas at the outskirts of galaxies. This is done using the hyperfine transition "21 cm" line of hydrogen and measuring the amount of Doppler shift to determine the rotation speed. The rotation speed was found to stay constant well beyond the region where stars cease to exist.

This really shows that galaxies are filled with dark matter. This is an important point as we look for signals of dark matter in our own galaxy. It is not easy to determine how much dark matter there is, however, because eventually the hydrogen gas runs out. Nonetheless, it shows the galaxy to be made up of a nearly spherical halo of dark matter in which the disk is embedded.

We don't know what dark matter is, but we have learned, as discussed above, that it is not ordinary atoms (baryons). Black holes and other massive astrophysical objects cannot make up the entirety of the galactic dark matter halo, because the biggest black hole mass that can be created is too small to account for all the dark matter, and because gravitation microlensing places bounds on the number of astrophysical objects in the galaxy.

Neutrinos are part of dark matter, but are not good cold dark matter candidates. First off, they are too light. Secondly, because they are so light they are still relativistic when structure starts to form and thus erase structure at small scales. What we want is cold dark matter, which is already non-relativistic and slowly moving at the time of matter-radiation equality $T \approx 1$ eV.

The idea of a WIMP is very simple. It is a relatively heavy elementary particle so that accelerator experiments so far have not had enough energy to create them. On the other hand, the Big Bang did have the energy to create them. If they are stable, what amount that was produced is still here, and the only way to get rid of them is to annihilate them with each other into more mundane particles. However, the universe expanded and there were fewer and fewer WIMPs in a given volume, and at some point WIMPs stopped finding each other. Then they could not find each other to annihilate and their number became fixed ("freeze-out"). This way, the universe could still be left with a certain abundance of WIMPs. This mechanism of getting dark matter is called "thermal relics".

WIMPs have historically attracted the most attention as dark matter candidates; the term generically refers to neutral particles that have weak scale cross-sections with ordinary matter. From general analyses of the thermalization of particles with such cross-sections, one finds that the present-day abundance of WIMP dark matter would be approximately equal to the observed dark matter abundance, what is known as the ``WIMP miracle". There is also an underlying particle physics motivation for WIMPs that comes from theories of supersymmetry (SUSY), which introduce partners for all the known particles with opposite spin-statistics. This elegantly solves a serious inconsistency in the Higgs mechanism which causes the Higgs boson to have a mass which is quadratically divergent - what is known as the gauge hierarchy problem. The lightest SUSY particle, the neutralino, has all the correct properties to be considered a dark matter WIMP candidate. Various experiments have searched for WIMPs of masses from tens of GeV to 1 TeV, either directly through the recoil of nuclei when passing dark matter WIMPs strike them \cite{lux14}, indirectly through their annihilation with each other in the galaxy \cite{slatyer09}, as well as searches in colliders \cite{rajaraman11}. The null results from these experiments have produced stringent constraints on WIMPs thus far. 

The neutrino was originally considered to be a good dark matter candidate; however neutrinos constitute "hot dark matter", meaning that their speeds in the early history of the universe were such that they were relativistic. This would affect the history of structure formation, causing large structures to form first and then smaller structures later on. This contradicts much of the evidence we have showing that small structures such as white dwarfs are billions of years old, while galaxy clusters are much younger, millions of year old. Thus the neutrino is not a good cold dark matter candidate (cold dark matter would favor this ``bottom-up" structure formation). However, what is known as the sterile neutrino could be a "cold" or "warm" dark matter candidate, depending on its production mechanism. Sterile neutrinos are right-handed neutrinos, so they do not participate in the weak interaction, and their only coupling would be to left-handed neutrinos. Their existence is predicted by the see-saw mechanism, which describes how neutrinos gain mass. There is some tentative evidence for a 3.5 or 7 keV sterile neutrino pair annihilating into X-rays in nearby galaxies \cite{bulbul14}, \cite{boyarsky14}; however it remains to be confirmed in direct experiments and the evidence is highly uncertain at the time of writing.

Finally, axion-like particles, the subject of this dissertation, are another strongly motivated dark matter candidates. These light ($< 1$ meV) pseudoscalar particles possess a generic coupling to two photons. The canonical axion arises from a consideration of symmetry violations in the theory of strong interactions, or quantum chromodynamics (QCD), which will be described later in the chapter.Axion-like particles (ALPs) are light bosons that have similar interactions and properties as the axion, but do not arise specifically from a symmetry interacting with QCD. Axion-like particles appear in string theory \cite{svrcek06}, grand unified theories [NEEDSREF], and more. As the light degrees of freedom of new symmetries broken at high energies, they provide a probe of physics at extremely high energy scales and at times early in the history of the universe. Moreover, evidence for the canonical axion would answer the strong CP problem of why charge and parity symmetries are conserved so well in the strong interaction when a priori there is no reason to suppose these are good symmetries.

Direct Detection Experiments
How do we know if the dark matter is indeed in the form of one of these candidates? One thing we'd love to see is the direct detection of WIMPs. The idea is very simple. You place a very sensitive device in a quiet location. WIMPs are supposed to be flying around in the halo of our galaxy with the typical speed of 220 km/sec. Because they are only very weakly interacting, they can go through walls, rocks, even the entire Earth with little trouble, just like neutrinos. For WIMPs with mass of 100 GeV, the typical kinetic energy is approximately 50 keV. If the WIMP ever scatters off an atomic nucleus, the energy deposit is only at most of this order of magnitude. It is a tiny energy deposit that is very difficult to pick out against background from natural radioactivity (typically MeV energies). Therefore you have to make the device very clean, and also place it deep underground to be shielded from cosmic-ray induced backgrounds.

The local halo density is estimated to be around 0.3 GeV/cm$a^3$. The number density of WIMPs is. The flux of WIMPs is.

Indirect Detection Experiments
On the experimental side, there are other possible ways of detecting signals of dark matter beyond the underground direct detection experiments and collider searches. There are indirect detection experiments, namely they try to detect annihilation products of dark matter. For annihilation to occur, you need some level of accumulation of dark matter. The possible sites are galactic cents,r galactic halo, and center of the sum.

At present there is no clear evidence for any of these particles, thus it is worthwhile investigating all dark matter candidates. Moreover, dark matter could be formed from any or all of these particles. This work focuses on a dark matter axion-like particle search.  The search done as part of the Yale Microwave Cavity Experiment (YMCE) looked for dark matter pseudoscalars that couple to two photons, also known as axion-like particles (ALPs). This project is part of YMCE's work in constraining exotic particles in the 140 $\mu$eV mass region using cryogenically cooled microwave cavities, with previous projects being a search for dark matter scalars, and one looking for photon regeneration due to hidden photons. This mass region is so far unexplored by other microwave cavity experiments, as it is more challenging to reach the sensitivities needed to detect the canonical axion.
%Starting from the assumption that dark matter is a particle, people look for heavy, stable, neutral particles, known by the acronym Weakly Interacting Massive Particles (WIMPs), under which the SUSY candidate falls. People also look for the WISPs. There are direct and indirect detection searches going on for both candidates. For WIMPS, direct searches look for WIMP to strike a nucleus, causing it to recoil. The indirect searches assume that WIMPs annihilate with each other, being their own antiparticle, and look for signatures of these events in the galaxy.

%For WISPs, direct searches primarily use the ALP to two photon vertex, as it is easy to produce large electromagnetic fields in the laboratory and easy to detect photons. Searches assuming that the ALP is the dark matter are only using microwave cavities as resonant detectors \cite{admx10} although a Rydberg atom detection experiment was performed \cite{yamamoto00}. These experiments depend on the dark matter density at Earth. There are also new ideas involving the axion as inducing an oscillating electron dipole moment in nucleons \cite{budker13}, which will be sensitive to  ALPs of a different mass than those in the microwave cavity experiments. There are other experiments looking for axion-like particles, although they do not use dark matter as the source of the WISPs. These involve looking for axions produced in the sun (CAST) \cite{cast11} or directly producing axions from the two photon vertex using a laser and strong magnetic field (ALPS-I, ALPS-II) \cite{ehret10}. The direct production or light-shining-through-wall experiments has the least number of assumptions, but these experiments (solar, microwave cavity, lsw) together form a complementary way of searching for ALPs with the two-photon vertex.
%
%There are also astrophysical arguments that can limit the coupling of the axion to the two photon vertex. The ALP, produced by various processes in red giants, neutron stars, and white dwarfs, would radiate energy from the star, altering the stellar evolution and thus stellar lifetime \cite{turner89}. By observing stellar lifetime consistent with 10$\%$, constraints on the axion coupling can be derived\cite{raffelt95}. A strong limit comes from the observation of neutrinos from the supernova explosion of SN1987A. The observation of neutrinos number and duration consistent with expectations limits the role of axions in acting as a energy loss channel. The limit is on the axion to nucelon coupling, but can be related to the axion to two photon coupling.

This dissertation will focus on a direct search for dark matter axions using microwave cavities as resonant detectors over the frequency range 33.9 to 34.5 GHz.

\section{Outline}

This dissertation will describe the pilot run of the Yale Microwave Cavity Experiment (YMCE) to look for dark matter ALPs in the mass range 140.2-142.7 $\mu$eV. The run set limits on the ALP-two photon coupling with sensitivity slightly better than the best previous limit set by CAST. The experiment used a microwave cavity that was tuned, immersed in a strong magnetic field - over the cavity bandwidth we would be sensitive to photons whose energy is equal to the incoming dark matter axion energy.  From the data taken, the analysis excludes axion-like particles with two-photon coupling $g_{a\gamma\gamma} < 8.6$ $1/GeV$. We end by suggesting future directions for the experiment.
The outline of the dissertation will be as follows:

\textbf{Chapter 2: Background} describes the mechanism by which these light ALPs can have the relic abundance today to match dark matter abundances observed, as well as briefly describing the specific symmetry breaking mechanism by which the axion comes about to solve the strong CP problem.

\textbf{Chapter 3: Parameter Space} goes over the current bounds on axion coupling and mass, and where microwave cavity searches fit into this field.

\textbf{Chapter 4: Signal Power} Explains the sensitivity we can achieve using microwave cavities in strong magnetic fields, and how the expression for signal power determines what we optimize in the experiment

\textbf{Chapter 5: Experiment} goes through the components of the experiment, design of the microwave cavity, and construction of the receiver. We also go through the data taking process and summary of data taken.

\textbf{Chapter 6: Data Analysis} puts down the analysis chain that takes the raw time domain voltage measurements and turns them into average power spectra. 

\textbf{Chapter 7: Results} We present the upper bound on the ALP to two photon coupling for the mass range investigated.

\textbf{Chapter 8: Future Work} we conclude by an outlook for future work on YMCE.

\chapter{Background}

This thesis describes the YMCE dark matter axion search: the design of the cavity, operation of the experiment, and measurements taken. The remainder of this chapter discusses the motivation for axions (and ALPs) in more detail. 
%Chapter 2 describes the technique of using microwave cavities, while Chapter 3 provides some background on astrophysics and cosmology necessary for understanding the current parameter space. Chapter 4 describes the experiment, while Chapters 5, 6, and 7 focus on the microwave cavity design and data analysis, which I worked on. This includes simulations of the cavity coupling and its form factor, tuning, and Q response at cryogenic temperatures (Chapter 5), the construction of a data analysis pipeline and determining an exclusion limit (Chapter 6), and work on the hardware automation for the experiment (Chapter 7).
%
%We briefly review motivations for the axion and axion-like particles (ALPs) as a dark matter candidate. 
For a more comprehensive discussion see \cite{hewett12}, \cite{arias12}, and \cite{kim87}. 

\section{Strong CP Problem}

%taken from Raffelt's Stars as Laboratories
%The idea of axions is introduced and their phenomenological properties are reviewed. The constraints on pseudo scalars that have been derived throughout this book are systematically applied to axions.
%
%All fermions, with the possible exception of neutrinos, have magnetic dipole moments. The minimial electromagnetic coupling of charged spin-1/2 fermions (charge q, mass m) automatically yields a Dirac moment q/2m. Higher-order amplitudes lead to an additional anomalous contribution, which is the only one for neutral particles. The QED prediction of the electron anomalous magnetic moment is perhaps the most stunning quantitative success of theoretical physics.
%
%On the other hand, no particle electric dipole moment has ever been detected. At first this is quite satisfying because an electric dipole moment would allow one to distinguish between matter and antimatter in an absolute sense. (In the non relativistic limit the electric dipole operator d must be proportional to the spin operator s which is an axial vector. Because the electric field is a polar vector the energy dE reverses sign under P and thus under CP whence its absolute sign yield an absolute distinction between fermions and antifermions.) The electroweak and strong gauge interactions are CP-conserving, so the observed broad symmetry between particles and antiparticles appears natural.
%
%This symmetry is not respected, however, by the generally complex  Yukawa couplings to the Higgs field which are thought to induce the fermion masses. The resulting complex quark mass matrix Mq can be made real and diagonal by suitable transformations of the quark fields. THis involves a global chiral phase transformation (angle theta = arg get Mq) leading to a termini the QCD lagrangian L = theta alphas over 8pi G Gdual.
%
%Here alphas is the fine structure constant of strong interactions and GGdual is defined as GbmunuGbmunu where Gbmunu is the color field strength tensor Gdual bmunu = one half epsilon Gbu rho sigma its dual, and the implied summation over b refers  to the color degrees of freedom. Of course get Mq  and thus theta would vanish if one of the quarks were exactly massless, but this does not seem to be the case.
%
%Under the combined action of charge conjugation © and a parity transformation ? the Lagrangian ref eq changes sign (the structure of G dual G is Ecolor dot Bcolor, i.e. the scalar product of a polar with an axial vector and so it is CP odd), violating the CP invariance of QCD. It leads to a neutron electric dipole moment abs dn approx abs theta 0.04-2 times 10 to -15 e cm Baluni 1979 Crewther 1979 This is dn approx theta 0.004-2 mu n in units of nuclear magnetons. Hence for theta of order unity one expects a neutron electric dipole moment almost as large as its magnetic one. The experimental limit, however, indicates theta less ten to the minus ten, surprisingly small in view of the phase delta equals three to the -3 which appears in the Cabbibo-Kobayashi-Maskawa matrix ref eq and which explains the observed CP violating effects in the K0 bar K0 system.
%
%Even worse, QCD alone produces a term like ref eq because of the nontrivial topological structure of its ground state (Callen, Dashen Gross 76, Jackiw Rebbi 76, tHooft 76). The coefficient theta bcd is a parameter characterizing the theta vacuum. It is mapped onto itself by a transformation under two pi so that different ground states are characterized by values in the range 9 to 2pi.
%
%The phase of the quark mass matrix and the QCD vacuum together yield theta bar as a compound coefficient for ref eq. The experimental bounds then translate into they bar less ten t0 the minus ten.
%
%THe CP problem of strong interactions consists of the smallness of theta bar whic implies that the numbers theta bcd and arg get Mq are either separately very small or cancel each other with very high accuracy. However bot hare expected to be of order unity, or perhaps of order delta in the case of arg get Mq and completely unrelated to each other.

%The motivation for the canonical axion, or QCD axion, arises from an attempt to explain what is known as the strong CP problem. 
CP symmetry, or charge parity symmetry, refers to the symmetry of physical equations under reversal of spatial reflection and charge conjugation.  When CP violation occurs,  it is manifested as a visible distinction between particles and antiparticles \cite{gottfried86}. The electroweak interaction violates CP symmetry, as observed in neutral kaon systems \cite{christenson64}, however there is no evidence for strong interaction processes which violate CP. This is odd, as there is a term in the QCD Lagrangian that is explicitly P- and T- violating:
\begin{align}
\mathcal{L} = \bar \theta \frac{\alpha_s}{4\pi} G \tilde G
\end{align}

where $\bar \theta$ is a phase between $0$ and $2\pi$, $G$ is the gluon field tensor and $\tilde G$ is the dual, or $G_{ab} = \epsilon-{abcd} G^{cd}$. To see that it is parity and time violating, construct the color electric and magnetic field equivalents from the tensor: for the electromagnetic field tensor $FF = E^2 -B^2$ and $F\tilde F = E\cdot B$. Therefore for the gluon field tensor, $G\tilde G = E_a \cdot B_a$. Under a parity transformation ($x \rightarrow -x$), $E \rightarrow E$ and $B \rightarrow -B$. Under a time transformation, $
E \rightarrow E$ and $B \rightarrow -B$.  Therefore the product $E\dot B$ is not symmetric under parity and time reversal. By the CPT theorem, T-violation is equivalent to CP-violation.

We note that the reason the equivalent CP violating term in QED does not arise ($F\tilde F$) is because it is a total four-divergence. This means, for fields that are vanishing small as you approach spatial infinity, that the term goes to zero when integrating the Lagrangian. Because the gluon fields are self-interacting the term $G \tilde G$ is not zero as you go to infinity, and so the four divergence has a finite effect.

This CP violating term should induce observable effects, such as a permanent neutron electric dipole moment \cite{baluni79}. An observation of a permanent electric dipole moment for any particle would be a major achievement, as no particle has yet been observed to have such a permanent electric dipole moment, although all fermions have magnetic dipole moments. However measurements of the neutron EDM $d_n$place upper bounds  at the level $d_n < 2.9 \times10^{-26}$ e$\cdot$cm\cite{baker06}, placing an upper bound on the QCD phase of $\bar \theta < 10^{-10}$ .

The P, T violating phase $\bar \theta$ can be set to zero, however this constitutes a fine tuning problem as $\bar \theta$ is the sum of two independent terms from two different sectors, which should be independent:
\begin{align}
\bar \theta = \theta_{QCD} + \text{arg det} \mathcal{M}
\end{align}
$\theta_{QCD}$ is a phase that comes from strong interaction physics; it can be thought of as the term characterizing the ground state of the QCD vacuum, which is a superposition of various vacua connected by tunneling events called instantons. A

%ny non-Abelian field may have such a non-trivial vacuum structure; the evidence for  QCD having a non-trivial vacua comes from of such a vacua solves the $U(1)_A$ problem, which is the question of why the $\eta'$ is not degenerate with the pion mass \cite{thooft76}. The problem is a question of symmetry breaking - [NEEDSEXPLANATION]. 

$\mathcal{M}$ is the quark mass matrix: $\text{arg det} \mathcal{M} = m_um_dm_s$ the product of the quark masses when real. If there is a massless quark, the value above is undefined and $\bar \theta$ is also undefined. However, we believe there is evidence that the lightest quark, the up, is not massless and has mass between 0.3-0.7 MeV [NEEDSREF].

 The fine tuning problem, or strong-CP problem, of why $\bar \theta$ is less than a billionth of a radian when there is no reason to believe it should be so small, can be solved by introducing a new global, chiral symmetry, as proposed by Peccei and Quinn in 1977 \cite{peccei77}. The spontaneous breaking of this symmetry at some energy scale $f_a$ introduces the axion as the resulting massless Goldstone boson of the symmetry. Due to a chiral anomaly with QCD, the axion experiences a potential, which causes it to acquire a mass proportional to the energy scale of QCD, $\Lambda_{QCD}$ and inversely proportional to the energy scale of the symmetry breaking $f_a$ \cite{weinberg78}, \cite{wilczek78}. 
 
% The role of anomalies is widespread in physics; a chiral anomaly with electromagnetic fields solves the $U(1)_A$ problem, which is the question of why the $\eta'$ is not degenerate with the pion mass. It is due to anomalies that this occurs. For more comprehensive treatment of anomalies, see \cite{bardeen07}, \cite{peskin95}. 
 
 The axion coupling constant to matter ends up also being inversely proportional to $f_a$, so the mass and coupling constant of the axion are directly proportional to each other. The axion coupling to gluons implies a generic coupling to photons, through mixing with the pion; although there is some model dependence for the coupling and it can be set to zero, this represents another fine tuning problem.

%[NEEDSPIC] of axion to gluon coupling, axion to pion coupling

The term axion-like particles (ALPs) describes pseudoscalar bosons that, like the axion, have a coupling with two gluons and thus have a two photon vertex; however, these general ALP models do not necessarily arise from anomalous interactions with QCD. Familons and majorons are two such examples of ALPs \cite{kim87}, but they arise generically in string theories  and extensions to the standard model,\cite{masso06}, \cite{hewett12}, \cite{arias12} as the mechanism of an additional U(1) symmetry is a minimal extension, and anomalies must often take place to cancel divergences. For these more general axion-like models, the coupling and mass are no longer proportional, so there are two free parameters to the theory. However the techniques used to search for axions also apply to ALPs, with experimental and theoretical bounds applying to both as well. From here on out, I use the term axion and ALP interchangeably to refer to any general pseudoscalar with a coupling to two photons. 

%However, the idea of a light, spinless, neutral, pseudoscalar boson with a two photon vertex is common to both axions and ALPs.

%The axion is also a strongly motivated cold dark matter candidate. The axion, as described above, arises from the symmetry breaking of a symmetry introduced to solve the strong CP problem by dynamically tending the P and T violating term in QCD to zero. The axion, due to astrophysical and laboratory constraints, would need to be less than approximately 1 meV; in the models of the axion, it's coupling is related to the mass, so these light axions have extremely feeble couplings to matter, making them good dark matter candidates. They can be produced thermally, making them hot dark matter candidates, or non-thermally, either through the vacuum misalignment mechanism [NEEDSREF], through cosmic strings [NEEDSREF], or topological defects [NEEDSREF].
%
%The argument for non-relativistic matter today usually relies on thermalization arguments; which imply that the heavier the matter, the cooler, or more non-relativistic it is today. However, there are other mechanisms by which very light particles could be produced in the early universe such that they are non-relativistic today.

\section{Peccei Quinn Mechanism}
%from Raffelt's Stars as Laboratories
%
%An attempt to explain the smallness of theta bar may be overambitious as long as we do not have an understanding of the origin of the Yukawa couplings that went into Mq and of the other seemingly arbitrary parameters of the standard model. Still, whatever determines these constants of nature, the strong CP problem can be elegantly explained by the existence of a new physical field, the axion field, which allows theta bar to vanish dynamically. In this scheme, the CP violating Lagrangian is literally switched off by its own force.
%
%To this end the new field a(x) must be a pseudo scalar which couples to gluons according to ref eq with theta replaced by -a/fa. The constant  with the dimension of an energy is the Pecci Quinn scale or axion decay constant. Axions must be fundamentally massless so that  all observable effects remain unchanged under a global shift a(x) -> a(x) + a0 (a mass term m_a^2a^2 would spoil this possibility). This invariance allows one to absorb theta bar in the definition of the axion field. Including a kinetic term, ref eq is replaced by 
%
%La -> La = 1/2(dmu a)^2 - alpha s/ 8 pi fa a G tilde G
%
%It conserves CP because axions were assumed to be pesudoscalar (odd under CP) similar to neutral pions.
%
%Even though axions were constructed to be massless they acquire an effective mass by their interactions with gluons. It induces transitions to q q bar states and thus to neutral pions Fig 14.1 which means physically that a and pi 0 mix with each other. Axions thereby pick up a small mass which is approximately given by ma fa approx mp dpi, where mph = 135 MeV is the pion mass and f pi approx 93 MeV its decay constant. This mass term implies that at low energies the axion Lagrangian contains a potential V(a) which expands to lowest order as 1/2 m_a^2 a^2. Because of the invariance of L theta with respect to theta + 2pi, the gluon induced potential V(a) is a function periodic with 2 pi fa.
%
%The ground state of the axion field is a the minimum of its potential at a= 0, explaining the absence of a neutron electric dipole moment. If one could produce a static non vanishing axion field a0 in some region of space, neutrons there would exhibit an electric dipole moment corresponding to theta bar = - a0/fa.
%
%The Lagrangian ref eq is the minimal ingredient for any axion model, the aGGdual coupling is their defining feature as opposed to other pseudo scalar energies. Then axions inevitabley acquire an effective mass at low energies.
%
%Because of their mixing with pi 0, axions share not only their mass, but also their couplings with photons and nucleons with a strength reduced by about dpi/fa. Therefore they generically couple to photons.
%
%The effective axion mass is a low energy phenomenon below lambda qcd. Above this energy pions and other hadrons dissociate in favor of a quark gluon plasma. Then a = 0 is o longer singled out so that any value in the interval 0 < a < 2pi f_a is physically equivalent.
%
%Axions as Nambu-Goldstone Bosons
%The invariance of Ltheta against transformations of the form theta -> theta+2pi and the corresponding invariance ft he axion Lagrangian against transformations a -> a + 2pif_a calls for a very simple interpretation of the axion field as the phase of a new scalar field.
%
%
%A transparent illustration is provided by the KSVZ axion model where one introduces a new complex scalar field which does not participate in the weak interactions, i.e. an SU(2)xU(1) singlet. There is also a new massless fermion field phi and one considers a Lagrangian with the usual kinetic terms, a potential V for the scalar field, and an interaction term.
%
%The Yukawa coupling is chosen to be positive and .. are the usual left and right handed projections.
%
%This Lagraingian is invariant under a chiral phase transformation of the form; this chiral symmetry is usually referred to as the PQ symmetry.
%
%The potential V is chosen to be a Mexican hat with an absolute minimum at phi = f_a/\sqrt{2} where f pq is some large energy scale. The ground state is characterized by a nonvansihing dev. It spontaneously breaks PQ symmetry because it is not invariant under a transformation of the type. One may then write in terms of two real files rho and a which represent the radial and angular excitations.
%
%The potential V provides a large mass for rho, a field which will be of no further interest for these low energy considerations. Neglecting all terms involving rho in the lagrangian. The variation of the fermion fields under a PQ transformation is given by ref eq while a goes to a + alpha f. The invariance of ref eq against such shifts is a manifestation of the Upq1 symmetry. It implies that a represents a massless particle, the Nambu Goldstone boson of the PQ symmetry. Expanding the last term in powers of a/fpq the zeroth order term m phi phi pal ays the role of an effective fermion mass. Higher orders describe the interaction of a with phi. The dimensionless Yukawa coupling ga m/fpq is proportional to the fermion mass.
%
%The fermion is taken to be some exotic heavy quark with the usual strong interactions some SUc(3) triplet. The lowest order interaction of a with gluons is then given by the triangle graph. Witth the first term of Eq it yields an effective a gluon interaction of . All external momenta were taken to be small relative tot the mass m of the loop fermion.
%
%In more general models, several conventional or exotic quark fields may participate in this scheme. The transformation of each field is characterized by its PQ charge Xj.
%The potential is periodic with 2pifa = 2pif_pq/N. The interpretation of a as the pause of phi on the other hand implies a periodicity with 2pif_pq so that N must be a nonzero integer
%
%To describe this mechanism we first have to describe the mechanism of symmetry breaking which gives rise to light particles. To do so, we will go through the process which gives rise to the canonical axion. This process was postulated by Peccei and Quinn in 1977 \cite{peccei77} as a natural way to produce CP conservation the theory of strong interactions, Quantum Chromodynamics. 

The Peccei-Quinn solution to the strong CP problem was to introduce a global chiral U(1) symmetry, denoted $U(1)_{PQ}$. This symmetry is spontaneously broken at some energy scale $f_a$, producing massless Goldstone bosons from the azimuthal degree of freedom (this is the axion), and some high energy mode from the radial degree of freedom; this was deemed to be the two Higgs doublets in the original theory, which sets the energy scale.  There are many models that construct other scalars as the radial mode, allowing the energy scale to decouple from the electroweak scale \cite{kim79} \cite{shifman80}, \cite{dine81}, \cite{zhitnisky80}.

The axion acquires mass through explicit symmetry breaking of the $U(1)_{PQ}$ symmetry with QCD. This occurs because of a chiral anomaly \cite{jackiw76}. In all respects this is analogous to the process by which the pion, the Goldstone boson of the axial $U(1)_A$ symmetry in QCD, acquires its mass through a chiral anomaly. The axion mass is proportional to the QCD scale: $m_a \sim \Lambda_{QCD}^2/f_a$. The axion coupling to matter is inversely proportional to the energy scale $f_a$ and thus proportional to the mass.

Using Higgs doublets would give one a rough prediction for the axion mass of 150 keV; this axion would have a lifetime of 1 microsecond and would have been detected in collider experiments through quarkonium decays and beam dump experiments \cite{crystalball90}. The branching ratios observed were significantly less than predicted; thus this axion was ruled out.

However, as stated above, the symmetry can come from other scalars; which would separate $f_a$ from the electroweak scale and let it be much higher, and so the axion coupling and mass would be much weaker. In 1983 Pierre Sikivie proposed using the axion to two photon coupling \cite{sikivie83} to search for axions, and proposed that axions would make good dark matter candidates. This interaction can be written as $E \cdot B$. With strong magnetic fields, the axion to two photon transition is made much stronger.

%Note, I say axion here, but these searches apply for axion-like particles in general. The only difference is that axion-like particles do not have the relationship between coupling and mass, so there are two free parameters in the theory.

In order for ALPs to be good dark matter candidates, they must have the correct abundance. We now go over how ALPs could be produced in the early universe such as to have the correct density today.

\section{QCD Axion Models}

Currently this follows the discussion as in  \cite{hagmann90}.

The first model of the axion came from introducing the new symmetry through two Higgs doublets, as proposed by Peccei and Quinn. The two doublets, $\lambda_1$ and $\lambda_2$ combine to have a non-zero vacuum expectation value. The phase of the vacuum expectation value is the axion; by current algebra techniques that mass of the axion can be computed to be 

\begin{align*}
m_a = \frac{Nm_\pi f_\pi}{v_F}\frac{\sqrt{z}}{1+z}(\frac{1}{x}+x) = (23 \text{keV})(\frac{1}{x}+x)
\end{align*}

for $ x = <\lambda_1>/<\lambda_2>$ is the ratio of the vacuum expectation values of the doublets and $z = m_u/m_d$ is the ratio of the up and down quark masses.

This Peccei-Quinn-Weinberg-Wilczek axion was predicted to have a mass of some keV, but was ruled out in reactor and accelerator experiments \cite{crystalball90}.

%Simple extensions to the Peccei Quinn mechanism modified the energy scale of the symmetry breaking, decoupling it from the electroweweak scale, and allowing the axion mass to be much lighter. 
The Dine, Fischler, Srednicki, Zhitniskii model (DFSZ) \cite{dine81},\cite{zhitnisky80}, adds a single heavy scalar in addition to the Higgs doublets introduced before. 

The mass of the axion is then calculated to be:

\begin{align*}
m_a = \frac{f_\pi}{f_a} m_\pi N \frac{\sqrt{z}}{1+z}
\end{align*}

For $z= 0.56$, $f_\pi = 93 \text{ MeV}$, and $m_\pi = 135\text{ MeV}$, $m_a \approx \frac{10^7\text{GeV}}{f_a}eV$.

Another model, the Kim, Vainshtein, Shiman, Zakharov model \cite{kim79},\cite{shifman80}, extends the Peccei Quinn mechanism by introducing a new heavy quark and complex scalar field, as well as a discrete symmetry. The axion then couples directly to this heavy quark and through the quark, to ordinary matter. The axion mass is then:

\begin{align*}
m_a = \frac{\sqrt{z}}{1+z}m_\pi\frac{f_\pi}{f_a}
\end{align*}

and the coupling to two photons is:

\begin{align*}
g_{a\gamma\gamma}^{KSVZ} &= \frac{\alpha}{2\pi f_a}(\frac{E}{N}-\frac{2}{3}\frac{4+z}{1+z}) 
\\ &= 1.93\times10^{-15}\text{GeV}^{-1}(\frac{E}{N}-\frac{2}{3}\frac{4+z}{1+z})(\frac{m_a}{10^{-5}\text{eV}})
\end{align*}

In conclusion, for the two photon interaction for which $\mathcal{L} = g_{a\gamma\gamma}E\dot B a$, the coupling is

\begin{align*}
g_{a\gamma\gamma} &= -\frac{3\alpha}{8\pi f_a}\xi = - \frac{m_a/\text{eV}}{0.69\times10^{10}\text{ GeV}}\xi 
\\ \xi &= \frac{4}{3}(\frac{E}{N} - 1.92 \pm 0.08)
\end{align*}

$E/N$ is the ratio of the color to electromagnetic anomalies. For the DFSZ mode it is 8/3, for the KVSZ model it is 0. It cannot be guaranteed that $E/N$ does not equal 2, however, in which case the coupling to photons would be severely suppressed.

\section{Non-Thermal Production of Dark Matter}
\subsection{Misalignment Mechanism}

So far we have explained how axions in particular can be produced as the result of a new symmetry having an anomaly with QCD. Now let us consider what happens during the evolution of the axion. The potential that the axion feels is a function both of $\theta$ and T, the temperature. 
%
%\begin{figure}
%\includegraphics[width=0.6\textwidth]{vthetavstheta}
%\end{figure}
%
%
%\begin{figure}
%\includegraphics[width=0.6\textwidth]{axionpotential}
%\caption{From \cite{kim95}; shows how slight the axion potential is.}
%\end{figure}

%Imagine this potential being stretched out in space, as is happening through the expansion of the universe. When the expansion slows down sufficiently so that $H \sim m_a$, the axion begins to oscillate. Because the lifetime of the axion is longer than the age of the universe, the oscillations do not die out, but the amplitude of the oscillations is decreased by the expansion of the universe. Discussion taken from Kim's "Axionic Extensions of the Standard Model".

In the early universe, $T \gg GeV$ the axion potential looks so flat that it cannot tell where the minimum is. This is especially true for the axion because its mass originate from QCD instant effects which are suppressed by powers of the temperature in a hot thermal bath. Therefore we expect it starts out wherever it finds itself. The likely initial misplacement is of the order of $f_A$. Now we would like to know what happens afterwards.

Let us consider a scalar field in an expanding universe. Neglecting the spatial variation  and considering the time dependence alone, the equation of motion is . For a quadratic potential the equation is particularly simple and homogeneous.

For later universe it oscillates as a usual harmonic oscillator and dilutes as non-relativistic matter. This is why a very light scalar field can be a candidate for cold dark matter. This way of producing cold dark matter is called "misalignment production" because it is due to the initial misalignment of the axion field relative to the potential minimum. Because the amount of misalignment is not know, we cannot predict the abundance of the axion precisely. Assuming a misalignment of order O(f), $f_a \approx 10^12$ GeV is the preferred range for axion dark matter.

[NEEDSALOTOFWORK]

For a real scalar field that is spatially homogeneous ($\partial_i \phi = 0$), its equation of motion in
the Robertson-Walker metric is 

\begin{align}
\ddot \phi + 3 H \dot \phi + V'(\phi) = 0
\end{align}

The potential for the QCD axion is temperature dependent. For $ H > m_\phi$ the field will be over damped and $\phi = \phi_0$ will stay at its initial value. The total energy density in the field is the potential energy $\frac{1}{2} m_\phi \phi_0^2$. When the temperature decreases, the Hubble parameter will become less than $m_\phi$; this happens when $T \approx (m_\phi M_{pl})^2$. After this point the field begins to oscillate in the potential and the total energy will be a combination of potential and kinetic energy. The kinetic energy will redshift like matter as $\rho_\phi \propto a^{-3}$.

Therefore $\rho_\phi(a) = \frac{1}{2}m_\phi \phi_0^2 \big(\frac{a_0}{a}\big)^3$

which leads to a density parameter today of $\Omega_{0, \phi} \approx \big(\frac{\phi_0^4 m_\phi}{10^{-19}\text{ GeV}^5}\big)^{1/2}$

For QCD axions with $\phi_0 = <\phi> \approx f_a$ and $m_a \approx \Lambda_{QCD} / f_a$, with $\Lambda_{QCD} \approx 0.3$ GeV, 
the density parameter is

\begin{equation}\label{eq:density}
\Omega_{0, \phi} \approx \big(\frac{f_a}{106{13}\text{ GeV}}\big)^{1/2}
\end{equation}

The axion potential is typically parameterized as $V(\phi) = m_\phi^2f_\phi^2(1-cos \frac{\phi}{f_\phi})$ disregarding temperature effects.


\subsection{Cosmic Strings}
If the "turn on" temperature happens after inflation, the scenario is different. The Higgs field $\sigma = f_a e^{i\phi/f_a}$ will acquire random angles in causally unconnected regions of space-time. Then the present universe originated from many regions with initially uncorrelated $<\phi>$.

Since $\sigma$ is single-valued, the total change in phase around any closed path must be 

$\Delta \theta = 2 \pi n$,

where n is an integer, called the winding number. For  $n >0$, it is not possible to shrink the loop radius to zero without encountering a singularity where the Higgs field vanishes. The resulting tubes of false vacuum are called strings.

Strings with $ n \neq \pm 1$ are unstable and decay into elementary ones. As the universe expands the string network starts to oscillate, causing the emission of axions.
A different explanation by Nelson:

Spatially varying modes of a bosonic field will be smoothed by the expansion of the universe. However the zero momentum component of the scalar field A n the FRW background has the equation of motion xxx which is reminiscent of a harmonic oscillator, with a time dependent damping term H(t). in the early univse, the scalar is effectively massless and its Compton wavelength does not fit into the horizon. The filed is stuck; it does not go through a single oscillation and therefore we observe no particles. The value of the field is assumed to take on some random nonzero value, because when the mass term is negligible there is no reason to prefer a field value of $\phi^{\mu} = 0$. An episode of inflation will generally produce a spatially uniform filed, fbut for large H in any causally connected patch of the universe the mean value of the field takes on some random non zero field. After inflation, the Hubble constant begins to decrease. As soon as the field begins to oscillate we can quantize the different modes and call them particles. We are left with an endrgy density which mmay be thought of as a coherent state of a macroscopic number of particles. An adiabatic perturbation spectrum arising from the fluctuations of the inflation field will imprint adiabatic spatial variations on the density of the scalar particle, as is needed to fit the WMAP data. Note that inflation will produce isocurvature perturbations arising from fluctuations of the scalar field A. Such perturbations are highly constrained, and will place an m dependent upper bound on the inflation scale.

For a light massive vector in a FRW universe, the equation of motion is $\partial_\mu (\phi^{\mu\nu}\sqrt{-g}) = M^2 \phi^\mu \sqrt{-g}$. As inflation blows up a small patch of space, the dark photon is uniformly distributed and picks a particular polarization. Then in the cosmic frame $\partial_i \phi^\mu = 0$, and from the previous equation $\phi_0 = 0$ as long as M is not 0. The spatial component satisfies the damped Harmonic oscillator equation, so each spatial component satisfies the same equations of motion as the scalar field previously.

Crucial to this argument is that the vector boson obtains its mass from the Stuckelberg mechanism. If it gained its mass via a Higgs mechanism, so that it would be massless above $T^2 \approx m^2/g^2$

In order to ensure the heavy photon remains non relativistic, the interaction processes that lead to thermalization must be small. These are Compton scattering $\phi e \rightarrow \phi e$ (suppressed by a factor $\chi^2$) and Compton-like scattering $\phi e \rightarrow \gamma e$.

\section{Hidden Photons as Dark Matter}

Light vector bosons may also constitute the cold dark matter of our universe; if they kinetically mix with photons they can also be detected with the same experimental setup that aims to detect ALPs. There is no lower bound on this kinetic mixing coupling, however upper bounds can be placed with a null observation.

For this spin one boson to be cold dark matter, it must be feebly interacting, have a long lifetime, and be produced in such a way that at present it is non relativistic. These conditions can be satisfied for particle with mass created from the Stuckelberg mechanism, and using the misalignment mechanism to create hidden photons, as observed in \cite{nelson11}.

The argument is the following:

Take  the Lagrangian for a vector particle that interacts with the electromagnetic field in a renormalziable way"

\begin{align}
L = \frac{1}{4}(F^{\mu\nu} F_{\mu\nu}  + \phi_{\mu\nu} \phi^{\mu\nu}  + 2\chi \phi^{\mu\nu} F_{\mu\nu} ) + \frac{M^2}{2}\phi^{\mu\nu}\phi_{\mu\nu} + J_\mu A^\mu
\end{align}

where $A^\mu$ is the field strength of the photon, $F_{\mu\nu}$ is the field tensor,  $J^\mu$ is the current, and $\phi^{\mu\nu} = \partial^{mu}\phi^\nu - \partial^\nu\phi^\mu$. With a non-unitary transformation $A \rightarrow A - \chi\phi$ $\phi \rightarrow \phi + O(\chi^2)$ we can redefine the fields as a massless and heavy photon:

\begin{align}
L = \frac{1}{4}(F^{\mu\nu} F_{\mu\nu}  + \phi_{\mu\nu} \phi^{\mu\nu} ) + \frac{M^2}{2}\phi^{\mu\nu}\phi_{\mu\nu} + J_\mu(A^\mu - \chi \phi^\mu)
\end{align}

In this basis the heavy photon couples to the electromagnetic current with the coupling constant scaled by $\chi$.

%We have covered how, by the addition of a global symmetry that has explicit symmetry breaking at some high energy scale, a low mass boson can arise. The mass of this particle will "turn on" when the energy scale at which the symmetry breaking occurs is matched in the energy scale of the universe (or more commonly described, the temperature). If we think of the initial 2$\pi$ degrees of freedom of the azimuthal mode, a simple picture would be of the tipping of the $\phi^4$ potential, or the wine bottle potential, leading to the angle to settle at one particular value. As the angle $\theta$ must approach its minimum, there will be oscillations around that point. These oscillations will be affected by the expansion of the universe; one can write a damped harmonic oscilllator equation of motion [NEEDSREF] where H is the hubble parameter.
%
%\begin{align}
%\ddot \bar{\theta} + 3H(t)\dot \bar{\theta} + m_a^2\sin(\bar{ \theta}) = 0
%\end{align}
%
%As long as $\theta$ is not too small, these damped oscillations will result in a present day energy density roughly equal to the dark matter density we observe \cite{turner89}.
%
%\begin{figure}[htbp]
%\includegraphics[width=0.7\textwidth]{differentpotentials}
%\caption{From \cite{hagmann90}. The shape of the potential for different temperatures.}
%\end{figure}
%
%The cosmological history is also affected by whether the mass is turned on before or after inflation.  If the axion acquires mass before inflation, then there is a uniform axion mass in our horizon; otherwise, there might be several causal patches with axion masses at different values, and we can only average over them to get a predicted value [NEEDSREF].



\chapter{Parameter Space}

QCD axions have mass and couplings to matter proportional to the energy scale $f_a$, so the mass and coupling are proportional to each other. In more general scenarios of axion-like particles that are not generated due to interactions with QCD, the mass and coupling are taken as independent parameters. This leaves a 2D parameter space of possibilities. However, astrophysical arguments have been crucial in constraining the possible parameter space for ALPs.

\section{Primakoff Effect}

Most experimental searches for axion-like particles use the Primakoff effect \cite{primakoff51}, which converts the axion to a photon in the presence of a strong magnetic field. The interaction arises from the axion to gluon coupling:
%
%We previously introduced the Primakoff effect [section 4.3]; this is the $a\gamma \rightarrow \gamma$ interaction that most axion experiments use and that is capitalized on in this work. 
\begin{align}
\mathcal{L} = \bar \theta g^2 G \tilde G = \frac{a}{f_a} g^2 G \tilde G
\end{align}

where $G$ is the color field tensor, $g$ is the coupling, and $\tilde G$ is the dual field tensor. This interaction, shown in Figure~\ref{fig:pionmixing}, is the result of the anomalous symmetry breaking with QCD - the triangle loop diagram shown in Figure~\ref{fig:triangleloop} shows the Yukawa coupling between the axion and the intermediate fermion which couples to the gluons. Either this fermion is a heavy quark (as in the KSVZ) model, or an ordinary fermion which carries PQ charge.

\begin{figure}[htbp]
\begin{subfigure}{0.95\textwidth}
\centering
\includegraphics[width=\textwidth]{axiontopionmixing}
\caption{Axion to pion mixing is a result of axion gluon coupling.}
\label{fig:pionmixing}
\end{subfigure}
\begin{subfigure}{0.95\textwidth}
\centering
\includegraphics[width=\textwidth]{axiontriangleloop}
\caption{The anomalous symmetry breaking results in a triangle loop diagram of axions to gluons.}
\label{fig:triangleloop}
\end{subfigure}
\caption{Feynman Diagrams of axion-gluon and axion-pion interactions; from \cite{vogel09}}
\end{figure}

The gluons can create quark-anti-quark pairs, with the pion being the lightest example. One can think of this axion-pion mixing as the effect that generates the axion mass. The pions can then decay into two photons via the Primakoff effect, which itself has a triangle loop anomaly, and this is how the axion interacts with two photons.

\section{Current Bounds on Axion-Photon Coupling }
%[ADD HIDDEN PHOTON BOUNDS]
This section discusses the constraints on the axion to two photon coupling and axion mass. Astrophysical observations provide stringent upper bounds on the axion coupling and mass; if axions are the dark matter, then cosmological arguments can provide a lower bound on the axion mass, although this bound does not hold if the Peccei Quinn symmetry breaking occurs before inflation. We also discuss laboratory searches, which look for axion to photon conversion using either intense photon sources, such as the sun or lasers,  or intense axion sources, such as the galactic halo, assuming axions form the dark matter of the universe. This thesis searches for dark matter axions from the galactic halo using microwave cavities.

\subsection{Astrophysical Constraints}

Various astrophysical limits basically require symmetry breaking scale $f_a > 10^{10}$ GeV, hence the axion is a very light boson. Most of these limits come from the fact that the axion can carry away energy from stars and would cool them too quickly.

The evolution of stars is limited by the rate at which they dissipate the energy created in fusion. This rate is set by the opacity of the stars; for many stars it takes $10^8$ years for photons produced in the core to escape from the star. If feebly interacting particles such as the axion are produced in the star, they will freely stream out and thus radiate away more energy, accelerating stellar evolution and shortening the star's lifetime.

By observing the statistical distribution of stars in globular clusters, we can infer the lifetimes of stars. They are consistent with our models of stellar lifetimes (without axions), so we can set a limit on the strength of axion coupling to matter by saying that the total energy loss (if there were axions) must be within the uncertainty of the observation. For different stars, different production mechanisms are dominant; in white dwarfs, nucleon bremmstrahlung predominates; in red giants, it is Compton-like processes \cite{raffelt08}.

The strongest limits come from horizontal branch stars, where Primakoff processes are strongest. These exclude axions with mass 1 eV and below for couplings greater than $g_{a\gamma\gamma} > 10^{-10} \text{ 1}/\text{GeV}$.

Another limit comes from the supernova SN1987A. Neutrinos provide the dominant source of cooling for supernovas. In less than a second, the supernova radiates all of its energy through neutrinos. If axions provide another cooling method, than we would see less neutrinos. Observations at Kamiokande observed nineteen neutrino events, consistent with expectations \cite{hirata87}. As the primary axion-matter interaction in supernova would be nucleon bremmstrahlung, one can exclude $g_{aNN} < 10^{-11}$ 1/GeV for axions of mass less than 2 eV \cite{mayle87}. One can convert this to a constraint on the coupling to two photons. The two most popular models are the DFSZ and KVSZ models, which we will now describe briefly.

Astrophysical arguments can constrain the axion mass severely. The requirement is that axions, which can produced in the cores of stars and act as an additional energy loss channel, have couplings lower than those which would produce a conflict with observation. The limits on the coupling strength to photons for globular clusters and the limit on the coupling strength to nucleons in the case of supernova SN1987A can be translated into limits on the axion mass of $m_a \leq 10^{-2} \text{eV}$ or $f_a \geq 10^9\text{GeV}$ \cite{raffelt08}.

Hidden Photons


%\section{Isocurvature Perturbations}
%Quantum fluctuations generated in the ALP field during inflation will produce inhomogeneities in $\phi_0$. As the field is essentially massless, this corresponds to isocurvature perturbations of the gravitational potential.

\subsection{Cosmological Constraints}

The abundance of dark matter axions in the universe today is given by Eq~\ref{eq:density} (see 5.2).

\begin{equation}\label{eq:newdensity}
\Omega_{0, \phi} \approx \big(\frac{f_a}{10^{13}\text{ GeV}}\big)^{1/2}
\end{equation}

For $f_a < 10^{14}$ GeV the dark matter abundance is greater than the critical density, so axions would ``overclose" the universe. This translates to a mass of $m_a = 10^{-6}$ eV. Together with the upper bounds from astrophysical limits, the axion mass is bounded by $10^{-6}  < m_a < 10^{-3}$ eV (Fig.~\ref{fig:onedex}). 

Much smaller masses are possible if inflation occurs after the axion mass turns on due to the explicit breaking of the symmetry. As well, if the initial value of $\bar \theta$ is much less than order unity, the mass of the axion can be smaller. Moreover, radiative decay from axion strings and domain wall decay can also be mechanisms for producing cold dark matter axions, although there is significant uncertainty in the predictions. For a review of axion cosmology, see \cite{sikivie06}.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.7\textwidth]{1dexclusionlimit}
\caption{Constraints on the axion mass (and thus energy scale) from \cite{raffelt08}. Striped lines are constraints; blank are projected constraints; and dotted are dependent on the cosmological history of the axion.}
\label{fig:onedex}
\end{figure}
%If cosmic inflation occurs before the axion mass ``turns on``, it is possible to create axions with a different abundance, and thus avoid the lower bound on the axion mass [NEEDSREF]. Thus proposed experiments to search for dark matter axions with nanoeV and picoeV masses are a completentary way to probe possible dark matter axion parameter space.

%Astrophysical arguments constrain a fair portion of the possible phase space; giving an upper bound on the axion mass of approximately 1 meV and an upper bound on the axion to photon coupling of $10^{-10}$ 1/GeV.
\section{Detection Strategies}
%For WISPs, direct searches primarily use the ALP to two photon vertex, as it is easy to produce large electromagnetic fields in the laboratory and easy to detect photons. Searches assuming that the ALP is the dark matter are only using microwave cavities as resonant detectors \cite{admx10} although a Rydberg atom detection experiment was performed \cite{yamamoto00}. These experiments depend on the dark matter density at Earth. There are also new ideas involving the axion as inducing an oscillating electron dipole moment in nucleons \cite{budker13}, which will be sensitive to  ALPs of a different mass than those in the microwave cavity experiments. There are other experiments looking for axion-like particles, although they do not use dark matter as the source of the WISPs. These involve looking for axions produced in the sun (CAST) \cite{cast11} or directly producing axions from the two photon vertex using a laser and strong magnetic field (ALPS-I, ALPS-II) \cite{ehret10}. The direct production or light-shining-through-wall experiments has the least number of assumptions, but these experiments (solar, microwave cavity, lsw) together form a complementary way of searching for ALPs with the two-photon vertex.
%\subsection{Direct Searches}

%Direct searches are those which attempt to directly detect signatures of axion interactions with matter in the laboratory. Most of these searches utilize the axion to two photon coupling. 
Methods to search for dark matter axions have been ongoing for the last four decades; however, since dark matter candidates by definition interact very feebly with ordinary matter, searching for any of these particles is experimentally challenging.  As this thesis is concerned with a dark matter axion search, I will briefly review the techniques used to search for axions. These include searches using the Primakoff effect: solar helioscopes, light-shining-through-wall (photon regeneration) experiments, and microwave cavity haloscopes. In addition there are non-Primakoff searches, looking for macroscopic forces or oscillating electric dipole moments.

%\begin{description}
\textbf{Solar Helioscopes}

This solar helioscope technique was originally proposed by Pierre Sikivie \cite{sikivie83}. This method searches for axions produced in the sun from the strong electric and magnetic fields in the plasma. By aiming a dipole magnet at the sun, the axions streaming from the sun can reconvert into photons (x-rays) for detection. This experiment has two processes of axion production and reconversion, so the sensitivity goes as $g^4B^2$. The CAST experiment as depicted in Fig~\ref{fig:cast} is the most sensitive of these helioscope experiments, and it has surpassed the astrophysical limits over a range $m_a < 2$ eV, with $g_a\gamma\gamma < 8.8 \times 10^{-11}$ 1/GeV \cite{cast11}. The axions detected in the CAST experiment are relativistic, and there is a large momentum mismatch between the massive axions and massless photons. The phase mismatch constrains the length scale over which the experiment can coherently convert axions, and therefore the sensitivity goes as $B^2L^2$, where $L$ is the length of the interaction region and $B$ the magnetic field. The limits set by helioscope experiments are broadband, as the axions produced in the sun have a broad range of energies.

%As \cite{raffelt08} notes, because the massive axions are converting to massless photons, there is a large momentum mismatch. The massive axion as momentum $k_a = (\omega^2 - m_a^2)^{1/2}$ while the photon has momentum $k_\gamma = \omega$. The difference is $q = k_\gamma - k_a \approx m_a^2/2\omega$ for $m_a \ll \omega$, so the length over which one can coherently detect a signal is limited, so conversion is a function of length.
\begin{figure}[htbp]
\includegraphics[width=\textwidth]{castprinciple}
\caption{CAST Experimental Setup \cite{fanourakis10}}
\label{fig:cast}
\end{figure}

The data from axion searches can also be used to set limits on hidden photons and the axion to electron coupling.

\textbf{Photon Regeneration/ Light Shining through the Wall}
\begin{figure}[htbp]
\centering
\includegraphics[width=0.55\textwidth]{alplsw}
\caption{Axion LSW experimental setup}
\label{fig:alplsw}
\end{figure}
Light shining through wall experiments use a laser (or microwave signal) as their photon source, unlike helioscopes which use the sun. Using the laser with a traverse magnetic field creates axions on one side of a wall; detection of photons on the other side of the wall would be a signal of axions traversing the wall and converting into photons (Fig~\ref{fig:alplsw}). Experiments with lasers \cite{ehret10}, \cite{sulc13}, \cite{chou07}, and microwaves \cite{betz13}, have placed bounds of $g < 3 \times 10^{-7} \text{ 1}/$GeV for the coupling of an axion like particle to two photons. These experiments use strong lasers or microwave sources to increase their sensitivity, and by placing resonant cavities on either side of the wall the sensitivity can be enhanced by a factor of each cavity's quality factor. These limits do not depend on assumptions about axion flux due to dark matter or solar processes. However, the dual conversion and reconversion effects makes these processes extremely weak and difficult to detect (sensitivity scales as $g^4B^4$), so the limits are well above the astrophysical bounds. 
%Another technique looks for axions produced by the Primakoff effect from photons and a magnetic field. The axions interact weakly with matter and thus pass through an opaque barrier that will stop photons. The axions reconverting back to photons in the strong magnetic field can be detected. These experiments use strong lasers or microwave sources to increase their sensitivity, and do not use the assumption of axion density due to dark matter. However, the dual conversion and reconversion effects makes these processes extremely weak and difficult to detect, so the limits are well above the astrophysical bounds. 
%These experiments are broadband except when using microwave cavities, and are limited only by phase mismatch which depends on the length of the interaction region. 
The LSW setup can be used to detect hidden photons (Fig~\ref{fig:lsw}). This experiment does not require a magnetic field. Currently LSW \cite{povey11}, \cite{betz13}, \cite{wagner10}, \cite{ehret10}, and helioscope experiments are the only laboratory searches for hidden photons.
\begin{figure}
\includegraphics[width=0.9\textwidth]{lsw}
\caption{Setup of Hidden photon LSW experiments.}
\label{fig:lsw}
\end{figure}

\textbf{Microwave Cavity Haloscopes}

Like the previous two methods, solar helioscopes and LSW experiments, microwave cavity haloscopes also use the Primakoff effect to detect axions. Dark matter axions have a narrow spread of energies around their rest energy, so the resulting photons must be detected using narrowband techniques in the microwave frequency band.
%The main distinction of the haloscope technique is that it looks for photons produced by dark matter axions. As dark matter axions would be non-relativistic, the produced photons would appear at one frequency, as opposed to the broadband searches of helioscope experiments. 
Pierre Sikivie first outlined the cosmic haloscope technique in 1983 \cite{sikivie85}. This process scales as $g^2B^2$.

Dark matter axions have energy given by $E_a = m_ac^2+\frac{1}{2}m_av^2$, with a small kinetic energy due to their virialized velocity $v_a \sim 10^{-3}c$. In the presence of a magnetic field the axion will convert to a photon with energy $\nu \approx m_a$. For $10^{-6} < m_a < 10^{-3}$ eV this will produce a microwave photon.
%If axions compose the cold dark matter of our galaxy, they will have an energy density with oscillations at the frequency $m_a$ with velocity dispersion most simply described as given by the virialized velocity $v \sim 10^{-3}c$. 
%The conversion of the axion to photon in the presence of the magnetic field will then deposit all of the axion energy into the photon, creating photons with frequency $\nu \sim m_a$. 
By having the conversion take place in a resonant cavity with a mode resonant at $m_a$, the signal will coherently build up by a factor of the cavity quality factor Q. 
%This technique of resonant detection, assuming a strong source of axions from dark matter, can achieve high sensitivities. This is the technique used in this thesis. 
The ADMX experiment \cite{admx10}  pioneered this technique and has excluded KVSZ axions for masses between 1.9 to 3.5 $\mu$eV. Upgrades are planned by ADMX to search for axions up to 80 $\mu$eV. This technique is also the basis of the Yale Microwave Cavity Experiment, which looks for axion dark matter from 140.2 to 142.7 $\mu$eV and is the subject of this thesis. A related experiment using Rydberg atoms to amplify the signal was carried out in the 1.9 to 2.8 $\mu$eV region, with an exclusion result similar to ADMX \cite{yamamoto00}.

%In the helioscopes the conversion was proportional to the length of the detector squared. For axion to photon transitions in the presence of a background magnetic field with high-Q cavities, the conversion probability depends on the overlap of the magnetic field and the electric field of the cavity mode, so thus the volume.
The data from this search can also be used to set limits on dark matter hidden photon coupling.

\textbf{Non-Primakoff Searches}
It is also possible for axions to mediate short range forces. Experiments have been made testing this hypothesis \cite{tullney13} and find no evidence for pseudoscalar forces as predicted by an axion. This experiment places upper bounds on the product of two coupling factors for a certain length range; it is not straightforward to compare this to the Primakoff effect experiments, but it seems that they also have no evidence.

A novel idea looking for oscillating electric dipole moments induced by dark matter axions \cite{budker13} would be sensitive to axions in the nanoeV range; this is still in the proposal stage.
\begin{figure}[htbp]
\centering
\includegraphics[width=0.9\textwidth]{2dexclusionplot}
\caption{Summary of the ALP and axion parameter space.}
\label{fig:2d}
\end{figure}
A summary of the parameter space and exclusion limits is shown in Fig~\ref{fig:2d}. In yellow are shown the axion model bounds. ADMX, in green, and their experimental limits begin to constrain the axion models. Helioscopes, led by CAST, and their limits are shown in blue; photon regeneration expts labeled as Lasers exclude the upper right region but do not assume anything about dark matter so are more rigorous. The dashed line labeled SN1987A is the exclusion on the axion mass extrapolated from the observation of neutrino events from SN1987A.

%The work in this thesis describes a search for dark matter axion-like particles, using a cryogenically cooled microwave cavity in a strong magnetic field. 
We now describe the expected sensitivity of a microwave cavity haloscope experiment with parameters for our experimental setup. 
%Vacuum Birefringence
%
%The axion community was sparked in large part by a report of an anomalous signal in a vacuum birefringence experiment by PVLAS \cite{zavattinni06}. This experiment looked at the slight change in polarization of a laser beam in a cavity immersed a strong transverse magnetic field, which could be do to some axions being made and thus altering the polarization. When the experimenters rebuilt the experiment to reproduce the signal, however, they were unable to see the anomaly. This anomaly would have predicted an axion with mass of around 1.2 meV and two-photon coupling of 
%$2.5\times10^{-6} \text{ GeV}^-1$. This patch was excluded by the BMV collaboration \cite{robilliard07}, and other photon regeneration experiments have pushed to higher laser output, and lower backgrounds to improve the sensitivity of the experiments.
%
%Rydberg Atoms
%An experiment using Rydberg atoms, CARRACK, \cite{yamamoto00}, assumed that dark matter is composed of axions. The experiment uses a strong magnetic field to convert the axions to photons in a resonant cavity. The resulting photons can excite Rydberg atoms passed through the cavity to an excited state, which can be detected using a technique called selective field ionization. They were able to get sensitivity almost to the axion model band line with a span of 8$\%$ around 10 $\mu$eV.
%
%Macroscopic Forces
%It is possible for axions to mediate spin-dependent short range forces \cite{moody84}. 
%This technique of detection with atoms is notable because the detector is the atoms and adds no additional noise to the experiment. This will come back to haunt us when we talk about higher frequency axion detection with microwave cavities and linear amplifiers \cite{lamoreaux13}.
%
%Oscillating EDMs
%\end{description}
%\begin{figure}
%\centering
%\includegraphics[width=0.6\textwidth]{1dexclusionlimit}
%\caption{Constraints on the axion mass (and thus energy scale) from \cite{raffelt08}. Striped lines are constraints; blank are projected constraints; and dotted are dependent on the cosmological history of the axion.}
%\end{figure}





%\subsection{Supernova Limit}
%
%We make a note here about the supernova limit and how it was achieved. The limit is $6 \times 10^{-11}$ 1/GeV; better than the limits produced by this experiment. However, we appeal to systematic uncertainties in the understanding of supernova physics.

\chapter{Axion Detection in Microwave Cavities}

%The signature of a dark matter axion converting to a photon in a strong magnetic field is an excess of photons with energy equal to the axion energy. As axions are thought to be non-relativistic, this would mean that the photons would have frequency equal to the rest mass of the axion plus a small energy dispersion. The amount of this dispersion can be most simply modeled by assuming an isothermal sphere. However, if you assume cold flows of non-virialized axions, the energy dispersion becomes much smaller. The broadening of the signal peak is distorted somewhat due to earth's orbital velocity around the sun and it's own rotational velocity - these effects are at the less than 4$\%$ level \cite{rosenberg00}.
%%As the axion is massive and the photon is massless, there is a large momentum mismatch. By having the converted photon be an excitation of a cavity mode, this can be overcome.
%The cavity also affects the rate of conversion; in a way this follows from Fermi's golden rule. In a vacuum there are isotropically many modes around; however for a cavity there are fewer modes so it is more probable for the axion to convert into the single one that is near it's energy. This is the same argument used for the Purcell effect; the phenomenon that an atom is more or less likely to spontaneously emit a photon if that transition is on resonance with a mode of the cavity.
%
%Yet another way to think of it is as the scattering of an axion off of the cavity mode.
%
%All in all, this makes the conversion rate go up as a factor of the cavity quality factor, Q. This property is partially what makes cavity searches so attractive. The downside though is that as we don't know the axion mass and resulting energy of the photon, we must tune the cavity resonant frequency, and are only sensitive to axions that occur with the cavity bandpass, which is inversely proportional to the Q. So with higher sensitivity to an axion at one frequency, there is less sensitivity to a wide range. This narrowband property makes for long searches. 

In this chapter, we derive the expected power $P_{out}$ for axion-induced signals in a microwave cavity. The experimental parameters we have control over are the magnetic field $B_0$, cavity quality factor $Q$, and volume $V$. The dark matter density $\rho$ is taken as a constant of Nature and the form factor $C_{lmn}$ is fixed once the cavity mode is selected. Our minimum detectable signal power will be determined by the noise floor of the experiment. For axions, the expected width of the signal $\Delta \nu_a$ is given by the axion velocity dispersion, and this sets our spectral resolution. The fluctuations of the noise power $\delta P_n$ are given by the Radiometer equation (Eq.~\ref{eq:radio})

\begin{equation} \label{eq:radio}
\delta P_n = k_B T_{sys}\sqrt{\frac{\Delta \nu_a}{\tau}}
\end{equation}

where $T_{sys}$ is the system noise temperature, $k_B$ is Boltzmann's constant,  and $\tau$ the integration time. We decrease  $T_{sys}$  by cooling the cavity to cryogenic temperatures and integrating for $\tau = 1$ hour.

The sensitivity is the Signal to Noise ratio (SNR) (Eq.~\ref{eq:snr}):

\begin{equation}\label{eq:snr}
SNR = \frac{P_{out}}{\delta P_{n}} = \frac{T_{out}}{T_{sys}}\sqrt{\frac{\tau}{\Delta \nu_a}}
\end{equation}

where $T_{out} = P_{out}/k_B\Delta \nu_a$ is the output equivalent temperature.
%In this chapter, we describe the expected signal power for a photon transformed from the axion in the presence of a static magnetic field. 
%This will depend on the cavity quality factor $Q$, the density of dark matter $\rho_a$, and the volume of the cavity $V$. 
%
%As we will see, the cavity quality factor and volume both decrease with increasing resonance frequency, if the mode measured is the lowest mode of the cavity. Working at higher modes also brings in a cost, as the form factor which calculates the overlap of the cavity mode with the background magnetic field, decreases for higher modes.
We now derive the expression for the output signal power $P_{out}$.
\section{Signal Power}
%The axion-photon interaction appears in the Lagrangian (Eq.~\ref{eq:lag}) with an effective term as 
%\begin{align} \label{eq:lag}
%\mathcal{L} = \frac{1}{4}F_{\mu\nu}F^{\mu\nu} + \frac{1}{2}\partial_\mu a^2 -\frac{1}{2}m^2 a^2 + \frac{1}{4}g a F_{\mu\nu}\tilde F^{\mu\nu}
%\end{align}
%
%where $F_{\mu\nu}$ is the electromagnetic field tensor, and $\tilde F_{\mu\nu} = \frac{1}{2}\epsilon_{ab\mu\nu}F^{ab}$ its dual. The product $F\tilde F = E \cdot B$ is the scalar product of a polar and axial vector, and thus is CP-odd. This produces modified Maxwell's equations of the form \cite{hoogeveen92}:
%
%\begin{align}
%\nabla \cdot B = 0 \\
%\partial_t B + \nabla \times E = 0 \\
%\nabla \cdot E = -gB \cdot \nabla a \\
%\partial_t E - \nabla \times B = g B \partial_t a - g E \times \nabla a \\
%(\partial_t^2 - \nabla^2 + m^2)a = gE\cdot B
%\end{align}
%
%this leads to an equation of motion that, assuming a spatially uniform axion field (which in our case holds), looks like 
%
%\begin{align}
%\nabla^2E - \partial_t^2E = gB_0\partial_t^2a
%\end{align}
%
%where $B_0$ is the magnetic field. Decomposing the electric field in terms of the cavity modes, as well as the background magnetic field, and following the discussion in \cite{krauss85}, shows that the cavity will respond in mode j as 
%
%\begin{align}
%\lambda_j(\omega) = \eta_j(\omega^2/(\omega^2-\omega_j^2))a(\omega)
%\end{align}
%
%where $\eta_j$ is the fourier coefficient (with basis of cavity modes j) for describing the background magnetic field, $a(\omega)$ is the Fourier representation of $a(t)$.
%
%Integrating over the parameter $\omega$, the energy stored in the cavity for a mode j is 
%
%\begin{align}
%U_j = \int |{E_j(\omega,x)}|^2 d^3x d\omega 
%= V \int \lambda_j^2 d\omega
%\end{align}
%
%Including dissipation by the substitution $(\omega^2-\omega_j^2)^2 \rightarrow (\omega^2-\omega_j^2)^2 + \omega^4/Q^2$, and rewriting the $\eta_j^2$ as $G^2B^2$ for some filling factor $G$, the energy in a mode is
%
%\begin{align}
%U_j = G^2VB^2\int \frac{|a(\omega)|^2 \omega^4}{((\omega^2-\omega_j^2)^2 + \omega^4/Q^2)} d\omega
%\end{align}
%
%On resonance, for $Q < Q_a$
%
%$P_j = \omega_j U_j/Q = G^2B^2VQ\rho/m_a$
%
%The form factor can be expressed as 
%
%\begin{align}
%C_{lmn} = \frac{|B_0 \int_V E \cdot \hat{z}\, dV|^2}{B_0^2 V \int_V \epsilon_r |E|^2 dV}
%\end{align}
%
%In terms of the laboratory parameters, for a 7 Tesla magnetic field and cavity operating in the $\text{ª}_{020}$ mode, an axion coupling to two photons with strength $g_{a\gamma\gamma} = 8\times10^{-11}$ 1/GeV has power coupled out of the cavity at a level:
%\begin{multline}
%P_a = 9.5 \times 10^{-25}\text{ W}\bigg(\frac{C_{020}}{0.13}\bigg)\bigg(\frac{\kappa}{0.5}\bigg)\bigg(\frac{Q}{10^4}\bigg)
%\bigg(\frac{V}{1.6\text{ cm}^3}\bigg)\bigg(\frac{B_0}{7 \text{ T}}\bigg)^2 \times\\
%\bigg(\frac{g_{a\gamma\gamma}}{8\times10^{-11}\text{ 1/GeV}}\bigg)^2 
%\bigg(\frac{\rho_a} {0.3\text{ GeV/}\text{cm}^3}\bigg)\bigg(\frac{m_a}{34\text{ GHz}}\bigg)^{-1}
%\end{multline}
%
%where $\kappa$ is the coupling strength of the cavity to the amplifier. On critical coupling half of the power is coupled out so $\kappa = 0.5$.
Following the discussion in \cite{arias12}, we can derive the signal power for axions $P_{out}$ by first expanding the total electric field $E(x)$ inside the cavity in the basis of the cavity mode fields,  each labeled by index $i$ (Eq~\ref{eq:cavmodes}):
\begin{align}\label{eq:cavmodes}
E(x, t) = \Sigma_i \alpha_i(t) E_i(x),\\ \int dV \epsilon_r |E_i(x)|^2 = N_i
\end{align}
where $N_i$ are the normalization coefficients and $\epsilon_r$ is the relative permittivity in the cavity. The coefficients $\alpha_i(t)$ satisfy the equation for a driven, lossy cavity (Eq~\ref{eq:diffeq})
\begin{equation} \label{eq:diffeq}
\big(\partial_t^2 + \frac{\omega_0}{Q}\partial_t + \omega_0^2\big) \alpha_i(t)  = b_i(t)
\end{equation}
where $\omega_0$ is the cavity resonance frequency, $Q$ is the unloaded quality factor, and $b_i(t)$ the driving force.
%
%In frequency space, this is a linear equation:
%\begin{align}
%(-\omega^2 -i\omega_0 \omega /Q + \omega_0^2) \alpha_i(\omega) = b_i(\omega)
%\end{align}
Solving for the coefficients in Eq~\ref{eq:diffeq} in Fourier space yields:
\begin{align}
\alpha_i(\omega) =  \frac{b_i(\omega)}{\omega_0^2 - \omega^2 - i\omega \omega_0/Q}.
\end{align}
The coefficients $b_i$ come from the equations of motion. Starting from the axion Lagrangian, where $F_{\mu\nu}$ is the electromagnetic field tensor,and $\tilde F_{\mu\nu} = \frac{1}{2}\epsilon_{ab\mu\nu}F^{ab}$ its dual
\begin{align} \label{eq:lag}
\mathcal{L} =  \frac{1}{4}F_{\mu\nu}F^{\mu\nu} + \frac{1}{2}(\partial_\mu a)^2 -\frac{1}{2}m^2 a^2 + \mathcal{L}_I\\
\mathcal{L}_{I} = \frac{1}{4}g_{a\gamma\gamma} a F_{\mu\nu}\tilde F^{\mu\nu} = g_{a\gamma\gamma} a E \cdot B
\end{align}
we see that the interaction term $\mathcal{L}_I$ goes as the scalar product of the electric field and the magnetic field.  The resulting Maxwell's equations  are modified by this axion interaction term:
\begin{align}
\nabla \cdot B = 0 \\
\partial_t B + \nabla \times E = 0 \\
\nabla \cdot E = -gB \cdot \nabla a \\
\partial_t E - \nabla \times B = g B \partial_t a - g E \times \nabla a \\
(\partial_t^2 - \nabla^2 + m^2)a = gE\cdot B
\end{align}
Assuming a spatially uniform axion field $a(x,t) = a(t)$, and a strong external magnetic field $B_0\hat{z}$ such that $B_{total} = B_i +B_0\hat{z} \approx B_0\hat{z}$, the equations of motion for the electric field are:
\begin{align}\label{eq:eqofmotion}
\nabla^2E - \partial_t^2E = gB_0\partial_t^2a.
\end{align}
Introducing a term to account for loss in the cavity, $\frac{\omega_0}{Q}\partial_t$, and multiplying each side of Eq \ref{eq:eqofmotion} by $E_i^*(x)$ and integrating out the spatial dependence, we regain Eq \ref{eq:diffeq}. Thus the drive coefficient $b_i(t)$ is
\begin{align}
b_i(t) =\frac{gB_0\partial_t^2a(t)}{N_i} \int dV E_i^*(x) \cdot B_0\hat{z}
\end{align}
and in Fourier space:
\begin{align}
b_i(\omega) =\frac{-gB_0\omega^2a(\omega)}{N_i} \int dV E_i^*(x) \cdot B_0\hat{z}.
\end{align}
% \frac{1}{4}F_{\mu\nu}F^{\mu\nu} + \frac{1}{2}\partial_\mu a^2 -\frac{1}{2}m^2 a^2 +
%The product $F\tilde F = E \cdot B$ is the scalar product of a polar and axial vector, and thus is CP-odd.As the axion is a pseudoscalar, the total interaction term is CP even.
%The driving coefficients are then:
%\begin{align}
%b_i(t) = \frac{g a(t) }{N_i} \int dV E_i^*(x) \cdot B_0\hat{z}
%\end{align}
%The resulting Maxwell's equations  are then modified to include an effective charge and current:
%
%\begin{align}
%\nabla \cdot B = 0 \\
%\partial_t B + \nabla \times E = 0 \\
%\nabla \cdot E = -gB \cdot \nabla a \\
%\partial_t E - \nabla \times B = g B \partial_t a - g E \times \nabla a \\
%(\partial_t^2 - \nabla^2 + m^2)a = gE\cdot B
%\end{align}
%
%This leads to an equation of motion that, assuming a spatially uniform axion field (which in our case holds), looks like 
%
%\begin{align}
%\nabla^2E - \partial_t^2E = gB_0\partial_t^2a
%\end{align}
The steady-state energy stored in the cavity mode $i$ is
\begin{align}\label{eq:energy}
U_i = \langle |\alpha_{i}(t)|^2\rangle\int dV\epsilon_r |E_i(x)|^2
\end{align}
Following the derivation in \cite{krauss85}, we can rewrite the time averaged expression in Eq. \ref{eq:energy} in terms of the frequency representation
\begin{align}
\langle |\alpha_{i}(t)|^2\rangle = \int _{-\infty}^{\infty} |\alpha_i(\omega)|^2 d\omega
\end{align}
and so
\begin{align}
\langle |\alpha_i(t)|^2\rangle \propto \int _{-\infty}^{\infty} \frac{|a(\omega)|^2\omega^4}{(\omega^2-\omega_0^2)+\omega^2\omega_0^2/Q^2} d\omega \\
\end{align}
%When $\omega = \omega_0$, the integral evaluates to
%The product $ga(t)$ is dimensionless, so in natural units we can write $g^2<a(t)^2>$ in terms of the halo energy density (dimensions $eV^4$)  and mass (dimension eV) as:
%\begin{align}
%g^2<a(t)>^2 = \frac{g^2\rho}{m_a^2}
%\end{align}
The halo density can be written in terms of the amplitude of the field and the mass $m_a$:
\begin{align}
\rho = m_a^2\langle a^2 \rangle
\end{align}
so for a single frequency axion signal $a(t) = a_0e^{-i\omega t}$ centered at $\omega =  \omega_0$, the integral evaluates to 
\begin{align}
\frac{\rho}{m_a^2}Q^2
\end{align}
This is correct as long as the axion quality factor $Q_a$ is higher than the cavity quality factor; in the case that $Q_a < Q$ we no longer capture the entire signal in the cavity bandwidth and must adjust the expression for output power accordingly.
%
%as the halo density can be expressed in terms of the amplitude of the field with the relation:
%\begin{align}t
%\rho = m_a^2\langle a^2 \rangle
%\end{align}
and so the stored energy is 
\begin{align}
U_i =\frac{g^2\rho}{m_a^2}CVQ^2B_0^2
\end{align}
where we will define $C$, the form factor, shortly.The general expression for power in mode $i$ can be expressed in terms of the quality factor $Q$ and the average energy stored $U_i$:
\begin{align}
P_{out} = \kappa \frac{U_i}{Q}\omega_0
\end{align}
where $\kappa$ is the coupling of the cavity to the detector, so the on-resoance power evaluates to
\begin{align} \label{eq:power}
P_{out} = \kappa (gB_0)^2 \frac{\rho}{m_a} Q V C
\end{align}
where the form factor $C$ expresses the overlap integral of the scalar product $E\cdot B_0$ for a medium with relative permittivity $\epsilon_r$ (Eq.~\ref{eq:formfactor})
\begin{align}\label{eq:formfactor}
C = \frac{|\int_V E_i(x) \cdot \hat{z}\, dV|^2}{V \int_V \epsilon_r |E_i(x)|^2 dV}
\end{align}
For the experimental parameters of our system, the output power we expect to see for an axion coupling to two photons with strength $g_{a\gamma\gamma} = 8\times10^{-11}$ 1/GeV is:
\begin{multline}
P_{out} = 9.5 \times 10^{-25}\text{ W}\bigg(\frac{C_{020}}{0.13}\bigg)\bigg(\frac{\kappa}{0.5}\bigg)\bigg(\frac{Q}{10^4}\bigg)
\bigg(\frac{V}{1.6\text{ cm}^3}\bigg)\bigg(\frac{B_0}{7 \text{ T}}\bigg)^2 \times\\
\bigg(\frac{g_{a\gamma\gamma}}{8\times10^{-11}\text{ 1/GeV}}\bigg)^2 
\bigg(\frac{\rho_a} {0.3\text{ GeV/}\text{cm}^3}\bigg)\bigg(\frac{m_a}{34\text{ GHz}}\bigg)^{-1}
\end{multline}

For hidden photons the steps are almost identical; the only difference is the form of the driving force. The Lagrangian for hidden photons (in the interaction basis) is:
\begin{align}
\mathcal{L} = \frac{1}{4}(F^{\mu\nu} F_{\mu\nu}  + \phi_{\mu\nu} \phi^{\mu\nu} ) + \frac{m_h^2}{2}(\phi^{\mu\nu}-\chi A^\mu)(\phi_{\mu\nu}-\chi A_\mu) + J_\mu A^\mu
\end{align}
where $m_h$ is the hidden photon mass, $\phi_{\mu\nu} = \partial_{\mu}\phi_{\nu}-\partial_{\nu}\phi_{\mu}$ the hidden photon field tensor, and $J^\mu$ is the charged current of the standard photon.

Working through to the equations of motion, one finds that the driving force for hidden photons is 
\begin{align}
b_i = \frac{\chi m_h^2}{N_i} \int dV E_i^*(x) \cdot \phi(x)
\end{align}
Solving Eq~\ref{eq:diffeq} for the cavity mode coefficients, the resulting expression for the power on resonance is very similar to the axion case:
\begin{align}
P_{out} = \kappa (\chi m_h)^2 \frac{\rho}{m_a} Q V G
\end{align}
where $G$, the hidden photon form factor, is
\begin{align}
G = \frac{|\int_V E_i(x) \cdot \hat{n}\, dV|^2}{V \int_V \epsilon_r |E_i(x)|^2 dV}
\end{align}
and $\hat{n}$ is the polarization direction of the hidden photon field $\phi$.

Note that the hidden photon form factor $G$ is the same as the axion form factor $C$ with the direction of the hidden photon polarization $\hat{n}$ replacing the direction of the magnetic field. If we rewrite $\hat{n} = \hat{z} \cos \theta$ then $G = C \cos^2 \theta$.

The axion form factor is only non-zero when the scalar product of the cavity electric field and the external magnetic field is non-zero. This means, for a non-zero form factor, we must operate with transverse magnetic modes which have an axial electric field. The $\text{ª}_{0n0}$ modes have a non-zero form factor and $C$ scales as 
\begin{align}
C_{0n0} \propto x_{0n}
\end{align}
for cylindrical cavities, where $x_{0n}$ is the nth root of the first order Bessel function $J_0(r)$. This goes down approximately as $n$ so with increasing mode index, the form factor goes down quickly.

%For the experimental parameters of our system, the output power we expect to see for an axion coupling to two photons with strength $g_{a\gamma\gamma} = 8\times10^{-11}$ 1/GeV is:
%\begin{multline}
%P_{out} = 9.5 \times 10^{-25}\text{ W}\bigg(\frac{C_{020}}{0.13}\bigg)\bigg(\frac{\kappa}{0.5}\bigg)\bigg(\frac{Q}{10^4}\bigg)
%\bigg(\frac{V}{1.6\text{ cm}^3}\bigg)\bigg(\frac{B_0}{7 \text{ T}}\bigg)^2 \times\\
%\bigg(\frac{g_{a\gamma\gamma}}{8\times10^{-11}\text{ 1/GeV}}\bigg)^2 
%\bigg(\frac{\rho_a} {0.3\text{ GeV/}\text{cm}^3}\bigg)\bigg(\frac{m_a}{34\text{ GHz}}\bigg)^{-1}
%\end{multline}

For hidden photons, a conservative estimate on the form factor leads to the following expected power:
\begin{multline}
P_{out} = N \bigg(\frac{G_{020}}{0.00013}\bigg)\bigg(\frac{\kappa}{0.5}\bigg)\bigg(\frac{Q}{10^4}\bigg)
\bigg(\frac{V}{1.6\text{ cm}^3}\bigg) \times\\
\bigg(\frac{\chi}{8\times 10^{-11}}\bigg)^2 
\bigg(\frac{\rho_a} {0.3\text{ GeV/}\text{cm}^3}\bigg)\bigg(\frac{m_a}{34\text{ GHz}}\bigg)
\end{multline}


\section{Axion Velocity Dispersion}

To estimate the expected width of the axion signal, we assume for simplicity that the dark matter halo forms an isothermal sphere and that the axion velocity has a Maxwellian distribution
\begin{align}\label{eq:mwell}
p(v)d^3 v = Ne^{-\frac{1}{2}v^2\beta}d^3v
\end{align}
where $\beta = 3/<v^2>$, $<v^2>^{1/2} \sim 270$ km/sec and N is a normalization constant. This model is taken for simplicity, although it is known that the isothermal sphere is not an accurate representation of the halo density. Obervations of spiral galaxies show that the density at the core is less than that predicted by the sphere model; however, we take this model for its simplicity in estimating the axion signal width.

The distribution in Eq \ref{eq:mwell} is boosted by the Earth's rotation around the center of the galaxy. Accounting for this factor the kinetic energy of the axion is
\begin{align}
E = \frac{1}{2}m_a(v-v_e)^2
\end{align}

where $v_e \approx 220$ km/sec. The probability distribution of $E$ is 
\begin{align}
p(E) = N' e^{-\beta E/m_a} \sinh(\beta v_e \sqrt{2E/m_a})
\end{align}

The axion Q is, assuming virialized axions, $\sim 10^6$.


%There is strong astrophysical evidence that a large portion of the matter in our galaxy is non-luminous, meaning that it does not have electromagnetic interactions. The first evidence came from measurements by Oort \cite{oort32}, who showed that their must be more mass in the Milky Way than measured; at around the same time, Fritz Zwicky \cite{zwicky37} measured the mass to light ratio in the Coma cluster. He found that the MtoL ratio was nearly 500 times greater than that expected. Most definitively, measurements of spiral galaxies using hydrogen's hyperfine transition at 21 cm have shown that in a a survey of many glaxies, all of them have rotation curves that suggest that the matter is distributed in a diffuse halo, not concentrated near the center, as the light is\cite{rubin80}. This dark matter would affect structure formation; as pockets of local overdensity formed, non-relativistic dark matter would settle into the gravitational well and provide many sites of small structure, which could then accrete to form large structure later - this is consistent with the level of temperature anisotropies observed in the Cosmic Microwave background \cite{planck13}, and n-body simulations [NEEDSREF]. Observations of temperature anisotropies in the Cosmic Microwave Background also allow us to make predictions on cosomological parameters; $\kappa$, the geometry of the universe, and $\Omega$, the matter density. The measurement of the relative amplitude of the anisotropies tells us that the baryon density of the universe is 4$\%$. This rules out the simplest assumption that dark matter is baryonic and made of dead stars or non-luminous brown dwarfs. This was also ruled out by micro-lensing surveys of Massic Compact Halo Objects (MACHOS) [NEEDSREF], which did not find as many events as would be predicted by the abundance of dark matter. The measurements of supernova with respect to distance, using them as standard candles, tells us how much of the universe is made up on dark energy, a mysterious substance which is causing the expansion of the universe to accelerate. The amount of dark energy in the universe, taken from CMB measurements, is 73$\%$. The remaining 21$\%$ is dark matter.
%
%The lambda cold dark matter model ($\Lambda$ CDM) supposes non-relativistic, non-baryonic particulate dark matter. 
%
%There are three strong candidates for the particle of dark matter: sterile neutrinos, WIMPs and axions. Sterile Neutrinos are neutrinos which are right handed, and thus do not interact with the electroweak force, which only deals with left-handed neutrinos. There is some evidence for a 3.5 keV line in some galaxies which would correspond to a 7 keV sterile neutrino [NEEDSREF].
%
%Weakly Interacting Massive Particles (WIMPs) are stable neutral particles with large mass, usually in the tens of GeV to some TeV range. These particles would have the correct dark matter density if their cross section for interactions is equal to the electroweak scale, a suggestive coincidence called the "WIMP miracle". There are also supersymmetric theories extending the Standard Model; these SUSY theories predict a super partner for every elementary particle with opposite spin, ie. every fermion has a boson partner and vice versa. SUSY theories are important for solving a problem in particle physics, which is that the Higgs mass is divergent when including higher order corrections. The lightesst SUSY partner, the neutralino, has the correct properties to be cold dark matter (spinless, chargeless) and would constitute a WIMP. There are direct and indirect searches looking for WIMPs, either through their rare scattering off of a nuclei such as LUX \cite{lux14}, or through indirect searches which assume that WIMPS are their own antiparticle and then annihilate, producing visible signatures in the galaxy [NEEDSREF]. There is some evidence from the Fermi gamma ray telescope for a WIMP like signal coming from the center of the galaxy [NEEDSREF].


\chapter{Experiment}
\section{The Magnet and Cryogenic Systems}




%The tuning rod connection consists of a bellows which allows the rod to enter a vacuum compatible region that has vertical motion capability.


%
%The cryostat is a gas flow design, meaning the primary mechanism of cooling occurs through convection? Movement of the helium gas from the bottom where it is boiling off from the liquid collected to the top. The atmospheric valve is left open so that when running the cryostat has slightly more than atmospheric pressure. There are several circular mylar baffles in place as well.


The experiment consists of a microwave cavity in the bore of a superconducting solenoid magnet from Oxford Instruments. The magnet is made of  NbTi alloy with copper windings and has a maximum field of 7 Tesla. The warm bore has a diameter of 89 mm. Over the size of the cavity the magnetic field is homogenous to better than $1\%$.

\begin{figure}[htbp]
\includegraphics[width=\textwidth]{nmrmagnet}
\caption{Oxford instruments NMR magnet}
\end{figure}

The magnet was cooled in the summer of 2011 and has run in persistent mode at full field up to the time of writing. A separate gas-flow cryostat custom built from Cryo Industries sits in the bore. This cryostat has an inner diameter of 1.57 inches and is offset from the bore center so that there is enough space for a second cavity to sit in the bore, outside the cryostat. 

\begin{figure}[htbp]
\centering
\includegraphics[width=1.3\textwidth, angle = 90]{cryostatalltogether}
\caption{Top half of the cryostat, with inset showing full cryostat. The cavity is located at the bottom of the sample region above the vaporizer}
\end{figure}

There are 3 Liter reservoirs for nitrogen and helium at the top, and a touch point with the nitrogen reservoir halfway down. A capillary tube allows liquid helium to flow from the reservoir to the bottom of the cryostat, and a block with a heating element inside of it allows us to control the temperature of the cryostat. We found when running that the temperature stability of the system as well as the helium consumption depended heavily on the cryostat vacuum - if we ran for more than two weeks, the helium consumption would more than double, from 30 L/week to 70 L/week. Thus during the actual runs we had to pump out the cryostat vacuum insulation layer every other weekend. 

A typical cooldown consists of filling the nitrogen reservoir of the cryostat, which we can do automatically through an autofill mechanism, clearing the capillary line from any air or nitrogen by running helium gas through from the helium reservoir, opening the flow valve and pumping on it, and then filling the helium reservoir. To go from room temperature to 4 K at the bottom of the dewar generally takes about three hours. If we do this procedure the night before, when we fill the nitrogen and helium again the next day it only takes an hour, generally.

%There are two cryogenic amplifiers with a gain of 50 dB and waveguides WR28 carry the signal power out of the cryostat to a room temperature electronics chain which filters, amplifies, and mixes the signal down to baseband, so it can be digitized. We have a PCI- National Instruments (PCI-5114) digitizer that samples at a rate of 10 MHz second, with a 10 MHz digital signal sent in by the PXA Signal Analyzer N90330A which is in turn phase locked to the first signal generator, which outputs a 10 MHz analog signal. A test tone signal is generated by a second signal generator, also an Anritsu MG3694C, offset to 3 MHz lower than the cavity resonant frequency. There is an RF switch (model number) to connect either one cable of the network analyzer (also frequency locked) or to take the signal power to the receiver. There is another RF switch on the other cable of the network analyzer that connects either the test tone signal to the calibration port or the network analyzer input. 

\begin{figure}[htbp]
\includegraphics[width=\textwidth]{closeupschematic2}
\caption{Not to scale. Sketch of cavity and waveguides in cryostat. Helium enters the sample region at the vaporizer; a heating element can be adjusted to increase the boil-off rate and thus raise or cool the cryostat temperature.}
\end{figure}

The heat load into the dewar is dominated by the waveguides. The two WR28 waveguides in the insert have Mylar radiation baffles to reduce any radiation heat load coming from the top, and a six inch section of copper-clad stainless steel WR28 at the top to also help reduce the heat load. There are two flexible 3 inch sections of WR28 waveguide that allow us to connect to bulkheads feedthroughs. An electrical stock allows electrical wires to go through for temperature sensors. 
The tuning rod consists of a G-10 rod, .125" diameter. The waveguides are made of several pieces - at the top of the insert there is a six inch section of stainless steel copper coated waveguide, and the rest is copper waveguide. This is to reduce the heat load on the bottom of the cryostat. The waveguides used throughout are WR28 - which means rectangular waveguide with a lower cutoff frequency of 21.5 GHz.
We place the assembly of the cavity, low noise cryogenic amplifier, and waveguides, which we call the insert, into the cryostat with a vacuum seal at the top. There are several temperature sensors and the power leads for the LNA is also fed through.
I should also mention that the tuning mechanism, which in this case consists of a long rod that is attached at the top via a screw, is coupled in a vacuum compatible way. The waveguide and cavity together consist a closed system - we pump on the waveguides when trying to keep liquid helium from entering the cavity, which it can do most probably through the tuning rod connection. 



%Another danger is if the cavity gets liquid in it, the resonance is no longer stable. This is probably because it fills up very slowly due to a small but intermittent leak somewhere in the indium seals of the waveguides. This means that whenever we saw the temperature sensors reading less than 4 K, we usually stopped the run and heated the cavity up. Thirdly, we found that the stability of the cavity resonance was more robust to changes if the cavity was at a higher temperature - changes of .5 K at 10 K seemed to affect the cavity resonance much less than at 5 K. One explanation is that the pressure in the cavity altered the resonance frequency - from John Rogers Thesis \cite{rogers87}, in their experiment they saw that there was a 30 kHz/GHz/psi shift. We see a XXX shift.




\section{The Microwave Cavity}

\subsection{Design}

We use a cylindrical cavity built out of oxygen free high conductivity (OFHC) copper, which consists of a block with a machined cylinder and a bottom end cap. After machining, the surfaces were polished with a rouge polish to reduce the roughness.  The pieces were then screwed together with an indium seal in between, and a taper cut into the bottom cap in order to allow for the spreading out of the indium as it compressed. 

%This will go into a previous chapter \subsection{Why ª 020}
%The reason we have been talking about TM020 all this time is because the Tm010 mode has too small a size in the 34 GHz range. Let us expand our range and take the entire Ka-band, or R-band as it is sometimes called. From 26.5-40 GHz, if the Tm010's resonant frequency lies in that range, it's cavity radius would be 4.33 mm to 2.869 mm. Hmm that actually seems pretty ok for the lower range. Why are we workign at 34 GHz anyways? The Tm020 mode would have 9.9mm-6.58mm. The size of our current opening in the cryostat is 40 mm. Our current cavity has a radius of 5 mm in the Te011 mode.
%However! We believe that the TM020 mode has a higher Q, at least theoretically, which with the higher volume for the same frequency, actually compensates the degraded C (C for 010 is 0.69 and C for 020 is 0.13). Although there are more mode crossings, we don't worry about this because we make the cavity height sufficiently small so that other modes can't come in.
%The reason we are working above 20 GHz is because this region is as of yet unexplored. People have been using large microwave cavities to look for lower mass axions because of the higher sensitivity due to the large volume. It is our goal to push the exploration to higher masses in order to investigate possible axion-photon couplings in this as of yet unexplored region.
%The reason we are working precisely at 34 GHz is pretty stupid though. We wanted to use a high power pulsed source which puts out fixed frequency 34.29 GHz radiation. Then we designed our whole system around it and now don't want to change it because it would be a pain.
%Our other limitations are the present waveguides installed (fundamental mode operates between 21.5 and 40 GHz even though the rating says 26.5-40 GHz) and the RF filter. Also our electronics might not be happy. But the LNAs can go from 11-34 GHz.
%We mention here that we are tryng to do something that cavities are not really made to do - be a broadband detector. They are very good at picking out specific frequencies from a broadband input, or enhancing processes when the radiation these processes emit is at a frequency where the cavity resonates. So much work is being done trying to bring tuning, which is a slow process with a cavity, into the picture.

\subsection{Aperture Coupling}
There are two coupling holes - the first one is to couple power out of the cavity. For critical coupling, the power coupled out is equal to the power lost in the walls. This gives optimal signal to noise. The other hole is so that we can send in power in order to do transmission measurements, which allow us to determine the Q of the cavity and the resonant frequency. This hole is in general very weakly coupled $<50 dB$. 

%We use coupling holes instead of antennas for god knows why. The reason is at the frequency we work at it is problematic using cables. They are lossier than waveguide and I don't know what else.

We couple inductively by picking up overlap in the magnetic field of the waveguide mode (TE(10) and the azimuthal field of the cavity TM020 mode. As discussed in the previous chapter, operating in the TM020 mode decreases the form factor C from the maximal value, but allows us to have a larger volume, which increases the sensitivity. It is also easier to machine and work with a cavity that is larger than the waveguides. The TM0n0 modes have only non-zero electric field in the z direction 

\begin{align}
E = E_0 J_0(x_{0n} r/R) e^{-i\omega t} \hat{z}\\
B = -i\sqrt{\epsilon}E_0J_n(x_{0n} r/R) e^{-i\omega t}\hat{\phi}
\end{align}

where $x_{0n}$ is 0th root of the nth Bessel function $J_n$ and R is the cavity radius.  The cavity resonant frequency is 

\begin{align}
\omega = \frac{5.52}{\sqrt{\epsilon}} \frac{c}{R}
\end{align}

where $x_{02} = 5.52$.

%There is no intrinsic advantage to this, just that the geometry of the fields in the waveguide and in the cavity and our space constraints make it easier to have vertical waveguides on the sides of the cavity and the fields in the mode that align with the propagating fundamental mode of the waveguide happen to be magnetic ones.

The TM020 mode must have good connection between the walls and the caps because the alternating E field means that there are vertical currents that switch direction and flow in the vertical axis so if they cannot flow to the top or bottom cap, the mode's Q will be severely degraded.
%\subsubsection{HFSS}
%Shown below is a cross-sectional plot of the electric field in the z-direction for a dielectric rod with $\epsilon = 9.2$ inserted 0.028 inches into the cavity.
%
%\begin{figure}[htbp]
%\centering
%\includegraphics[width=\textwidth]{efieldhfsssim28thou}
%\caption{Magnitude of Electric field in the mode with dielectric rod inserted.}
%\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.6\textwidth]{tm020efield}
\caption{Electric field lines in the cavity.}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.6\textwidth]{tm020magneticfield}
\caption{Magnetic field lines in the cavity.}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{waveguidefields}
\caption{Showing the magnetic field lines of the $TE_{01}$ propagating mode in the waveguide. This couples to the azimuthal magnetic fields in the cavity.}
\end{figure}
\subsection{Tuning}
%The cavities we use for detection are made to resonate at frequencies near $~34$ GHz. This choice has to do with the predictions for the resonant frequency of axions, sensitivity, and the constraints on making 3D cavities that will fit into the space limitations of our current setup.

Taking the most practical consideration, the diameter of cavities scale in size as $\lambda$. We assume throughout we are only interested in low order modes for which the prefactor for lambda is O(1). If we wish to tune the resonant frequency of a particular mode, the common methods are perturbing the cavity geometry, either by inserting a dielectric or physically changing the size of the cavity. 

For axion searches, only $\text{TM}_{0n0}$ modes couple to the emitted photon, and the frequency is independent of the cavity height, which is easier to adjust than the radial dimension. 

%Therefore the scheme that we use for our $TE_{011}$ cavity of using a floating cap that we can vary the height of (called the plunger) no longer works.  

So instead we introduce a dielectric, in our case alumina ceramic which has a relative permittivity of $\epsilon \approx 9.3$. The size of the dielectric will affect how much it perturbs the cavity mode - in our case we limited the size of the dielectric rod by considering what the cutoff frequency was of the tube in which the dielectric was held. For a circular tube (which is essentially a waveguide) with $\epsilon = 9.3$, light will not propagate until 36.22 GHz for a diameter of 0.063". 

In order to keep the mode Q high, it is best not to destroy the axial symmetry of the $TM_{0n0}$ mode so we insert it vertically in the center. It is also easier to make vertical insertions that horizontal ones, where the cavity must be aligned with its axis along the axis of the magnet. 

Not only the resonance frequency, but the form factor C will be affected by the dielectric since the fields in the mode are perturbed. Other groups (ADMX) have seen that inserting a dielectric rod can cause large degradation in the field mode, however we do not find this to be the case in our simulations for the range of insertion depths tested. 

\begin{figure}[htbp]
\centering
\includegraphics[width=1\textwidth]{formfactorvsfrequency}
\caption{Form factor calculated for an axially moving dielectric rod of radius .0315 in and cavity radius $R=.3$ in. The frequency span is reached for a travel of 0.032 in of the dielectric rod.}
\end{figure}

The height of the cavity was set to be $L=0.34$ in to avoid a mode crossing with the higher TE112 mode that appeared in the simulation. However, when the cavity was built the modes were separated by at least 2 GHz and there is no danger of a mode crossing over the range in which we scan. The other close mode is the TM010 mode, which is at 17 GHz.

\begin{table}[htbp]
\caption{Summary of cavity parameters}
\begin{center}
\begin{tabular}{|c|c|c|c|c}
\hline
R [in] & tuning rod & tuning range [GHz] & $Q_{wall}$ & C \\ \hline
0.3 & dielectric & 33.9-34.5 & $1.9\times10^4$ & 0.13 \\ \hline
\end{tabular}
\end{center}
\label{summary}
\end{table}%


\subsection{Simulation and Bench Tests}
\subsubsection{RF Properties at Cryogenic Temperatures}
%The walls of the cavity are 40 thousandths thick at their thinnest point. There is a small hole for the weak coupling port and a large oval ``racetrack`` hole for the strong port.  

The cavity was simulated in Ansoft HFSS. Surface finish plays a large role in the Q of the cavity - using a surface roughness tester we determined that the surface roughness of the cavity surface was less than 2 $\mu$inches. This value leads to negligible effects in the simulations and was therefore neglected.  

$\sigma = 5.86 \times 10^{7}/\Omega\cdot\text{cm}$ for oxygen-free copper at 294 K.

At cryogenic temperatures the conductivity of copper is approximately three times higher. The regime of low temperatures and microwave frequencies causes the anomalous skin depth effect - where due to the fact that the mean free path is now longer than the skin depth, one can no longer use the classical formula for the conductivity. In this regime the skin depth is given by:

\begin{align}
\delta = \big(\frac{\sqrt{3}c^2 m_e v_F}{8\pi^2 \omega n e^2}\big)^{1/3}
\end{align}

where $m_e$ is the electron mass, $e$ the electron charge, $v_F$ the Fermi velocity, and n the conduction density \cite{hagmann90}. For copper, $v_F  = 1.57 \times 10^8$ cm/sec and $n = 8.5 \times 10^22\text{ cm}^{-3}$, so the anomalous skin depth is 

\begin{align}
\delta = 2.8 \times 10^{-5}\text{ cm} (\frac{GHz}{f})^{1/3}
\end{align}

For the $TM_{010}$ modes the theoretical unloaded Q is $$Q_0 = \frac{L}{L+R}\frac{R}{\delta}$$

in general a cylindrical $TM_{mnp}$ mode has Q equal to \cite{poole96}

\begin{align}
Q_0 = \frac{\lambda}{\delta}\frac{[x_{mn}^2 + (p\pi a/d)^2]^{1/2}}{2\pi(1+2a/d)}
\end{align}

 where a is the radius and d the length. Then for the $TM_{020}$ mode, this simplifies to 
 \begin{align}
 Q_0 =\frac{\lambda}{\delta}\frac{5.52}{2\pi(1+2a/d)}
 \end{align}
 
 and recall that at room temperature, the skin depth is given by 
 
 \begin{align}
 \delta= (2/\omega \mu \sigma)^{1/2}
 \end{align}

The theoretical unloaded Q in the anomalous skin depth regime for the $\text{ª}_{020}$ mode with $2a/d = 1.76$ and $\lambda = .88\text{ cm}$ ($f=34$ GHz) is:

\begin{align}
Q_0 =\frac{.88\text{ cm}}{8.6\times10^{-6} \text{ cm}}\frac{5.52}{2\pi(1+1.76)} = 3.2\times10^4
\end{align}
 
 and at room temperature assuming resistivity of 1.69 $\mu\Omega \text{ cm}$,
 
 \begin{align}
 Q_0 =\frac{.88\text{ cm}}{11.2\times10^{-6} \text{ cm}}\frac{5.52}{2\pi(1+1.76)} = 2.5\times10^4
 \end{align}
 
 We measure the unloaded Q to be $1.9\times10^4$ and $1\times10^4$, respectively for the cold and warm cases. The loaded Q goes from 6455 to 9422, and the coupling coefficient goes from 0.6 (warm) to 1.15 (77K). Measurements of the coupling coefficient as the cavity is tuned (warm) show that it varies by 15$\%$ over the frequency range.  We take 1.15 to be the coupling coefficient at liquid helium temperatures. The VNA estimates the loaded Q here by finding the 3 dB bandwidth about the cavity peak in the transmission measurement. This is slightly inaccurate as the cavity is not critically coupled, but as an approximation is satisfactory for our purposes and we take the Q measured this way as the loaded Q during data runs.
 
%  In general $Q_0(TM_{0n0}) \sim x_{0n} \lambda/\delta $ for the aspect ratio kept constant.
% As $x_{mn} \sim n$ and $\lambda/\delta \propto f^{-3/2}$ or $f^{-4/3}$ depending on the regime, if you had to decide on what mode to operate in at a particular frequency, taking into account the axion signal power at $m_a=f$ being proportional to $C_{0n0}VQ/m_a \propto n^{-1} (n/f)^{3} Q/f \propto n^{3}$ implies going to higher order modes is more advantageous for operating at a fixed frequency. However the density of modes also increases proportionally to $n$, so the number of mode crossings will make the experiment difficult.

%Two cavities were made - the difference between them being that the small hole was .052 or .05, and that the length between the center of the hole and the ledge on which the waveguides rested was .06 or .08 inches. Both of these parameters should have given equivalent cavities, but when tested, it was seen that the first cavity had a worse Q (it had a rougher finish) but was also much more overcoupled. However, the loss through the weak port was -50 dB as expected. The second cavity had a higher Q, was less overcoupled (although still slightly overcoupled), but had a much higher loss of -68 dB. 

\begin{figure}[htbp]
\begin{subfigure}{\textwidth}
\centering
\includegraphics[width=\textwidth]{warms11}
\caption{Room temprature cavity frequency, Q, and coupling. Plot of reflection coefficient $|\Gamma|^2$ vs detuning from resonance $f_{\text{res}}$. Unloaded Q and coupling coefficient calculated via formula in Ref \cite{kajfez94}}
\end{subfigure}
\begin{subfigure}{\textwidth}
\centering
\includegraphics[width=\textwidth]{colds11}
\caption{Cavity at 77 K in liquid nitrogen.}
\end{subfigure}
\end{figure}

 The cavity was designed so that there would be no mode crossings within the frequencies scanned.  The resonance frequency shifts by 100 MHz from 34.407 to 34.517 GHz (dielectric rod not full retracted) when going from room temperature to 77 K; this is consistent with the thermal contraction of copper, whose fractional expansion coefficient in going from room temperature to 4 K is $\Delta L/L = 0.324\%$ Ref \cite{ekin06}.
 
 \begin{figure}[htbp]
\includegraphics[width=\textwidth]{1}
\caption{Cavity trace from VNA at room temperature.}
\end{figure}
\begin{figure}
\includegraphics[width=\textwidth]{20}
\caption{Cavity trace from VNA when cooled to 77 K.}
\end{figure}


 \begin{figure}
 \begin{subfigure}{\linewidth}
\includegraphics[width=\linewidth]{chart_5(3)}
\caption{Tuning (warm): loaded Q vs frequency}
\end{subfigure}
\begin{subfigure}{\linewidth}
\includegraphics[width=\linewidth]{chart_8}
\caption{Tuning (warm): frequency vs rod insertion depth}
\end{subfigure}
\end{figure}

%\begin{figure}[htbp]
%\includegraphics[width=\linewidth]{chart_7}
%\caption{Bench tests (warm): coupling coefficient vs frequency}
%\end{figure}

%Although it is impossible to perform the same test with the cavity in situ because we cannot make a reflection measurement on the strong port (we don't have space to put in a directional coupler), we see that the loaded Q is THIS at 4 K. 

%PLOT OF SIMULATED FREQ COLD AND ACTUAL FREQ COLD

%The simulation predicts that going from warm to cold, the thermal contraction taken into account and keeping the conductivity the same, that you should get so much change in the coupling and frequency.

%The simulation predicts that you can tune over a XXX frequency range without a mode crossing. It also predicts that the Q should degrade by YYY over a certain range. The form factor is predicted to be ZZZ. What we see in practice is that there is a mode crossing (warm); in situ, there is a blind spot. The upper and lower modes should be TE112 and TM010.

\subsection{Assembly with Tuning Mechanism}
The cavity is a right circular cylinder made of OFHC copper. The cavity has two aperture couplings on the side - these apertures go to WR28 waveguide, which is soldered on. The cavity has a removable bottom lid, which can be screwed on with 2-56 screws with Belleville washers - it has a groove for an indium seal, with the outer lip of the groove tapered off. This ensures the contact happens between the inner lip of the groove and the cavity bottom.

The cavity assembly consists of the cavity body, two waveguides, and tuning sub-assembly. The tuning rod is an alumina dielectric rod with dielectric $\epsilon = 9.2$. The loss tangent from the literature is $< 10^{-5}$ at Ka-band frequencies and thus can be neglected in comparison to the loss due to the walls: $1/Q_0 \approx 10^{-4}$.

The tuning rod is held in place with a pin socket which is press fit to a copper disk. A BeCu bellows is brazed to this disk, and the bellows itself is encased in a sleeve. The rod is moved by force from above; a lever arm translates the off-center motion of a G-10 rod rotating on a 100 threads per inch fitting into vertical motion on the rod. The range of the lever arm is 16.9$\deg$ for a total of .185 inches of rod travel.

At room temperature the assembly was tested for vacuum leaks. Weak points were the solder joints between the waveguides and the cavity body, the brazing joints holding the bellows to the outer caps. These joints were resoldered or re-brazed until the assembly had no vacuum leaks at room temperature.

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{full-thing}
\caption{Cavity Assembly}
\end{figure}

\begin{figure}[htbp]

%\begin{subfigure}{0.5\textwidth}
%\includegraphics[width=\textwidth]{bellows-subassembly}
%\caption{Bellows sub-assembly showing bellows cap and o-ring}
%\end{subfigure}
%\begin{subfigure}{0.5\textwidth}
%\includegraphics[width=\textwidth]{top-view}
%\caption{Top-view}
%\end{subfigure}
\begin{subfigure}{\textwidth}
\centering
\includegraphics[width=\textwidth]{bellows-subassembly2}
\caption{Bellows-sub-assembly}
\end{subfigure}
\begin{subfigure}{\textwidth}
\centering
\includegraphics[width=\textwidth]{outline}
\caption{Cavity body and Waveguides}
\end{subfigure}
\begin{subfigure}{\textwidth}
\centering
\includegraphics[width=0.58\textwidth, angle = -90]{cavity-outline}
\caption{Cavity body}
\end{subfigure}
\end{figure}

%\begin{figure}[htbp]
%\includegraphics[width=0.76\textwidth,angle=-90]{cavitylaidout}
%\end{figure}

%\begin{figure}[htbp]
%\begin{subfigure}{0.4\textwidth}
%\includegraphics[width=\textwidth]{hemts}
%\caption{Waveguide to coax adaptor and two HEMTs with 3 dB attenuation between them. The adaptors have been potted with forr seal to make them vacuum tight.}
%\end{subfigure}
%\begin{subfigure}{0.4\textwidth}
%\end{subfigure}
%\begin{subfigure}{0.3\textwidth}
%\includegraphics[width=\textwidth]{bottomofinsert}
%\caption{Insert shown without amplifiers. Cavity is connected to tuning mechanism and waveguides.}
%\end{subfigure}
%\end{figure}

%\begin{figure}[htbp]
%\includegraphics[width=0.6\textwidth]{efieldhfsssim28thou}
%\caption{HFSS Simulation of electric field magnitude in the $TM_{020}$ mode of the cavity.}
%\end{figure}


%The theoretical unloaded Q \ref{rogers89}:
%
%$$Q_0 = \frac{\mu}{\mu_c} (\frac{\mu_c \omega \sigma}{2})^{1/2} \frac{V}{S} \cdot 2 $$
%
%$\mu$ and $\mu_c$ are the permeabilities of the cavity interior and walls in MKS units, which are nearly equal to $\mu_0$ for helium and copper: $\omega$ is the resonant frequency and $\sigma$ the conductivity of the walls.

%\begin{figure}[htbp]
%\includegraphics[scale=0.7]{freq_vs_turn_number}
%\caption{TE mode freq tuning}
%\end{figure}

We tune using a 1/16th inch thick dielectric rod ordered from McMaster, with the suppliers originally being Coorstek. THis alumina rod is secured with a pin socket soldered to a copper top hat. This has a groove for an indium seal and this hat is screwed on to the top face of the cavity. There is a small beryllium copper bellows soldered on to the top of the top hat, and this is encased in a tube which provides structural support to make sure the bellows only has one degree of freedom in the vertical direction. 

There is a lever arm that pushes the bellows up or down - this is controlled by a G-10 tube that connects from a screw at the top of the cryostat which we manually turn, and thus allows us to translate the rotation motion into translational motion of the lever arm. 

%\begin{figure}[htbp]
%\centering
%\includegraphics[width=0.7\textwidth]{insertdrawing}
%\caption{Model of the insert, showing cavity at bottom}
%\end{figure}
%\begin{figure}[htbp]
%\includegraphics[width=0.8\textwidth]{experiment}
%\caption{Picture of cryostat bolted onto magnet, with insert in background.}
%\end{figure}


\section{The HEMTs}

The low noise amplifiers are placed in the cryostat and are High Electron Mobility Transistors (HEMTs). We have two cascaded together, with a three dB attenuator between them. The first amplifier (both were ordered from Sandy Weinreb at Caltech) was measured by him to have a minimal noise temperature of 35 K at a physical temperature of 15 K and 34.3 GHz, and a noise temperature of 150  K at room temperature. The second amplifier has slightly worse characteristics - the noise temperature at 15 K is given as 90 K and at room temperatue it is 168 K (we only have room temperature data up to 26 GHz). The gain for the optimal voltage settings to operate cryogenically are given by Sandy Weinreb as $32.2 \pm .2$ dB for the first and $27.5 \pm .2$ dB for the second.

\begin{figure}[htbp]
\includegraphics[width=\textwidth]{weinrebgain}
\caption{Gain of 1st amplifier measured by vendor}
\end{figure}

Put in the VNA screenshot of the amplifier gain at room temperature here.

There are two HEMT voltage settings that produce an optimal gain/noise combination for the different temperatures. We adjust the voltage (adjusting for resistive losses due to the cables between the power supplies) for the cold setting during cool-downs.

\subsection{Noise Temperature} 
We measured the noise temperature of the first cryogenic amplifier by doing a Y-factor measurement. This meant using a $50$ ohm RF termination as noise source and varying the temperature while keeping the HEMT thermally isolated. We did this by connecting the termination to the HEMT via a two and a half inch long piece of stainless steel co-axial cable. The termination was encased in a copper block, which had a central hole through which a carbon resistor of 1 k$\Omega$ was placed, with thermal grease applied to increase the contact between the copper block and resistor. Current was injected into the resistor which heated the copper block and thus the terminator; by measuring the difference in the output noise power we can extract the amplifier intrinsic noise temperature. The electrical loss of the stainless steel coax segment was measured to be 0.5 dB and included in the calculations.

\begin{figure}[htbp]
\includegraphics[width=0.6\textwidth]{noisetempmeasurement}
\caption{Photograph showing copper block and first amplifier. The heating element is a 100 k$\Omega$ resistor threaded through the block. A cold finger is attached to the amplifier.}
\end{figure}

$P_{out} = k_B G B(T+T_a)$

for gain $G$ and bandwidth $B$. The gain here is the total gain of the cascaded amplifiers minus the losses of the waveguide and cables before detection with an Agilent signal analyzer. 

The noise contributions from the later stages in the amplification scheme are negligible:

\begin{align}
T = T_1 + T_2/G_1 + T_3/G_2 + \ldots
\end{align}

for $T_1 = 15 K$ and $G_1 = 27$ dB, for the second amplifier with noise temperature given by the vendor of $100$ K, this would only contribute $100/10^{2.7} = .1$ K to the total noise temperature.

\begin{figure}[htbp]
\includegraphics[width=\textwidth]{yfactor5}
\caption{Y-factor measurement of the 1st HEMT noise done using a 50 Ohm load in a copper block. We heated the block quickly and used a short stainless steel segment in order to thermally isolate the hot block from the HEMT. The plot shows  the  output power measured over a resolution bandwidth of 3 MHz on the spectrum analyzer as a function of frequency.}
\end{figure}

\begin{figure}[htbp]
\includegraphics[width=\textwidth]{yfactor6}
\caption{Noise Temperature measured with the Agilent Signal Analyzer N9030A. Weinreb measurement refers to the measurements made by the JPL group, which found a noise temperature of the first HEMT of 35 K for a physical temperature of 20 Kelvin. }
\end{figure}



Let us neglect the effect of the waveguide to coaxial adaptor. Then the noise at the input of the 1st cryogenic amplifier is the sum of the load and amplifier physical temperatures plus the intrinsic electronic noise temperature of the amplifier:

\begin{align}
T_{sys} = max(T_{HEMT}, T_{load}) + T_N
\end{align}

If we assume that the noise temperature of the amplifier remains constant over a small range of physical temperatures, say 4-10 K, then by doing the Y-factor measurement with the HEMT at approximately the same temperature and the load temperature varied, we see that 

\begin{align}T_{a} \approx 15\text {K}
\end{align}

This gives us the minimal noise temperature. We can get a sense of the maximal noise temperature as well; with a detuned run, as the physical temperature increases we can use the variation in temperature to see that the noise temperature for a source impedance close to 1 is around 34 K.

SHOWDETUNEDRUN

The total gain of the system is calibrated by inserting a 50 ohm terminator in place of the cavity and cooling the system. 

SHOWFIFTYOHMRUN
\begin{figure}[htbp]
\includegraphics[width=\textwidth]{fiftyohmruns-witherrorbars-bothdatasets-notransferfunction}
\caption{The output power density in the receiver as a function of LO frequency for a 50 ohm terminator in place of the cavity for a cool down. The 1st HEMT temperature was 9.3 K for the no switch runs, and 9.1 K for the switch runs.}
\end{figure}

\section{Input match of the first cryogenic amplifier}

The input return loss is specified by the vendor to be greater than 9 dB at 26 GHz. The output return loss is is stated to greater than 14 dB at 26 GHz. The input return loss means that up to  12.5$\%$ of the power is reflected at the input to the amplifier. This is significant and complicated by the fact that there is an additional source of impedance mismatch due to the waveguide to coax adaptor. We use two end-type waveguide- coax adaptors from Maury Microwave to allow the HEMTs to be inserted in the waveguide assembly, stated to have a VSWR at room temperature of 0.15. This translates to a power reflection coefficient of 4$\%$. The room temperature power reflection coefficient should not depend on temperature, so we take these values to be correct for our cryogenic operating conditions. If the power reflection coefficient did vary significantly with temperature, this would be reflected as a high noise temperature. However, we do not see this effect.

%\subsection{The first cryogenic amplifier coupled to the resonant cavity}
%
%The cavity to amplifier coupling has been treated well in other works Ref \cite{dawthesis98}; here we sketch the basics. 
%
%\begin{figure}[htbp]
%\includegraphics[width=\textwidth]{penfieldnoise}
%\caption{Model the noise of the amplifier as two uncorrelated waves traveling away and towards the amplifier. From Penfield \cite{penfield60}}
%
%The temperatures of these waves are 
%
%\begin{align}
%T_a = |a_n|^2/kB \\
%T_b = |b_n|^2/kB
%\end{align}
%
%For a source impedance $\Gamma_s$ the power at the input to the noiseless amplifier is $T_a + T+b|\Gamma_s|^2$. For a line of length $L$ between the source and amplifier, this becomes $T_a +T_b|\Gam
% 
% The cavity can be treated as an RLC circuit, with an axion signal appearing as a voltage source. The coupling of the cavity to the waveguides is equivalent to a transformer, and the length of waveguide between the cavity and amplifier introduces a phase delay with some attenuation constant. The noise temperature of the HEMT can be modeled as two independent noise sources; one a current source and the other a voltage source. Equivalently, the HEMT noise can be treated in a wave model as two independent waves traveling towards and away from the cavity. This is more convenient to work with as it allows us to express terms in quantities of temperatures.
% 
% The noise power emitted in bandwidth $B$ at the cavity coupling port is 
% 
% \begin{align}
% T_{cav}(z=0) = kBT(1- |\Gamma|^2)
% \end{align}
% 
% where $\Gamma$, the reflection coefficient, is $\Gamma = \frac{Z_0 - Z_c}{Z_0+Z_c}$.
% 
% Ignoring the impedance mismatch of the HEMT and waveguide-coax adaptor for now, when we now account for the line length between the cavity and amplifier, the power reaching the amplifier has an associated phase delay
% 
%\begin{align}
% T_{cav}(z=L) = e^{i\beta L}T_{cav}(z=0)
%\end{align}
% 
% where $\beta$ is the attenuation constant of copper waveguide. 
% 
% Now adding in the effect of the noise power coming from the amplifier,
% 
% \begin{align}
% T(z=L) = T_{cav}(z=L) + (e^{-i2\beta L}\Gamma)T_{noise,+} + T_{noise,-}. 
% \end{align}
% 
% all of which means that to completely parametrize the cavity-amplifier interaction, we need to know five parameters: L, $\beta$, $T_{noise,+}$, $T_{noise,-}$, and $\Gamma$.
% 
% This is further complicated if we try to account for a non-zero reflection coefficient at the amplifier. 
% 
% In previous dissertations in the ADMX group, they developed a five-parameter model to describe this interaction - we applied the model to our data and see that it fits well. In practice however, we use an empirical fit to take out the effect of the cavity-amplifier interaction, as will be described in Chapter 4.
%
%\section{The gain of the cryogenic amplifiers at cryogenic temperatures}
%
%It is important to make an 'in situ' measurement of the gain of the first cryogenic amplifier and the results compared with gain data supplied by Sandy Weinreb. 

\section{Room Temperature Hardware}

The room temperature electronics serve to further amplify, filter, and mix the signal to baseband. The output of the cryogenic amplifiers is carried through three meters of waveguide and fed into a mixer and then further amplification.

\begin{figure}[htbp]
\includegraphics[width=\textwidth]{schematicnew}
\caption{Schematic of experiment}
\end{figure}

\begin{table}
\centering
\begin{tabular}{| c | c | c | c |}\hline
\hline
Component & Gain (dB) & \multicolumn{1}{|p{2cm}|}{\centering Power Density \\ (dBm/Hz)} & Total Power (dBm) \\ \hline \hline
Cavity & - & -185 & -  \\ \hline
Cryogenic Amplifiers w/ 3dB atten. & 50 & -144 & - \\ \hline
Waveguide to Shielded Room & -3.4 & -148.6 & -\\ \hline
RF switch & -2.7 & & \\ \hline
RF filter & -0.2 & - & -\\ \hline
RF mixer & -12 & x & x\\ \hline
Cable to Electronics & - & - & - \\ \hline
16 dB attenuation & -16 & - & - \\ \hline
1.5 GHz Bandpass Filter & -0.5 & - & - \\ \hline
4 GHz Amplifier & 59.5 & - & - \\ \hline
Bandpass Filter & -0.5 & - & - \\ \hline
4 GHz - 590 MHz Mixer & -6.5 & - & - \\ \hline
25 MHz Bandpass Filter & -2.3 & - & - \\ \hline
590 MHz Amplifier  & 34 & - & - \\ \hline
25 MHz Bandpass Filter & -2.3 & - & - \\ \hline
590 Mz to DC IQ Mixer & -8.5 & x & x \\ \hline
4 MHz Low Pass Filter & x & - & - \\ \hline
50 Ohm Voltage Pre-Amp  & x & - & - \\ \hline
\end{tabular}
\caption{Power levels at different points (in dBm) in the receiver chain. At each point in the receiver chain the total broadband noise power over the bandwidth of the next component is insufficient to cause saturation}
\label{table:rxchain}
\end{table}

\begin{table}[htdp]
\caption{Model Numbers}
\begin{center}
\begin{tabular}{|c|c|}
4GHz amp & MITEQ AFS33-04000420-20-10P-GW-44 \\ \hline
RF mixer & MITEQ M2640W1 \\ \hline
another amp & MITEQ AFS3-00100400-13-10P-4 \\ \hline
4GHz Filter & Spectrum Microwave 311-517144-001\\ \hline
4MHz filter & Spectrum Microwave 311-527062-001 \\ \hline
IQ mixer & MITEQ IR0502LC1Q
\end{tabular}
\end{center}
\label{default}
\end{table}%

A vacuum window is in place after the directional coupler which allows us to pump on the waveguide. Then comes a waveguide RF filter with a bandpass from 32.6-36 GHz. Then a waveguide to coax adaptor, and a a mechanical RF latching switch (RLC electronics 1 pole 2 throw). The custom receiver chain was designed by Penny Slocum, with three stages of mixing and bandpass filters to suppress image frequencies and harmonics. The image frequency is at $\omega_i = \omega_{LO} - \omega_{IF} = 2\omega_{LO}-\omega_{RF}$. The first LO comes from Anritsu MG3694C signal generator (so is tunable) with output power level of +15 dBm and goes to the mixer with conversion loss 12 dB that mixes the signal to the 4 GHz range. The image frequency for a 34.29 GHz RF signal would be 26 GHz (assuming LO mixes RF down to 4.09), which is attenuated by the waveguide RF filter. Then there are two cascaded amplifiers in the 4 GHz with total gain 60 dB (and a filter before and after them with width 1.5 GHz around a central frequency of 4.1 GHz), and second mixer with local oscillator fixed at 3.5 GHz. This mixes the signal down to around 590 MHz. Again, the image frequency is now 2.1 GHz. There is then another amplifier with 30 dB gain, and a 25 MHz filter around 590 MHz (again before and after the filter). The image frequency at this point is the same as the input frequency as we are mixing down to DC. The last mixer is an IQ mixer that mixes 590 MHz down to zero. There are two outputs, the I and Q channel, and each has a 4 MHz lowpass filter at the output. THe BNC outputs go to an SRS SR445A voltage pre-amplifier, set to 50 ohm input impedance and voltage gain of 5. This then goes to the PCI-5114 digitizer card, which samples at a 10 MHz rate set by the external digital clock with a resolution of 8 bits. The reference clock is the 10 MHz clock inside the signal generator which send out the first local oscillator signal.

\begin{figure}[htbp]
\includegraphics[width=\textwidth]{roomtempelectronicson}
\caption{Response of room temperature electronics chain}
\end{figure}

Once the signal is mixed down an offline script computes the discrete Fourier Transform to look at the voltage spectrum of the I and Q channels, the squared sum of which is the power spectral density. The Fourier Transform is computed using the FFTW libraries. For each spectrum, 294 samples were taken for each I, Q channel, yielding a 294 point power spectrum.

%The details of the mixing sequence are as follows: the first mixer has an LO input from a signal generator that can give out signals at frequencies up to 40 GHz. We usually set the LO to 30.2 GHz for RF signals to the input of 34.29 GHz. This would make the intermediate IF frequency around 4.09 GHz.There is then 60 dB of amplification and further filtering before the second mixer, which has a fixed LO frequency of 3.5 GHz. The IF then becomes 590 MHz. With more filtering and another 30 dB of amplification the 590 MHz signal enters an IQ mixer, which separates the in phase and quadrature components of the signal and mixes both down to baseband. There are two 25 MHz (or 4MHz) filters on the I and Q outputs, which determines the final bandwidth of our home made analyzer.
%
%All these elements are commercial and from MITEQ. The reason for filtering is to suppress image frequencies (frequencies $f_{image} = f_{LO}-f_{IF}$) since there are two frequencies that can mix down to the same intemediate frequency. The reason for the particular values of the local oscillator frequencies is that they are all multiples of 10 MHz so they can be all phase locked with a 10 MHz reference clock (in this case the clock is from the Anritsu signal generator) and the reason for the three stages of amplification is that these components seemed like a good idea.

The output power of the I channel after going through a voltage pre-amplifier is -97 dBm/Hz when looking at the thermal noise of a ~5 K cavity before the LNAs. The output power of the Q channel is usually -96 dBm/Hz. The difference between them are due to imperfections in the I/Q mixer.

\chapter{Data Analysis}
\section{Data Acquisition and Analysis}
The data acquisition of the voltage time series controls the PCI digitizer card and sets the number of samples to acquire. This was written by Penny Slocum in C$\#$. 
%\begin{figure}[htbp]
%\includegraphics[width=\textwidth]{snapshotofdaq}
%\caption{The DAQ user interface. Written in C$\#$ by Penny Slocum, with minor adjustments made by me for logging and overflow problems. The DAQ digitizes the data and streams it to disk continuously, with $2.56\times10^6$ points per record acquired.}
%\end{figure}

Before running the data acquisition program, the cavity resonance is manually set and then the Q and bandwidth are measured with a vector network analyzer. Two microwave switches were installed to allow for the network analyzer to be directed to the cavity via the calibration waveguide, and also to allow test tone signals to be injected into the system.

The temperatures of various points along the cryostat are monitored continuously during data taking. One temperature sensor is connected to the bottom plate of the cavity, another to the first cryogenic amplifier, one connected to two points half way up the insert, and another on the vaporizer. The temperature sensors were produced and calibrated by Lakeshore Cryotronics Inc.  

%Five were used and they were attached at a) bottom plate of cavity, b)vaporizer c) cryogenic amplifiers, and d) two in the middle of the insert. The temperature sensors were calibrated to typically within a tenth of a degree Kelvin of the true temperature, and were read out with a temperature sensor controller also produced by Lakeshore.

%\begin{figure}[htbp]
%\includegraphics[width=\textwidth]{snapshotoftempmon}
%\caption{Written by Sergey Schkelunov. The Labview interface records the temperature of the sensors and plots the most recent points. A 50 ohm resistor is in place near the vaporizer. We use a power amplifier to and a heater control loop to control the temperature at the vaporizer. Practically speaking it is often more productive to wait until the cryostat has stabilized rather than try and use the heater to stabilize the temperatures.}
%\end{figure}




%\section{Data}
%
%To date we have performed two experiments - one using a single "quiet" cavity in the magnetic field, cooled to 4 K, and one using two cavities, with one quiet cooled cavity and the other driven by an RF source.

%The first experiment looked at the TE011 resonance (tunable but centered around 34.29 GHz) and tried to set a limit on the possible scalar particle-photon couplings that this setup could potentially detect. The starting assumptions are that the dark matter halo has a density of these scalar particles given by  $10^{13}$ GeV/${cm}^3$ which acts as the initial seed for these particle-photon conversions. The reason photon-particle conversions are not seen as a cancelling effect is that the number of photons is so much less than the number of particles that we have a huge population inversion $n_{ALP} >> n_{\gamma}$, and also that these conversions are so rare that a particle-photon-particle conversion and then reconversion would be suppressed by an extra factor of the weak coupling.
%
%The particle-photon conversion is stimulated by the presence of the strong magnetic field and enhanced in the region of a cavity, since there are fewer states that a cavity can support, therefore by Fermi's golden rule the transition probabilities of going from this continuum particle state to the discrete mode state of the photon are higher. This is known as the Purcell effect when talking about enhancement or suppression of spontaneous emission of an atom in a cavity.
%
%So the expression for the probability of conversion goes as the number of particles available to emit a photon (nV), the probability of a single particle conversion in free space with a magnetic field $(gB)^2$, the overlap integral expressing how likely the emitted photon is to be in the particular mode j we measure $(f_{j})$, and the enhancement by the Q of the cavity (Q). By conservation of angular momentum the emitted photon must have the same polarization as the magnetic field (really this is a two photon interaction, with the magnetic field providing a "virtual" photon), so since the magnetic field is axial, for a scalar interaction the emitted field must be a $TE$ mode (meaning the only axial field is magnetic, not electric).
%
%Therefore we have $P_{a\gamma} = (gB)^2 nfVQ.$ If the density is, as commonly the case, written as the energy density and not the number density we have $P_{a\gamma} = (gB)^2 n_e f_{j} VQ/m_a$, where natural units are assumed.
%
%Unfortunately the problem with looking for particles that give off photons whose wavepacket overlaps in a non-zero way with the $TE_{011}$ mode or in fact any $TE$ mode is that due to symmetry considerations, the overlap integral is in general very small or zero. The reason is because of boundary conditions -by Maxwell's equations the incident normal B field on a conductor must be zero, so for the axial magnetic field $B_z$, the boundary conditions imply $B_z(z=-L/2)=B_z(z=L) = 0$ so all $TE$ mode have an even $B_z$ field around $z=0$. But because of cylindrical symmetry, the value of $B_z(z,r=R)$ must be the same at diametrically opposed sides of the cylinder (at least for the lowest order mode). Because there are no magnetic monopoles, the magnetic field must integrate to zero. 
%
%As well, I was lying when I said $f_j$ goes as the integral of $B_z$. If you go through the equations of motion for Maxwell's equations with a source term of the form $B_z\cdot B_{magnet}$, the source term is actually second order with regards to $g$.
%
%Both of these things make it extremely hard to detect scalar particles in microwave cavities due to symmetry considerations and magnetic field properties.
%
%We nonetheless performed the experiment and were able to exclude $g > 10^{8}$ 1/GeV for masses $~0.14$ meV.

%The second experiment performed was for a two cavity detection method. Here the photon-particle-photon process is employed. By using an RF source as the photon source, we hope to produce these weakly interacting particles. Applying conventional shielding (any material) will attenuate the photons but not the particles. However to detect them we need to convert them back to regular photons. Since this process involves to extremely rare events, it suffers from the $g^4$ factor, but with a high intensity source of photons and using enhancement of the generation and detection volumes, one can improve the sensitivity to make experimentally interesting measurements. One caveat - having a high Q in the detection region will enhance sensitivity due to the Purcell effect as discussed above, but the Purcell effect is not what allows us to get enhancement by Q in the generation region. This is just due to the fact that the power in a cavity scales as the input power times Q.
%
%Instead of $f_j$ we now have $G$, the geometry factor, in the probability of this process occurring. $G$ takes into account the modes of each cavity and the distance between them.
%
%For vector particles, $G ~ 0.12$ for two $TE_{011}$ cavities separated by 3 cm. For scalar particles $G = $ I don't know for scalars, probably zero since the generation probability is zero. And of course zero for pseudoscalars which need a different polarization of the mode, since we were only looking at the $TE$ mode. However maybe it is non-zero for another mode.
%
%For this two cavity experiment, we drove one cavity $TE_{011}$ mode with a signal generator set for its maximum stable output of 22 dBm or 158 mW. The signal was a cw signal at the cavity resonance, usually 34.299 GHz, although it changed by about 300 KHz due to variations in room temperature. The bandwidth of the signal is very small, about 0.1 Hz. There was approximately a meter of waveguide between the cavity and the signal output, as well as a directional coupler and isolator between the two. At 34 GHz the loss of wr28 is 3 dB/m, and since the cavity was observed to be not critically coupled, there is probably more than 6 dB of power that does not get into the cavity. This changes the power entering the cavity to about 16 dBm, or around 30 mW. For a Q of  around 7,000,  this means that the power circulating in the cavity is in general around 210 Watts. Is this right? I am not sure, it seems to be wrong. Need to look at accelerator books and people who talk about RF power.
%
%As the cryostat is in the bore of the magnetic field, the driving cavity is also placed in the bore, next to the cryostat. Thus the walls of the driving cavity, the cryostat walls, and the walls of the quiet cavity all act as layers of attenuation for regular photons. We cool the quiet cavity down to 4 K to reduce the background thermal noise, and encase the electronics for mixing and analyzing the RF signal in a metal room which acts as a Faraday cage to close off any potential interference from the 22 dBm source.
%
%Our first measurements showed that there was an intermittent signal at our frequency of interest on the level of 3 dB above the thermal noise background. We had the driving cavity detuned with respect to the driving frequency $\omega_L$, so the observed spike, if from hidden photons would have to come from a process whith only one Q and a much lower G, since it would have to convert from the circular mode of the waveguide which connects to the cavity. So by suppressing any possible $\gamma'\rightarrow \gamma$ conversions, we test for interference exclusively. When the quiet cavity and driving cavity were retuned, the leak appeared to be larger, but still intermittent. We suspected that the interference was happening in the electronics, not through the cryostat or cavity. Two suspects were the power leads for the LNAs that could carry an RF signal down into the cryostat or the various connections in the mixing scheme which could pick up EM leakage. At room temperature with the LNAs powered off, the spike was observed but disappeared by closing the door to the shielded room encasing the electronics. At room temperature with the LNAs powered on ... this has not been tested.
%
%With the parameters in our setup we were able to place an exclusion limit on the coupling of vector particles to photons for $\chi > 10^{-7}$ 1/GeV.


%Maybe some ideas would be trying to use metamaterials or do mode-locking somehow. I don't think our amplifiers have the bandwidth to support more than two, maybe three modes mode-locked and I haven't seen anything that says that people have tried to mode-lock microwave cavities, but this woud emit radiation at higher peak intensties because they would all be emitted in one short burst. I thought this would improve our 
%signal to noise but maybe it wouldn't because we only care about fluctuations in the signal and these are not different are they? I don't know.
%Also a way to get around the high frequency, small volume problem seems to be to make it not be a problem - ie find ways to make high volumes resonate at high frequencies in low order modes. So we need an anti-dielectric, which will increase the frequency rather than lower it. Dielectric smaller than one only exist as things called metamaterials and I don't know their RF properties.
%Or maybe mode-locked detectors could help us because of the thing of pulsed things having better signal to noise than cw things. Not really sure.


%\section{Receiver Noise Figure}
%
%Because of the Friis formula the noise in the entire electronics analyzing chain is dominated by the noise of the first amplifier if it's gain is high enough.

%\section{HSP Introduction}
%
%We also did a HSP search using two $\text{TE}_{011}$ cavities. There was one $\text{TE}_{011}$ cavity that was not tunable and had a resonant frequency of 34.29 GHz. It had one aperture coupling on the bottom face where it went to 13 mm cylindrical waveguide and then to WR28. There was a meter and a half of this between an isolator and directional coupler and before all of that a signal generator capable of putting out 25 dBm but in practice we operated it at 22 dBm because it would output a warning that the power was unleveled at 25 dBm. 
%
%There the reflected power went through the directional coupler to a spectrum analyzer.
%
%The $\text{TE}_{011}$ cavity (signal cavity Iâll call it) was inside the bore of the magnet but outside the cryostat
%
%SHOW SCHEMATIC OF EXPERIMENT
%
%EMI Shielding
%
%There are many shielding improvements made iteratively. I list them below:
%
%1. Aluminum Wool in Bore of Magnet
%2. Copper Tape Over Joints of WR28 connections
%3. Copper tape over Vacuum Tube connections in Shielded Room
%4. Terminator on Cable to Weak Port when Disconnected
%5. HEMT power supplies moved to different room than both magnet and shielded room
%6. Everything locked to 10 MHz reference
%7. Shielded Room Shut and Run on Battery Power
%8. 10 MHz BNC cable hole drillled in shielded room wall and had RF absorbing foam placed around opening
%9. Aluminum Wool Placed in Holes leading HEMT power supply cables out.
%10. One HEMT power supply grounded through another HEMT power supply.
%
%\section{Expected Sensitivity}
%
%As the power is monochromatic, by reducing the resolution bandwidth we decrease the noise in each bin while the power stays the same. The size of each resolution bandwidth is inversely proportional the number of samples we acqure, and thus the integration time. The exact formula is 
%
%resBW = 1/tau
%
%When no windowing is used.
%
%\section{Thermal Noise - As Expected?}
%
%\section{Hypothesis Testing}
%
%\section{HSP Results}
%
%Hopefully we can redo these results, but we were able to make an exclusion based on non-observation of a peka in a 2.5 minute run.
%
%\begin{figure}
%\includegraphics[scale=0.3]{malagon_ana_fig2}
%\end{figure}
%\begin{figure}
%\includegraphics[scale=0.3]{malagon_ana_fig3}
%\end{figure}
%
%\begin{figure}
%\includegraphics[scale=0.3]{malagon_ana_fig4}
%\end{figure}



%\section{Signal injection}
%
%It would be advantageous to inject a synthetic axion line int othe experiment cavity. the benefits are simple, we could test different search algorithms and determine their relative performance without the need for Monte Carlo methods in the data analysis. The scheme for inject this synthetic signal is simple and is sketched in Figure 3.
%
%The synthetic axion line would be injected into the cavity during data taking via the weakly coupled minor port. 

%I've demonstrated that a single synthetic axion line can be injected into the cavity and detected with the receiver chain. The next step would be to calibrate the power level of the injected signal inside the cavity from the noise power and then automate the procedure. With sufficient statistics the search confidence can be validated by search algorithms to be discussed in Chapter 4.


%\section{Data Runs}
\begin{figure}[htbp]
\includegraphics[width=\linewidth]{frequencycoveragepretty}
\caption{The first runs were taken with a slow DAQ that operated with 60$\%$ deadtime. The runs taken at 33.4 GHz had the cavity filled with helium. A heater feedback loop was put in place and an RF switch installed to toggle between the network analyzer and the receiver. In April 2014 the insert was taken out to study the dead spot between 33.368-33.398 GHz. Andrew Martin discovered it was due to the weak coupling port being so weakly coupled that at those frequencies no power was entering the cavity. The coupling was raised by adding a 20 thousandths metal shim in the bottom of the waveguide, adjusting the effective coupling.}
\end{figure}

%We used a cylindrical cavity cooled to $\sim 5$ K resonant at a frequency of $33.9-34.5$ GHz in the $\text{ª}_{020}$ mode. The cavity was tuned to a specific resonant frequency using a dielectric rod; we measured the resonant frequency and Q using a vector network analyzer, then recorded the amplified noise from the cavity (after being mixed down to baseband) for an hour before retuning the cavity by 3 MHz. The baseband noise when Fourier transformed is a measure of the power in each frequency interval $\delta f$ that is the sum of the power in the cavity plus additional noise from the receiver chain. 

%We recorded data in twelve separate runs (Nov 19 to May 30, 2014), and measured noise for 500 settings of the cavity frequency, with an hour of integration. The actual performance of our system

%Summary of Runs
%\begin{center}
%\begin{tabular}{c | c | c }\hline
%\hline
%Run & No. of Freq.'s & State \\ \hline \hline
%11/19-11/22 & 9 & slow DAQ \\ \hline
%12/03-12/07 & 39 & faster DAQ \\ \hline
%12/10-12/13 & 22 & tuning rod froze\\ \hline
%12/16-12/20 & 27 & RF switch added\\ \hline
%01/08-01/11 & 46 & heater feedback loop online\\ \hline
%01/14-01/18 & 69 & 00 \\ \hline
%01/23 & 5 & -- \\ \hline
%01/28-02/01 & 41 & test tone added \\ \hline
%02/04-02/07 & 33 & tuning rod froze\\ \hline
%02/11-02/13 & 19 & -- \\ \hline
%03/10-03/13 & 16 & -- \\ \hline
%05/06-05/09 & x & weak coupling port altered, test tone removed\\ \hline
%05/14-05/17 & x & -- \\ \hline
%05/28-05/30 & x & -- \\ \hline
%\hline
%\end{tabular}
%\label{table:runsummary}
%\end{center}

\subsection{Procedure during normal running}

The data acquisition system (computer plus sensors plus instruments) measures important parameters, e.g. temperatures, pressures. As discussed earlier, the important cavity parameters are the cavity quality factor Q, center frequency of the cavity, strength of magnetic field, and cavity physical temperature. Once these quantities are measured, we manually tune the tuning rod by an amount corresponding to 3 MHz (approximately xx length). The cavity resonance moves, the cavity parameters are then measured, and then a 1 hr time trace is acquired as a two channel system and saved to disk in little-endian binary format as signed 8-bit integers.

%The binary data format compresses the information by a factor of xx in relation to ASCII (Text) format. The data format is as follows: there is a xx byte header, followed by the 2948-bit integers plus three FFT parameters. The following table shows the axion data format taken for these data.
%
%There is a potential issue in saving data with one computer and then post-processing the data on another. Data might be "big endian" or "little endian", referring to the byte order of how floating point numbers are read by different computer platforms. The mismatch was solved with a byte swapping routine, which first checked whether the data made sense if the data was in one endian form or another. Once established, the endian issue is resolved and the post-processing computer performs the analysis.

\begin{table}
\centering
\begin{tabular}{| c | c ||}\hline
\hline
Description & size (bytes) \\ \hline
Header & 35 \\ \hline
Gain & x \\ \hline
Offset & x \\ \hline
NumSamples &  xs\\ \hline
NumTriggers & x \\ \hline
Voltage(T) & x \\ \hline
\end{tabular}
\caption{Data format for YMCE running. Each file begins with four numbers specifying the digitizer gain, offset, number of triggers, and number of points in each trigger. It is followed by a header and then the 294 points for the time record}
\label{table:dataformat}
\end{table}

%\subsection{State Parameters}

%Below is a plot of the measured loaded Q over the runs taken.
\begin{figure}[htbp]
\centering
\includegraphics[width=1\textwidth]{loadedQ}
\caption{Q as measured by the VNA E8364C over the course of the runs. The runs with unusually low Q, near 5000, were taken near the "dead spot". After the shim was inserted in the cavity weak port waveguide, these runs were retaken and the Q was normal (near 8000).}
\end{figure}

%\section{Temperature Drifts}
%Another danger is if the cavity gets liquid in it, the resonance is no longer stable. This is probably because it fills up very slowly due to a small but intermittent leak somewhere in the indium seals of the waveguides. This means that whenever we saw the temperature sensors reading less than 4 K, we usually stopped the run and heated the cavity up. Thirdly, we found that the stability of the cavity resonance was more robust to changes if the cavity was at a higher temperature - changes of .5 K at 10 K seemed to affect the cavity resonance much less than at 5 K. One explanation is that the pressure in the cavity altered the resonance frequency - from John Rogers Thesis \cite{rogers87}, in their experiment they saw that there was a 30 kHz/GHz/psi shift. We see a XXX shift.


\section{Cool-down Troubleshooting}

During a typical cool down, we pumped out the sample region and pumped on the cryostat vacuum jacket for several days prior to the run. Then we filled the sample region and capillary tube with helium until the following test was satisfied: in opening the valve which allowed pumping on the sample region, the pressure rose to 10 Torr within 10 seconds. This generally meant that the region had only helium gas in the region. 

The nitrogen reservoir is then filled using the autofill system. This is set to refill every 3-4 hours. We then filled the helium reservoir, which has a capacity of 3 Liters. Depending on the state of the cryostat, the helium consumption can be .75 L/hr or .25 L/hr. We generally found that the lower helium consumption was tied to longer pumping times on the cryostat vacuum, however the temperature of the room and humidity also mattered. As well, we generally had more success with temperature stability after several rounds of helium fills.

It typically took three to four hours for the vaporizer (at the bottom of the cryostat) to reach liquid helium temperatures. At that point the liquid helium was usually depleted and another fill was done. After two fills, we are usually able to begin taking data, although the top of the cryostat continues to cool down, making temperature stability in the first day tricky. 

A heater feedback control loop was implemented in Labview, however, as the flow valve does not have a fine regulator, it is difficult to predict the helium flow rate in each cool down, so regular adjustment of the feedback loop was necessary.  The vaporizer was usually held between 3 and 4 Kelvin; when the vaporizer went below that it was usually a sign of liquid accumulating in the bottom. 

If the cavity temperature drops below 4 Kelvin, this is also a sign of liquid accumulating in the cavity. This can be due to a vacuum leak allowing helium gas to enter the cavity and waveguide assembly and then condensing. Although having liquid in the cavity on first thought seems like a good way to achieve temperature stability, in practice we tried to avoid this state, as the cavity frequency is no longer stable, but moves back and forth every few seconds by around 0.5 MHz. This oscillation may be due to helium boiling in the cavity; the combination of liquid accumulating and bubbles  due to boil-off disturbing the liquid make for an unstable state. 

The waveguide leading from the calibration port of the cavity to the shielded room has a directional coupler attached to it. We use a vacuum feedthrough attached to the coupling port of the directional coupler to pump on the waveguide during cool-downs. This can reduce the chance of liquid accumulation by decreasing the pressure of gas inside the cavity.

\section{Dead Spot}

Between 33.368 and 33.398 GHz the cavity resonance disappears. We initially believed this to be due to a mode crossing, even though no other modes are visible, and though it might be due to a mode that usually didn't couple to the waveguide being excited. However, the cause turned out to be the extremely weak coupling of the calibration port suppressing the mode at that frequency.

\begin{figure}[htbp]
\begin{subfigure}{\textwidth}
\includegraphics[width=\textwidth]{1stpic}
\caption{The cavity response is suppressed at the edge of this band and no response is apparent in the middle of the dead spot.}
\end{subfigure}
\begin{subfigure}{\textwidth}
\includegraphics[width=\textwidth]{2ndpic}
\caption{Resonance severly suppressed. Taken Feb 05, 2014.}
\end{subfigure}
\end{figure}

However after adding the metal shim in the bottom of the waveguide, the cavity resonance re-appears in this region.

\begin{figure}[htbp]
\begin{subfigure}{\textwidth}
\includegraphics[width=\textwidth]{1stpic_1_}
\end{subfigure}
\begin{subfigure}{\textwidth}
\includegraphics[width=\textwidth]{2ndpic_1_}
\end{subfigure}
\caption{May 07, 2014 - cavity response looks normal after inserting a shim and setting frequency to previously problematic region.}
\end{figure}

We now discuss the analysis of the data, where we looked for peaks in the recorded spectra.  In the absence of statistically significant peaks, we set a limit on the minimum detectable power we can measure, and use that as our exclusion limit. 

%In our analysis, we assume that the axion has a boosted Maxwellian distribution with energy fractional width of $\mathcal{O}(10^{-6}$, or about one 34 KHz bin. 

The analysis process can be decomposed into three parts: baseline corrections, weighting and peak finding.

In section 4.2 we show the procedure for correcting the raw data and cuts made. Section 4.3 discusses the power combining and resulting exclusion limit, section 4.4 describes the resulting candidates and section 5 shows our final exclusion result.

\section{Data Processing}


In a typical run, we sampled voltage as a function of time from two channels in our receiver chain over the course of an hour. At a sampling rate of 10 MHz/sec, this generated a large volume (37 GB  per channel) of data. Using the FFTW libraries \cite{fftw} we computed the discrete Fourier transform for each set of 294 samples. Squaring the voltage transforms and summing resulted in a power spectra. The double-sided power spectra has a span of -5 to 5 MHz, centered at 0 MHz. Each spectra is saved to a file which consists of two vectors corresponding to the baseband frequency and power density, respectively. The first step in data analysis is to extract axion induced signals (i.e. peaks) from raw spectra. As we are searching for extremely weak signals amidst the noise, searching for true signals is a challenging task. 

An axion induced signal would appear as a local maxima in the spectra. However, detecting the signal is challenging as a the weakness of the signal means it may be buried by noise, causing a high false positive rate of peak detection. For each cavity setting, we average over many spectra to increase our sensitivity. As well, electronic noise results in a curve that affects the background of the data, which is referred to as a baseline. THe existence of the baseline produces strong  bias in the peak detection. It is desirable to remove the baseline before peak detection.

\begin{figure}[htbp]
\includegraphics[width=\linewidth]{flowchart2}
\caption{Data Analysis Pipeline}
\end{figure}

\section{Baseline correction}

Baseline correction is typically a two-step process: (1) estimating the baseline and (2) subtracting the baseline from the signal. In the following, we list details of the method we used to calculate the baselines using smoothing filters.

\subsection{Smoothing Filters}

For an input spectrum, we represent it as [f,p] with the first element as the frequency bin vector and the second element as the power spectral density (with equal length). We use p[n] to denote the discrete form of the power density vector. The input spectrum is always discrete. A spectrum after smoothing can be expressed as $y[n] = x[n] * w[n]$ where $*$ denotes the convolution operation. In the above equations, $w[n]$ is a weight vector. The use of different $w[n]$ will lead to different filters.

\subsection{Moving average filter}

The baseline was initially estimated using a moving average filter, where the output of the moving average filter $y[n]$ is defined as:
\begin{align}
y[n] = x[n] * w[n] = \frac{1}{2k+1}\Sigma_{i=-k}^{k} x[n-i]
\end{align}

where $w[n] = \frac{1}{2k+1}$, $-k \leq n \leq k$ a. The odd number $2k+1$ denotes filter width. The greater the filter width, the more intense the smoothing effect. However, this filter failed to remove oscillatory structure that appears at the level of $O(10^{-3})$. Shown below is the residual after using the moving average to calculate the baseline and then averaging over 522 baseline-removed traces.

This structure is much wider than our expected signal; therefore, we attempt to correct for it using a different filter, known as a Savitzky-Golay filter. The Savitsky-Golay filter can be considered as a generalized moving average filter. It performs a least squares fit of a small set of consecutive data points to a polynomial and takes the central point of the fitted polynomial curve as output.

The smoothed data point $y[n]$ after the Savitzky-Golay filtering is given by the following equation:
\begin{align}
y[n[ = x[n] * w[n] = \frac{\Sigma A_i x[n-i]}{\Sigma A[i]}
\end{align}

Using the Savitzky-Golay filter with a polynomial order of 4 and window size of 11 points reduces the residual structure significantly.

\begin{figure}[htbp]
\begin{subfigure}{\textwidth}
\includegraphics[width=0.8\linewidth]{01-11-08-24-55avgsubpltposfreq_522}
\caption{Systematic residual structure seen when baseline is estimated using moving average filter.}
\end{subfigure}
\begin{subfigure}{\textwidth}
\includegraphics[width=0.8\linewidth]{01-11-08-24-55gs-avgsubpltposfreq_522}
\caption{Residual when baseline is estimated using Savitzky-Golay filter.}
\end{subfigure}
\end{figure}

\section{Data Description}

We use data from measurements taken between 12/13 and 6/14. The physical temperature of the cavity was between 4 and 10 K. The observation time for each cavity setting was on average 1.06 hours. For data taken between Jan 29 2014 and March 13 2014, a test tone signal was injected into the cavity. The test tone frequency was set to be mixed down to -1 MHz. For these runs the cavity frequency was normally mixed down to 2 MHz. 

This data set has 499 groups of data. Each group has a number of spectra, usually 261. 
%\section{Running Time}
%
%\section{Parameter Tuning}
%
%\section{Conclusion}
%
%\begin{table}
%\centering
%\begin{tabular}{| c | c | c | c |}\hline
%\hline
%Component & Gain (dB) & \multicolumn{1}{|p{2cm}|}{\centering Power Density \\ (dBm/Hz)} & Total Power (dBm) \\ \hline \hline
%Cavity & - & -185 & -  \\ \hline
%Cryogenic Amplifiers w/ 3dB atten. & 50 & -144 & - \\ \hline
%Waveguide to Shielded Room & -3.4 & -148.6 & -\\ \hline
%RF switch & -2.7 & & \\ \hline
%RF filter & -0.2 & - & -\\ \hline
%RF mixer & -12 & x & x\\ \hline
%Cable to Electronics & - & - & - \\ \hline
%16 dB attenuation & -16 & - & - \\ \hline
%1.5 GHz Bandpass Filter & -0.5 & - & - \\ \hline
%4 GHz Amplifier & 59.5 & - & - \\ \hline
%Bandpass Filter & -0.5 & - & - \\ \hline
%4 GHz - 590 MHz Mixer & -6.5 & - & - \\ \hline
%25 MHz Bandpass Filter & -2.3 & - & - \\ \hline
%590 MHz Amplifier  & 34 & - & - \\ \hline
%25 MHz Bandpass Filter & -2.3 & - & - \\ \hline
%590 Mz to DC IQ Mixer & -8.5 & x & x \\ \hline
%4 MHz Low Pass Filter & x & - & - \\ \hline
%50 Ohm Voltage Pre-Amp  & x & - & - \\ \hline
%\end{tabular}
%\caption{Power levels at different points (in dBm) in the receiver chain. At each point in the receiver chain the total broadband noise power over the bandwidth of the next component is insufficient to cause saturation}
%\label{table:rxchain}
%\end{table}

The measurements from Dec 2013 to May 2014 were taken at 368 distinct resonant frequencies, with 499 total observations made. 415 of these observations were taken for 1.06 hours, with a smaller number (28) being taken for longer observation times; the remaining observations were taken for shorter times due to storage limitations or technical problems with the data acquisition system, and later were retaken to increase the number of averages at that frequency setting. For each measurement we tracked the in-phase and quadrature components of the baseband signal, and converted the time-domain data into a 294 bin,  34013.6 Hz/bin double-sided FFT power spectra. The FFT traces are 10 MHz wide, with a center frequency at 0Hz. Each of the spectra consist of 500,000 averages lasting a total of 14.7 seconds in integration time; for the standard observation length of 1.06 hrs, 261 such spectra could be produced. 

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{examplespectra}
\caption{FFT Power spectral density vs baseband frequency. Each bin is 34013.6 Hz wide.}
\label{fig:example}
\end{figure}

Shown in Figure\ref{fig:example} is one such raw FFT trace. The horizontal axis shows the baseband frequency, and the vertical axis corresponds to the power density across the 50 ohm input in milliWatts per Hz. The visible features in the spectrum are the spike at 0 Hz, which is DC noise, the skirts at the edges showing the attenuation of the last low pass filter in the receiver chain, the 1/f noise near the center, and a dip corresponding to the combined cavity-amplifier response.

\subsection{Corrections}

To remove the features due to the last low-pass filter, we cut out the first and last thirty bins of each trace to remove the filter skirts, and also cut out twenty bins around the center to remove the DC spike and 1/f noise. 

%\begin{figure}[htbp]
%\centering
%\includegraphics[width=\textwidth]{roomtempchain1}
%\label{fig:roomtempchain1}
%\caption{The transfer function of the room temperature electronics chain with the RF switch in place, for different settings of the first local oscillator.}
%\end{figure}

The first local oscillator of the receiver is usually set so that the cavity resonant frequency is mixed down to 2 MHz. However, for a period of runs the first local oscillator was set so that the cavity frequency was mixed down to -1 MHz or -0.5 MHz in the baseband. There are also some measurements that had to be discarded because the local oscillator frequency was incorrectly set due to operator error and thus the cavity frequency was outside of the pass-band of the last filter. In order to prevent this from occurring, we introduced a test tone signal at an RF frequency such that it would mix down to -1 MHz, to make sure the local oscillator was set correctly. For the measurements taken with the test tone on, we later also cut out the bin with the test tone signal, as well as the two nearest bins to either side, for reasons to do with the fit. Lastly, there is some leakage into the positive frequency bins at 1 MHz due to the test tone; this will be discussed later.

\begin{figure}[htbp]
\begin{subfigure}{0.5\linewidth}
\includegraphics[width=\textwidth]{rawwithtesttone}
\caption{FFT trace with test tone signal at 34.044 GHz, -60 dBm}
\end{subfigure}
\begin{subfigure}{0.5\textwidth}
\includegraphics[width=\textwidth]{rawwithtesttone2}
\caption{FFT trace with test tone signal at 34.258 GHz, -72 dBm}
\end{subfigure}
\label{fig:testtone}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.85\textwidth]{rawwithfit2}
\label{fig:dataandfit}
\caption{FFT trace and fit.}
\end{figure}

We then estimate the baseline as described in the previous section and cut the seven bins at the end of the spectrum as well as the seven bins nearest the gap. This is to guard against end effects when computing the smooth. The baseline is subtracted from the data to give the residual fluctuations.

%\begin{figure}[htbp]
%%\centering
%\begin{subfigure}{\textwidth}
%\includegraphics[width=1\textwidth]{meansub}
%\label{fig:ms}
%\caption{Residual}
%\end{subfigure}
%\begin{subfigure}{\textwidth}
%\includegraphics[width=0.8\textwidth]{02-12-04-36-35gs-avgsubplt_75}
%\label{fig:avgsubplt}
%\caption{Average of 75 residual traces.}
%\end{subfigure}
%\end{figure}

\begin{figure}[htbp]
\begin{subfigure}{\textwidth}
\includegraphics[width=0.8\textwidth]{meansubzoomed}
\label{fig:msz}
\caption{Residual trace in cavity region\ for one FFT trace}
\end{subfigure}
\begin{subfigure}{\textwidth}
\includegraphics[width=0.8\textwidth]{02-12-04-36-35gs-avgsubpltposfreq_75}
\label{fig:avgsubpltpos}
\caption{Average of 75 residual traces, cavity region. Test tone leakage at 1 MHz.}
\end{subfigure}
\end{figure}
For frequency bins in the FFT trace that are outside of the 3 dB bandwidth of the cavity, the bins can be considered as holding purely background noise. Therefore, when the cavity is centered at 2 MHz in the baseband, this means that we drop all bins occurring at negative frequencies.

The shape of the data near the cavity resonance is dictated by the interaction of the cavity and amplifier coupling, as described in the previous chapter.

\begin{figure}[htbp]
\begin{minipage}{0.5\linewidth}
\includegraphics[scale=0.38]{12-12-15-39-55gs-withfitposfreq_261}
\vspace{4ex}
\end{minipage}
\begin{minipage}{0.5\linewidth}
\includegraphics[scale=0.38]{02-12-04-36-35gs-withfitposfreq_75}
\vspace{4ex}
\end{minipage}
\begin{minipage}{0.5\linewidth}
\includegraphics[scale=0.38]{01-11-12-06-17gs-withfitposfreq_261}
\vspace{4ex}
\end{minipage}
\begin{minipage}{0.5\linewidth}
\includegraphics[scale=0.38]{05-29-05-50-37gs-withfitposfreq_261}
\vspace{4ex}
\end{minipage}
\label{fig:varofcurve}
\caption{Data with fits for different resonant frequencies}
\end{figure}

Ref \cite{dawthesis98} describes the equivalent circuit model of the cavity and amplifier. The result is a five parameter model that can be used to fit the measured data. We are able to fit the data successfully using the five parameter model, but find practically that the empirical fit is more convenient to use. As well, the empirical fit removes the residual oscillatory structure which arises due to the room temperature electronics.

The $\delta P$ power fluctuations that result from the fit subtraction form the data that we analyze to look for excess power.

After subtracting the fit from each FFT trace, we average together many such corrected FFT traces. Within the standard observation time of 1.06 hrs, there were usually 261 FFT traces. Because temperature and pressure variations cause the cavity frequency to shift during the hour of data taking as discussed in the previous chapter, all the FFT traces produced were inspected, and if there was a significant shift in the structure of the traces over the hour, those significantly different traces were discarded. 

There is also leakage at the level of $0.5\%$ of the test tone power into the bins near 1 MHz. This is due to incomplete isolation in the IQ mixer, which is responsible for separating out the in-phase and quadrature components of the signal. The test tone was present in 105 measurements. We gradually reduced the power level of the test tone, but for 72 of the observations, the leakage was statistically significant and so we cut the out the five bins around 1 MHz as well.

\begin{figure}[htbp]
\includegraphics[width=\textwidth]{leakage15}
\caption{Shown are the output power for a test tone sent in at -60 dBm and the power leakage in the 1 MHz bin. For an hour of integration time, the power fluctuations are $O(10^{-14})$, so the test tone leakage is significant.}
\end{figure}


%\begin{figure}[h]
%\begin{subfigure}{0.5\linewidth}
%\includegraphics[width=1\textwidth]{02-04-14-03-57}
%\caption{Change in power spectra over course of 20 min run.}
%\end{subfigure}
%\begin{subfigure}{0.5\linewidth}
%\includegraphics[width=0.8\textwidth]{temp02-04-14-03-57}
%\caption{Temperature of system (red = 1st amplifier, blue = cavity) over run.}
%\end{subfigure}
%\label{fig:tempdrift}
%\caption{We discard data when temperature drifts or frequency drifts occur.}
%\end{figure}

By taking 65 bins considered to measure only background noise and looking at the distribution of fluctuations for 261 traces after correcting for the baseline, we see that the distribution is Gaussian. The width of the Gaussian is $2.45*10^{-13} \text{ mW}/\text{Hz}$ in terms of the output power spectral density; if we convert this to thermodynamic temperatures by dividing out the gain of the system (87 dB) and Boltzmann's constant, we see $\sigma =  .034$ K, which is consistent with the radiometer equation value of $\sigma = T_{sys}/\sqrt{N} = 20/\sqrt{5\times10^5} = 0.028$ K.

This gives us confidence that the statistics of the noise are indeed Gaussian. Thus we assign an initial uncertainty to each bin $i$ in the FFT trace of magnitude $\sigma = P_i/\sqrt{N}$, where $P_i$ is the power of the $i$th bin.

\begin{figure}[htbp]
\includegraphics[width=\linewidth]{01-16-11-30-28gs-histogramofleftbins_261}
\label{fig:singlegaussian}
\caption{Histogram of power fluctuations from 261 corrected FFT traces (baseline), taking the fluctuations from 65 background bins from each trace.}
\end{figure}

As we average the corrected FFT traces together, the fluctuations should go down as $t^{-1/2}$, or as the square root of the number of averages $1/\sqrt{N}$. To estimate this, we take the bins which do not survive the final cut of ``region of interest``; that is to say, for a cavity centered at 2 MHz, we take the residual baseline portion for the negative frequency bins, and by calculating the standard error of the mean as a function of the number of averaged FFT traces that go into the residual baseline, we can get an estimate of whether the system is behaving according to Gaussian statistics. The reason we take the negative (or opposite) frequency bins is to make sure we are only looking at background noise.

\begin{figure}[htbp]
\includegraphics[width=\linewidth]{gs-logstderr1}
\caption{The standard error of the mean of the background bins (92 bins) vs number of averages for a stable 5 hour run}
\label{fig:stderr}
\end{figure}
% for the timestamp 05-30-23 
%The residual baseline for many runs shows a systematic error, showing that we have not fully removed all structure. The amplitude of this effect appears at the level of $0.1\%$.

Figure \ref{fig:stderr} shows that the log of the standard error does indeed go down linearly as we increase the number of averages. This was done for a five hour run; we can see that for that integration time, we have not yet hit a systematic noise floor.

%The total number of averages in each frequency bin is between 0.2 and 2 $10^9$.

\section{Lorentzian Correction}

After correcting the FFT traces for the baseline, we apply an additional weight to the power fluctuations and uncertainty of each bin to remove the cavity response. This factor corrects for the fact that an axion produced off resonance will have a signal amplitude attenuated by the Lorentzian response of the cavity. By weighting by the inverse response, the signal height is expected to be the same in each bin, barring differences in different runs due to different quality factors and form factors. We apply this weighting to the uncertainty of each bin as well.

\begin{align*}
h(f) = \frac{1}{1+4(f-f_0)^2/\Gamma^2}
\end{align*}

\begin{figure}[htbp]
\centering
\begin{subfigure}{0.78\textwidth}
\includegraphics[width=\linewidth]{05-16-12-15-04gs-avgsubplt_92}
\caption{FFT trace with cuts in place and baseline removed. 92 traces are averaged together.}
\end{subfigure}
\begin{subfigure}{0.78\textwidth}
\includegraphics[width=\linewidth]{05-16-12-15-04gs-avgsubpltlc_92}
\caption{FFT trace with cuts in place and baseline removed and cavity response divided out. 92 traces are averaged in this plot.}
\label{fig:lorentz}
\end{subfigure}
\end{figure}

Figure \ref{fig:lorentz} shows the effect of dividing out the cavity Lorentzian. 
\section{Combining Power Spectra}

For power spectra with overlapping frequency bins, we average the power values at those bins from the different traces, with weights given by the inverse uncertainty squared. This weighting gives the maximum likelihood for the mean of values with non-uniform uncertainties. For more discussion on this topic, see \cite{dawthesis98}, \cite{yu04}. The physical intuition behind doing the weighted arithmetic mean is that it allows us to favor bins which have smaller uncertainties because the temperature was lower in that run or because more traces were averaged together at that setting.

\[
\bar{ \delta P_f} = \Sigma_r \delta P_{r, f} w_{r,f}
\]
\[w_{r,f} = \Sigma_r 1/\sigma_{r,f}^2/A\]
\[A=\Sigma_r w_{r,f}\]

So the combined power fluctuations $\bar{ \delta P_f}$ are the weighted mean of the power fluctuations from runs $r$ at the frequency f: $\delta P_{r,f}$, each of which has uncertainty $\sigma_{r,f}$. $A$ is the overall normalization. 

An RF switch was added between the waveguide and receiver chain at the end of Dec 20, 2013. This introduced a loss of 2.55 $+ .67$ $-.79$ dB over the frequency range scanned. Therefore we correct for the difference in gain by dividing all runs taken before the switch was introduced by a factor of 1.8.

The histogram of the power fluctuations in the co-added power spectrum is compared with a simulation done by adding Gaussian noise to the baseline curves and otherwise running it through the data analysis pipeline in the same manner as the real data. Both the real data and simulation have a Gaussian distribution; however the distribution of the real data is narrowed with respect to the simulation distribution. This may be due to the effect of the baseline removal.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.9\linewidth]{histogramofcoaddedpowerspectrum2}
\caption{Histogram of power fluctuations in the total co-added power spectrum.}
\end{figure}

\begin{figure}[htbp]
\includegraphics[width=\linewidth]{numberofaverages}
\label{fig:numberofaverages}
\caption{The number of individual spectra that contribute to each frequency bin in the co-added power spectrum.}
\end{figure}

%\begin{figure}[htbp]
%\includegraphics[width=\linewidth]{lorentzcorrectednumberofaverages}
%\caption{Lorentz corrected number of traces contributing to each frequency}
%\end{figure}

\section{Threshold}

Although the noise is not perfectly Gaussian, we use Gaussian statistics to define a simple threshold. To test for outliers, we set the threshold at each bin $i$ equal to $3\sigma_i$ and rescan at all points where the bin value exceeds this threshold. 

\begin{figure}[htbp]
\includegraphics[width=\linewidth]{switchcorrected5-threshold-error}
\caption{Setting the threshold to be 3 times the uncertainty of each bin, there are 30 candidates.}
\end{figure}

The number of rescans $n_r$ we expect for Gaussian noise when setting a threshold of p sigma and looking at N bins is 
\[n_r = \frac{N}{2}(1-\text{erf}(\frac{p}{\sqrt{2}}))\]
 which for 18345 bins gives $n_r = 25$.

As oulitiers due to noise should go down with increasing averages, we covered the candidate frequencies with half an hour runs and produced a new co-added power spectrum with the rescans added into the data analysis pipeline. If the new co-added power value at the frequency is less than the original threshold, we consider the candidate to have been due to noise.

As all outliers were later suppressed due to additional data taken by rescanning the frequencies in the table above, we generate an exclusion limit by taking the minimum detectable axion signal power as the threshold value at each frequency and converting that into an axion-photon coupling.

%The fraction of power from the axion signal power that appears in a bin is a function of the distance between the axion frequency f_a and the center of the bin $f$ where the bin width is $\delta f$ : \Delta = 2(f_a - f)/\delta f$. For $\Delta > 0$, some fraction of the power leaks into adjacent bins due to the discrete nature of the transform; when $\Delta =1$ the signal is at the bin edge. This fraction of power is given by $P_a(\Delta) - \frac{4P_a}{\pi^2\Delta^2} \sin^2(\frac{\pi \Delta}{2})$. The probability of a signal passing the $3\sigma$ threshold for an offset $\Delta$ is
%
%\begin{align*}
%\begin{multline}
%Prob(P_a(\Delta) > 3) =\frac{1}{2\pi} \int_{-\infty}^{P_a(\Delta) - 3} exp(\frac{-x^2}{2}),\ dx
%= \frac{1}{2} (\frac{1+\text{erf}(P_a(\Delta) - 3}{\sqrt{2})
%\end{multline}
%\end{align*}
%
%Averaging over $\Delta \in [0,1]$
%
%
%\begin{align*}
%\overline Prob(P_a > 3 = \frac{1}{2} \int_{\Delta=0}^{\Delta=1} d\Delta (1+\text{erft}(\frac{1}{\sqrt{2}(P_a sinc^2(\pi \Delta/2) - 3)))
%\end{align*}

\begin{figure}[htbp]
\includegraphics[width=\linewidth]{numberofcandidatesvsthreshold2}
\caption{Number of candidates versus threshold}
\end{figure}

\begin{table}[htbp]
\caption{Candidates}
\begin{center}
\begin{tabular}{|c|c|c|}
\hline 
Frequency (GHz) & PSD (mW/Hz) & Threshold \\ \hline
33.922278828 & 2.6433062220 &  2.56177873618e-14\\ \hline
33.9821087504 & 4.01889850759e-14 &  3.75779859252e-14\\ \hline
34.032823028 & 3.9813823045e-14 & 3.22466144484e-14\\ \hline
34.0330951368 & 3.57069525293e-14 & 3.19619691831e-14\\ \hline
34.0335713272 & 2.44207326219e-14 & 1.94152529304e-14\\ \hline
34.0352720072 & 1.88003796249e-14 & 1.82006596004e-14\\ \hline
34.0439794888 & 4.02448855563e-14 & 2.21003268442e-14\\ \hline
34.0585713232 & 2.25485631512e-14 & 2.04846595321e-14\\ \hline
34.0614284656 & 3.28436642257e-14 & 2.84855312922e-14\\ \hline
34.0632652 & 3.16572898809e-14 & 2.2479112676e-14\\ \hline
34.0662583968 & 2.87516371617e-14 & 2.33616496463e-14\\ \hline
34.1129930832 & 1.59198873493e-14 & 1.3809913528e-14\\ \hline
34.1426189288 & 4.16770641435e-14 & 3.78242771001e-14\\ \hline
34.1448298128 & 2.30593607493e-14 & 1.91897857856e-14\\ \hline
34.1449318536 & 2.03901772311e-14 & 1.85352212317e-14\\ \hline
34.1458502208 & 1.92768292095e-14 & 1.62473638403e-14\\ \hline
34.1463944384 & 1.70908654746e-14 & 1.69355141309e-14\\ \hline
34.1475168872 & 2.22833996376e-14 & 2.1356105071e-14\\ \hline
34.1725508968 & 2.90983734422e-14 & 2.24914699629e-14\\ \hline
34.1742515768 & 7.20190044285e-14 & 2.09515421745e-14\\ \hline
34.2082651768 & 3.08782413537e-14 & 2.68277290415e-14\\ \hline
34.2452719736 & 2.28537708519e-14 & 1.82106093843e-14\\ \hline
34.2590814952 & 2.38090356895e-14 & 2.05178958959e-14\\ \hline
34.3315644768 & 1.33971266806e-14 & 9.12957448161e-15\\ \hline
34.3332651568 & 8.30755776663e-15 & 5.97072478179e-15\\ \hline
34.338265156 & 1.99348483186e-14 & 1.88348838013e-14\\ \hline
34.3485712768 & 2.06439988028e-14 & 1.91898996061e-14\\ \hline
34.3699998448 & 2.39983850695e-14 & 2.32990970718e-14\\ \hline
34.5108501624 & 3.96664566965e-14 & 3.1224174159e-14\\ \hline
34.5175508416 & 1.57719161032e-14 & 1.56830081055e-14\\ \hline
34.5192515216 & 1.30334171873e-14 & 1.24182640031e-14\\ \hline
\end{tabular}
\end{center}
\label{default}
\end{table}%

An alternative approach is to estimate the noise by taking the local standard error of 1000 bins in the combined power spectrum, and then set the threshold as 3 times that local standard error. This approach has a lower threshold and thus more candidates arise. 

There are 78 bins with values greater than this threshold. 

\begin{figure}[htbp]
\includegraphics[width=\linewidth]{switchcorrected5-threshold-dots}
\caption{Number of candidates appearing when threshold defined using running standard deviation with window size of 1000.}
\end{figure}

There were two environmental signals that persisted after rescans. We believe these to be environmental signals as they appear in both the positive frequencies where the cavity is centered, and in the corresponding negative frequency bin with similar amplitudes. This implies that the signal is not coming from the cavity, as in the case of the test tone signals, as then the amplitude would be suppressed to $0.5\%$ in the negative frequency bins.

\begin{figure}[htbp]
\includegraphics[width=\textwidth]{05-15-23-50-02gs2-avgsubplt_261}
\caption{Environmental signals in original runs}
\end{figure}

In the rescans, two of the detected environmental signal persisted, as shown in the following figure.

%\begin{figure}[htbp]
%\includegraphics[width=\textwidth]{07-09-01-06-58gs2-avgsubplot_121}
%\caption{Rescan at the same LO freq}
%\end{figure}

We believe the 2.2 MHz signal to be due to pickup at that frequency from the two cables that carry the I and Q signals to the digitizer. In a June 23rd run taken with the cavity detuned and the local oscillator set to 30.23 GHz, DOESSIGNALAPPEAR?

SHOW2.2MHZAMPASFUNCTIONOFTIME

REDOSMOOTHTOEXCLUDEPEAKS

\chapter{Exclusion Limit}

\section{Axion Bounds}
From the threshold, we can derive an exclusion limit with $95\%$ confidence. For the first approach using the uncertainty in each bin to set the threshold, we can translate the output power into an expected axion-photon coupling. Our data analysis procedure is excluding axion signals that appear as power excesses in one bin. However, we must correct for the fact that if the axion converts to a photon whose frequency is not centered on the FFT bin, due to the discrete nature of the transform, some power is lost to other bins. In the worst case $40.5\%$ of the power is lost when the axion signal is at the boundary between two bins. We assume that this worst case scenario always happens by putting this factor in to the expected signal power, which degrades the exclusion result by $\sqrt{.405}$ or $16\%$. 

Assuming all the candidates end up being shown to be noise, we can set an exclusion limit as shown in the following figure.

\begin{figure}[htbp]
\centering
\includegraphics[width=\linewidth]{1binsearch}
\caption{Gray filled region shows the CAST exclusion bounds. Blue is the present work.}
\end{figure}

This improves on the previous best limit in this frequency range by the CAST experiment of $g_{a\gamma\gamma} > 8.8 \times 10^{-11}$.

The confidence level can be obtained by finding the probability of a an axion signal passing the $3\sigma$ cut for a given offset from the center of a bin, and integrating over the various possible offsets.

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{confidencelevel3}
\caption{For a cut of 3$\sigma$, a power of 6.54$\sigma$ will pass the cuts with 95$\%$ confidence level}
\end{figure}

For a $90\%$ confidence level in total, we need the signal to pass both cuts with $\sqrt{.9} = .949$ probability, so the power level corresponding to a $95\%$ probability is some number of sigma.

A two bin search is slightly more sensitive, since in the worst case only $81\%$ of the power remains in any given two-bin. Again, we can take the worst case estimate as the valuation for all bins and set a limit 

\begin{figure}
\centering
\includegraphics[width=\textwidth]{2binsearch}
\caption{Exclusion limit from two bin analysis}
\end{figure}

\section{Hidden Photon Bounds}

We can use the same data set to restrict the coupling of hidden photons with masses $140.2-142.7$ $\mu$eV. The argument is slightly modified to account for various polarization scenarios. One can imagine that (1) all of the polarizations are aligned, or (2) the polarizaions are random, as two model cases. 

For randomly pointed directions the average value of $<cos^2 \theta> = \frac{1}{3}$; for the case where all the polarizations are aligned, assume all directions are equally likely; then for $\theta$ such that $\cos^2 \theta = 0.0025$, there is a 95$\%$ probability that the actual value is larger than that estimate.

\begin{figure}[htbp]
\includegraphics[width=\textwidth]{hiddenphotonexclusion}
\caption{Parameter space for hidden photon dark matter, from \cite{arias12}. The pink is allowed parameter space; other colors are experimental or observational exclusions.}
\end{figure}

\begin{figure}[htbp]
\includegraphics[width=\textwidth]{hspexclusionlimitwithlongmodes}
\caption{New limits placed on hidden photon coupling with analysis of longitudinal mode contribution from the sun \cite{pradler13}, \cite{an13}}
\end{figure}

The blue region in the above plot is previous work done by this collaboration using a light-shining-through-wall method. In that project, we recorded the noise from one cryogenically cooled cavity while driving a second cavity placed nearby on resonance. Both cavities had the same resonant frequency. Detection of excess power in the shielded and cooled cavity would be a possible signature of hidden photons being produced in the driven cavity, traversing the shielding and reconverting to photons. The green region labeled CERN \cite{betz13} was the first LSW experiment to use microwave cavities and probe new parameter space. It operated at around 2 GHz and did not employ cryogenic cooling, but rather long measurement times to reduce the noise floor. 

Why isn't CAST sensitive to hidden photons?
%\section{Procedure during normal running}
%
%The data acquisition system (computer plus sensors plus instruments) measures important parameters, e.g. temperatures, pressures. As discussed earlier, the important cavity parameters are the cavity quality factor Q, center frequency of the cavity, strength of magnetic field, and cavity physical temperature. Once these quantities are measured, we manually tune the tuning rod by an amount corresponding to 3 MHz (approximately xx length). The cavity resonance moves, the cavity parameters are then measured, and then a 1 hr time trace is acquired as a two channel system and saved to disk in little-endiant binary format as signed 8-bit integers.
%
%The binary data format compresses the information by a factor of xx in relation to ASCII (Text) format. The data format is as follows: there is a xx byte header, followed by the 2948-bit integers plus three FFT parameters. The following table shows the axion data format taken for these data.
%
%There is a potential issue in saving data with one computer and then post-processing the data on another. Data might be "big endian" or "little endian", referring to the byte order of how floating point numbers are read by different computer platforms. The mismatch was solved with a byte swapping routine, which first checked whether the data made sense if the data was in one endian form or another. Once established, the endian issue is resolved and the post-processing computer performs the analysis.
%
%\begin{table}
%\centering
%\begin{tabular}{| c | c ||}\hline
%\hline
%Description & size (bytes) \\ \hline
%Header & 35 \\ \hline
%Gain & x \\ \hline
%Offset & x \\ \hline
%NumSamples &  xs\\ \hline
%NumTriggers & x \\ \hline
%Voltage(T) & x \\ \hline
%\end{tabular}
%\caption{Data format for YMCE running. Each file begins with four numbers specifying the digitizer gain, offset, number of triggers, and number of points in each trigger. It is followed by a header and then the 294 points for the time record}
%\label{table:dataformat}
%\end{table}
%\section{Sensors and Instrumentation}
%
%The experiment relied on a number of important sensors, mostly temperature sensors, level sensors, and vacuum pressure sensors. One temperature sensor as connected to the bottom plate of the cavity, another to the first cryogenic amplifier, one connected to two points half way up the insert, and another on the vaporizer. The temperature sensors were produced and calibrated by Lakeshore Cryotronics Inc.  Five were used and they were attached at a) bottom plate of cavity, b)vaporizer c) cryogenic amplifiers, and d) two in the middle of the insert. The temperature sensors were calibrated to typically within a tenth of a degree Kelvin of the true temperature, and were read out with a temperature sensor controller also produced by Lakeshore.
%
%Vapor pressure of Helium 4. 
%
%\section{The FFT}
%
%The FFTW libraries are used to do the data reduction. Uniform windowing is employed. Figure 4 shows a typical averaged power spectrum taken during running.
%
%The most obvious feature of this typical power spectrum is the rapid falloff in power outside the frequency range -4-4 MHz, caused by attenuation outside the passband of the low-pass 4 MHz filter. Understanding the shapes of traces from the raw data is important for data analysis since the signal from axions is predicted to be power excess over a bin of a trace above the noise baseline. Treatment of the noise baseline is presented in chapter 4.
%
%\section{Signal injection}
%
%It would be advantageous to inject a synthetic axion line int othe experiment cavity. the benefits are simple, we could test different search algorithms and determine their relative performance without the need for Monte Carlo methods in the data analysis. The scheme for inject this synthetic signal is simple and is sketched in Figure 3.
%
%The synthetic axion line would be injected into the cavity during data taking via the weakly coupled minor port. 
%
%I've demonstrated that a single synthetic axion line can be injected into the cavity and detected with the receiver chain. The next step would be to calibrate the power level of the injected signal inside the cavity from the noise power and then automate the procedure. With sufficient statistics the search confidence can be validated by search algorithms to be discussed in Chapter 4.
%
%\section{Input match of the first cryogenic amplifier}
%
%To measure the input match of the 1st cryogenic amplifier, the power reflection coefficient at room temperature was determined according to the apparatus of Figure 3.
%
%The signal from the sweeper is incident on the load via the directional bridge. Power reflected off the load is directed onto a power sensor. A null measurement is first done with the bridge terminated in a short so all the incident RF power is reflected. Next the short is replaced with the device under test. The difference between the reflected power with the amplifier connected and the reflected power with the short connected is the the power reflection coefficient.  Figure 3 is the power reflection coefficient as a function of frequency. There vertical axis is the reflection coefficient in dB with the cursor indicating 0 dB and 4 dB per division.
%
%The power reflection coefficient is very good, better than -18 dB over a bandwidth of at least 799 MHz. The reflection coefficient is not expected to have a strong temperature dependence and any serious worsening of the reflection coefficient would manifest itself through poor gain and high noise temperature. As we shall see from the results of cryogenic measurements later in this section, at low temperatures the gain of the amplifier increases and its noise decreases, indicating that the good match at the amplifier input persists at cryogenic temperatures.
%
%\section{The first cryogenic amplifier coupled to the resonant cavity}
%
%If the load on the cavity is not a 50 ohm impedance then a fraction of this power reflects off the load and appears back at the amplifier as a signal. Since the cavity impedance is rapidly varying with frequency near resonances it is important to understand the contribution of the internal terminations to the system noise with a cavity  connected to the amplifier input.
%
%The following experiment is an indicator of how noise sources in the amplifier contribute to the amplifier noise with a cavity load. The cryogenic amplifier is critically coupled to the resonant cavity at room temperature. The power spectrum a the amplifier output is measured using a spectrum analyzer, first with the amplifier at room temperature then with the amplifier cooled in liquid nitrogen. Figure 3 shows the two power spectra.
%
%Consider the upper trace, taken when the cavity was warmer than the amplifier. On resonance the cavity acts as a load perfectly matched to the amplifier input. Therefore all power from the amplifier that is emitted at the input port is absorbed in the cavity and not reflected. The noise temperature at the input is the physical temperature of the cavity.
%
%\section{The gain of the cryogenic amplifiers at cryogenic temperatures}
%
%It is important to make an 'in situ' measurement of the gain of the first cryogenic amplifier and the results compared with gain data supplied by Sandy Weinreb. The gain of the cryogenic amplifier was measured previously uon a cold test-stand.
%
%\subsection{'In Situ' measurement of the cryogenic amplifier noise temperature}
%
%The noise temperature of the 1st cryogenic amplifier was measured with the amplifier installed on the axion receiver. We argued in the previous section that the 1st cryogenic amplifier is the only component in the receiver chain whose noise temperature significantly affects the sensitivity of the search. This measurement is a check that the amplifier noise temperature in the high magnetic field of the detector remains low.
%
%The amplifier noise temperature is referenced to the temperature of the Johnson noise in the cavity. The cavity temperature is varied, and by looking at the output power of the cryogenic amplifier as a function of the cavity temperature, the amplifier noise temperature can be deduced.
%
%Referring to figure 3, the cryogenic amplifier is critically coupled to the cavity using the reflection method described earlier. For the remainder of the measurement, the directional coupler is not used. On-resonance, the impedance of the cavity through the critically coupled probe is 50 ohms. Hence the cavity may be used as a source of thermal noise at a known temperature. The cavity temperature is initially 1.6 K.
%
%The cavity is warmed by allowing the pressure above the liquid helium lake below the cavity to rise. A large gate valve between the Roots blower and the insert space is closed most of the way to allow for a slower pressure relaxation. As the helium vapor pressure rises, the temperature of the liquid helium also rises, until at atmosphere pressure, the physical temperature of the liquid and the vapor helium inside the cavity space is 4.2 K. Care is taken to ensure the cavity warmup is slow. During this slow warmup the data acquisition runs.
%
%The DAQ software first injects a swept signal through the weak port and measures the transmission to the receiver chain using a network analyzer, then takes a power spectrum about the cavity resonance. Figure 3 shows the power per Hz for the on-resonance bin versus temperature for our in situ noise temperature measurement for a cavity resonant frequency of xx GHz. Specifically, the output power at the end of the axion receiver is given by 
%
%Noise temperature versus frequency from Sander Weinreb.
%
%\begin{figure}[htbp]
%\includegraphics[width=0.5\textwidth]{yfactor5}
%\caption{Y-factor measurement of the 1st HEMT noise done using a 50 Ohm load in a copper block. We heated the block quickly and used a short stainless steel segment in order to thermally isolate the hot block from the HEMT. The plot shows  the  output power measured over a resolution bandwidth of 3 MHz on the spectrum analyzer as a function of frequency.}
%\end{figure}
%
%\begin{figure}[htbp]
%\includegraphics[width=0.5\textwidth]{yfactor6}
%\caption{Noise Temperature}
%\end{figure}
%
%\begin{figure}[htbp]
%\includegraphics[width=0.5\textwidth]{weinrebgain}
%\caption{Gain of 1st amplifier measured by vendor}
%\end{figure}
%
%Let us neglect the effect of the waveguide to coaxial adaptor. Then the noise at the input of the 1st cryogenic amplifier is the sum of the load and amplifier physical temperatures plus the intrinsic electronic noise temperature of the amplifier:
%
%$T_{sys} = T_{HEMT} + T_{load} + T_N$
%
%If we assume that the noise temperature of the amplifier remains constant over a small range of physical temperatures, say 4-10 K, then by doing the Y-factor measurement with the HEMT at approximately the same temperature and the load temperature varied, we see that 
%
%$T_{sys,hot load} - T_{sys, cold load} = \Delta T_{HEMT} + \Delta T_{load}$ 
%
%Unfortunattely it is difficult to make noise temperature measurements of the cryogenic amplifier in situ to an accuracy of better than 10 percent. This is due to difficulty in controlling the exact temperature of the resonant cavity as it warms. However, our value measured in situ is consistent with the value measured by Sander Weinreb. We used 10 K as our amplifier noise temperature for the frequency range 33.9-34.5 GHz.
%
%\section{The room temperature electronics}s
%
%After the signal leaves the first cryogenic amplifier, it goes through a 3 dB attenuator and a second cryogenic amplifier. After this it proceeds up the waveguides in the insert through a feedthrough, through more waveguides, past a vacuum window and through a waveguide to coax adaptor and to the room temperature electronics. We discuss the room temperature electronics in this section.
%
%\subsection{RF components}
%
%The output of the 
%=====
%BELOW THIS POINT IS OLD WORK
%
%We used a cylindrical cavity cooled to $\sim 5$ K resonant at a frequency of $33.9-34.5$ GHz in the $\text{ª}_{020}$ mode. The cavity was tuned to a specific resonant frequency using a dielectric rod; we measured the resonant frequency and Q using a vector network analyzer, then recorded the amplified noise from the cavity (after being mixed down to baseband) for an hour before retuning the cavity by 3 MHz. The baseband noise when Fourier transformed is a measure of the power in each frequency interval $\delta f$ that is the sum of the power in the cavity plus additional noise from the receiver chain. 
%
%We recorded data in twelve separate runs (Nov 19 to May 30, 2014), and measured noise for 500 settings of the cavity frequency, with an hour of integration. The actual performance of our system
%
%Summary of Runs
%\begin{center}
%\begin{tabular}{c | c | c }\hline
%\hline
%Run & No. of Freq.'s & State \\ \hline \hline
%11/19-11/22 & 9 & slow DAQ \\ \hline
%12/03-12/07 & 39 & faster DAQ \\ \hline
%12/10-12/13 & 22 & tuning rod froze\\ \hline
%12/16-12/20 & 27 & --\\ \hline
%01/08-01/11 & 46 & heater feedback loop online\\ \hline
%01/14-01/18 & 69 & RF switch added \\ \hline
%01/23 & 5 & -- \\ \hline
%01/28-02/01 & 41 & test tone added \\ \hline
%02/04-02/07 & 33 & tuning rod froze\\ \hline
%02/11-02/13 & 19 & -- \\ \hline
%03/10-03/13 & 16 & -- \\ \hline
%05/06-05/09 & x & weak coupling port altered, test tone removed\\ \hline
%05/14-05/17 & x & -- \\ \hline
%05/28-05/30 & x & -- \\ \hline
%\hline
%\end{tabular}
%\label{table:runsummary}
%\end{center}
%\section{Procedure}
%the following section is formed of quotes/notes from Silk(?) in "Inner Space Outer Space"
%We tracked the in-phase and quadrature voltage of our baseband signal for an hour at each frequency setting. To allow for overlap between the covered frequencies, the cavity resonance was shifted by 3 MHz at a time. The dominant systematic effects were temperature variations in the cryostat. 
%
%To reduce the effects of the the temperature shifts we discarded all data that was greater than 28 sigma away from the first minute of data. 
%
%The data presented here were taken during 2014 Nov 19-22, Dec 05 to 07, 11 to 13, É . These runs gave a total of 500 hours of useful data. After correcting the data for the gain of the receiver and converting them to thermodynamic temperatures we compute the mean values $\Delta T_{bin}^i$ for the observations of each frequency bin of width $\delta f$ for each spectrum. The corresponding standard deviations, $\sigma_{bin}^i$ are calculated from the scatter of the individual 57 second measurements and are an estimate of the statistical uncertainty in the mean of an hour of data. ADDINBOOTSTRAP A typical value for data taken at 5 K is $\sigma_{bin189}^i = 0.25 mK$ whereas one expects $0.14$ mK from system noise alone. The excess noise at this stage is due to the $1/f$ component and in the variable temperature noise.
%
%The final values $\bar \Delta T_{bin}^i$ for each one of the bins were obtained by weighting by $(\sigma_{bin}^i)^2$ each one of the hour observations for a given bin. The results are plotted in Figure 1 and show no statistically significant signal in any of the bins. The errors associated to each point correspond to the standard deviations estimated from the measurement statistics in the usual way. As the data will be used to decide what level of axion coupling is excluded by these measurements it is crucial to estimate the errors in Figure 1 accurately. The scatter in the values of $\Delta T_f^i$ for the different measurements could be larger than expected from the systematic effects. In principle, one could perform standard Chi-square tests for each one of the bins. Any such test would compare the scatter of the different observations of a given field with respect to the final value, with the corresponding values of $\sigma$. Let me emphasize that such a test does not depend on whether there is a true signal coming from the sky, as the scatter is computed with respect tone "local mean"; it is truly an instrumental Chi-square test. Figure 2 shows a histogram of the weighted residuals $(\Delta T - \bar \Delta T)\sigma$ for the observations. The histogram is reasonably gaussian with the a width that is consistent with what we would expect if all the scatter the values of $\Delta T$ with respect to their corresponding average value were due to fluctuations contained in $\sigma_i$. Indeed, the corresponding value of Chi-Square is of 78 with 75 degrees of freedom. Therefore, we conclude that it is legitimate to estimate the standard deviations $\bar \sigma$ in the standard way, as $\bar \sigma = [\Sigma \sigma^{-2}]^{-1/2}$. The variation of $\sigma$ frm bin to bin is mainly due to the different number of runs over which each frequency is observed. The weighted mean of the points in Figure 1 is $T_{avg} = 26 \pm 3 mk$.
%
%It follows from visual examination of Figure 1 that none of the points differs significantly from the mean. The question is then what limits do the data place on $g_a$ from the fact that we only see the scatter shown in Figure 1. The Neyman-Pearson lemma prescribes the optimal statistical estimator for testing the hypothesis that $g_a \neq 0$. The optimal statistic turns out to be essentially a weighted Chi-square test, which can be used to find out which values of $g$ are ruled out at a certain confidence level.
%
%\section{State Parameters}
%
%Below is a plot of the measured loaded Q over the runs taken. NEED TO UPDATE
%\begin{figure}[htbp]
%\centering
%\includegraphics[width=1\textwidth]{measuredqvsfrequencyinsitucutoutoutlierswithtitle}
%\end{figure}
%
%Below is a plot of the form factor, calculated by simulating the electromagnetic fields in the cavity using the HFSS software.
%\begin{figure}[htbp]
%\centering
%\includegraphics[width=1\textwidth]{formfactorvsfrequency}
%\end{figure}
%
%Shown below is a cross-sectional plot of the electric field in the z-direction for a dielectric rod with $\epsilon = 9.2$ inserted 0.028 inches into the cavity.
%
%\begin{figure}[htbp]
%\centering
%\includegraphics[width=0.8\textwidth]{efieldhfsssim28thou}
%\end{figure}
%
%Shown below is the frequency coverage NEED TO UPDATE
%
%\begin{figure}[htbp]
%\centering
%\includegraphics[scale=0.7]{frequencycoverage}
%\end{figure}
%
%\section{Data Analysis in Detail}
%The data analysis starts from the raw time traces. The receiver chain at the final step separates the signal into an in-phase and quadrature component using an IQ mixer. These two separated signals each go through a low pass filter with approximately 4 MHz bandpass, and then are amplified by a voltage pre-amplifier with a gain of 5. The output channels (labeled henceforth as I and Q) are then plugged into a PCI 1154 card on a Dell desktop and digitized at a rate of 10 MSa/sec, with a a digital external referene at 10 MHz. We have a data acquisition program written in Visual C$\#$ that acquires however many records we desire, with each record containing 2.56e6 samples. The data acquisition has zero deadtime. The regular running procedure is to take 15,000 records at one particular cavity setting, and then retune - 15,000 records takes 1.06 hrs. 
%Shown below is an example spectra
%
%\subsection{cuts}
%
%We discard all chunks that have the cavity drifting in frequency.
%
%\begin{figure}[htbp]
%\includegraphics[width=\textwidth]{01-16-00-38-43}
%\includegraphics[width=\textwidth]{temp01-16-00-38-43}
%\end{figure}
%\begin{figure}
%\includegraphics[width=\textwidth]{01-14-16-14-53}
%\includegraphics[width=\textwidth]{temp01-14-16-14-53}
%\end{figure}
%
%We also cut data when the temperature difference causes changes in the spectra.
%
%\begin{figure}[htbp]
%\includegraphics[width=\textwidth]{02-04-14-03-57}
%\includegraphics[width=\textwidth]{temp02-04-14-03-57}
%\end{figure}
%\begin{figure}
%\includegraphics[width=\textwidth]{02-04-17-34-58}
%\includegraphics[width=\textwidth]{temp02-04-17-34-58}
%\end{figure}
%
%
%
%\section{HFSS Design}
%
%\includegraphics[width=\textwidth]{tableofchoice}
%
%\includegraphics[width=0.6\textwidth]{tm020efield}
%
%\includegraphics[width=0.6\textwidth]{tm020magneticfield}
%
%\includegraphics[width=\textwidth]{waveguidefields}

\chapter{Outlook}

To search for ALPs in the $10^{-3}-10^{-4}$ meV mass range using microwave cavities, with sufficient sensitivity to detect QCD axions, is experimentally challenging. The most significant limitation comes from the reduced volume of the cavity if operating in the lowest order mode. The volume can be increased by operating at higher order modes, as we did in operating in the $\text{TM}_{020}$ mode. We chose to operate with a conservative aspect ratio in order to stay away from possible mode crossings; further sensitivity can be gained by increasing the length and increasing the overall volume.

The other main limitation comes from the system noise temperature. Our amplifiers operate with a noise temperature of approximately 15 Kelvin at a physical temperature of 9 K. Other options for amplifier technology are microwave SQUIDs, parametric Josephson amplifiers, masers. All of the above are amplifiers that rely on resonance, so they require additional tuning and in most cases, separate magnetic shielding. Neither of the first two have been developed for use at 34 GHz; the highest frequency microwave SQUIDs go to is 9 GHz. They can be developed for higher frequencies; however, there is a more fundamental limitation due to the standard quantum limit, which at 34 GHz is 1.2 K. Lamoreaux et al \cite{lamoreaux13} points out that using nonlinear amplifiers can beat this standard limit, so it is of interest to see if new amplifier technology can be used in the high frequency ranges. The key point here is that while linear amplifiers can preserve phase information and thus spectrally resolve the signal, the fundamental limit also increases with frequency. So by switching to single-photon detection (think bolometers) you lose the spectral information but no longer have that concern. For high frequencies but low temperatures the number of photons is much less than one.

Other than operating at lower system noise temperatures and compensating for the higher frequency by working at higher order modes, there is little else one can do to improve the sensitivity. Operating at higher magnetic fields is possible, given money; perhaps improvement to a 12 Tesla magnetic field is possible. Improving the Q is one strategy; ADMX-HF \cite{admxhf} is doing research on using hybrid superconducting cavities that will hypothetically improve the Q by a factor of 6.

Regardless of the improvement in sensitivity, the microwave cavity technique remains a narrowband measurement, so multiple experiments that can cover complementary portions of parameter space are desirable.

For YMCE's pilot run, 600 MHz of frequency space were covered. Portions of the experiment were manually operated, such as the tuning of the cavity resonance, the recording of the cavity resonance and Q, and the first local oscillator adjustments. Automating these steps would bring the experiment to a stage where it could run without much need for oversight. For the initial analysis, the raw time domain data was saved and processed later - having a real time analysis would be greatly beneficial. Temperature stability was also a serious issue, especially during the first half of the data taking, and caused us to have to discard a significant portion of the data taken. Due to the capacity of the cryostat reservoirs and the consumption rate, there is little that can be done to improve this with the current cryostat. 

One advantage of small cavities is that they can be relatively easily interchanged. This could compensate for the coverage gaps caused by mode crossings. For a future experiment of YMCE, it seems feasible to imagine working with longer cavities, to improve the volume by a factor of up to four, which improves the sensitivity to axions by a factor of two. Using multiple cavities to scan a continuous rangej, these cavitys should be in the $\text{TM}_{020}$. It is not possible to measure the $\text{TM}_{010}$ and $\text{TM}_{020}$ modes in parallel as the $\text{TM}_{010}$ resonant frequency is at 15 GHz and below the cutoff frequency of the waveguides.

\chapter{Appendix}
\section{Confidence Levels}
The fraction of power appearing in a bin is only exactly one when the axion frequency is equal to central frequency of the bin. For any offset $\Delta$, the fraction of power appearing in that bin is then 

\begin{align}
f(\Delta) = \frac{4}{\pi^2\Delta^2} sin^2(\frac{\pi\Delta}{2})
\end{align}

where $\Delta$ is between 0 and 1, $\Delta = 1$ when the axion frequency is  on the border between bins.

That means that for the 1 bin search, in the worst case $\Delta =1$ and only $40.5\%$ of the power is deposited in a bin. For the two bin search, the worst case is when $\Delta =  0.5$, so the lowest amount of power deposited in any two bins is 80.1$\%$.

We can construct a confidence level by finding the probability that an axion deposited signal of a given power $P_a$ and offset $\Delta$ passes the $3\sigma$ threshold for varying values of $\Delta$.

The confidence level is then the probability that the noise in any bin is not less than $P_a - 3\sigma$.
%
%\begin{align}
%c(P_a, \Delta) = \frac{1}{2\pi} \int_{-\infty}^{P_a-3} e^{-x^2/2} dx = \frac{1}{2}(1+\text{erf}(\frac{P_af(\Delta) - 3}{\sqrt{2}))
%\end{align}

Averaging over the possible $\Delta$,

%\begin{align}
%\bar{c(P_a)  = \int_0^1 d\Delta c(P_a, \Delta)
%\end{align}

Integrating the above expression shows that a power level of 6.54$\sigma$ has a 95$\%$ probability of passing the cut. As there are two runs, we need the probability of it passing both cuts is $.95 \times .95 = .9$, for a total confidence level of $90\%$.

\section{Noise Temperature}


%\printbibliography
\bibliographystyle{ieeetr}
\bibliography{thesisbib}

\end{document}